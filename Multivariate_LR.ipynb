{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Multivariate LR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trivedinush/MachineLearning/blob/master/Multivariate_LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkRJzpAZfUTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyLinearRegression:\n",
        "    def __init__(self, weight1=0,weight2=0, bias=40, learning_rate=0.01,\n",
        "                 iterations=2000):\n",
        "        self.weight1 = weight1\n",
        "        self.weight2 = weight2\n",
        "        self.bias = bias\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterations = iterations\n",
        "        self.cost_trend = []\n",
        "        self.cost = 0\n",
        "\n",
        "    def predict(self, xfeature, zfeature):\n",
        "        predicted_set = []\n",
        "        for i in range(len(xfeature)):\n",
        "            predicted_value = self.weight2 * zfeature[i] + self.weight1 * xfeature[i] + self.bias\n",
        "            predicted_set.append(predicted_value)\n",
        "        return predicted_set\n",
        "\n",
        "    def cost_function(self, xfeature, yfeature, zfeature):\n",
        "        count = len(xfeature)\n",
        "        total_error = 0.0\n",
        "        for i in range(count):\n",
        "            total_error += (yfeature[i] - ( self.weight2 * zfeature[i] + self.weight1 * xfeature[i] +\n",
        "                            self.bias)) ** 2\n",
        "        return float(total_error) / (2 * count)\n",
        "\n",
        "    def update_weights(self, xfeature, yfeature, zfeature):\n",
        "        weight_deriv1 = 0\n",
        "        weight_deriv2 = 0\n",
        "        bias_deriv = 0\n",
        "        count = len(xfeature)\n",
        "\n",
        "        for i in range(count):\n",
        "            # Calculate partial derivatives\n",
        "            # -2x(y - (mx + b))\n",
        "            weight_deriv1 += -2 * xfeature[i] * (yfeature[i] -\n",
        "                                                ( self.weight2 * zfeature[i] + self.weight1 * xfeature[i] +\n",
        "                                                 self.bias))\n",
        "            weight_deriv2 += -2 * zfeature[i] * (yfeature[i] -\n",
        "                                                ( self.weight2 * zfeature[i] + self.weight1 * xfeature[i] +\n",
        "                                                 self.bias))\n",
        "            # -2(y - (mx + b))\n",
        "            bias_deriv += -2 * (yfeature[i] - ( self.weight2 * zfeature[i] + self.weight1 * xfeature[i] +\n",
        "                                self.bias))\n",
        "\n",
        "        # We subtract because the derivatives point in direction of steepest\n",
        "        # ascent\n",
        "        self.weight1 -= (weight_deriv1 / count) * self.learning_rate\n",
        "        self.weight2 -= (weight_deriv2 / count) * self.learning_rate\n",
        "        self.bias -= (bias_deriv / count) * self.learning_rate\n",
        "\n",
        "    def train(self, xfeature, yfeature, zfeature):\n",
        "        for i in range(self.iterations):\n",
        "            self.update_weights(xfeature, yfeature , zfeature)\n",
        "            # Calculating cost\n",
        "            self.cost = self.cost_function(xfeature, yfeature, zfeature)\n",
        "            self.cost_trend.append(self.cost)\n",
        "            #if i % 10000 == 0:\n",
        "            print(\"Iteration: {}\\t Weight1: {}\\t Weight2: {}\\t Bias: {}\\t Cost: {}\".\n",
        "            format(i, self.weight1, self.weight2, self.bias, self.cost))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjoNDjuqXh7b",
        "colab_type": "text"
      },
      "source": [
        "It is noted that the learning rate when increased with high iterations the model could not work properly and give monotonous result. Hence the learning rate was reduced to 0.01 and iteration's value was made 2000 (high) so that we could get a perfect line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZhPdTtHoEjN",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIhWZzM2fUTN",
        "colab_type": "code",
        "outputId": "c9782178-5bec-4e85-df03-cf0e2ad334b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# intialise data of lists. \n",
        "data = {'Hours':[2.5,5.1,3.2,8.5,3.5,1.5,9.2,5.5,8.3,2.7,7.7,5.9,4.5,3.3,1.1,8.9,2.5,1.9,6.1,7.4,2.7,4.8,3.8,6.9,7.8],\n",
        "         'Subjects':[1,3,2,4,2,1,5,3,4,1,4,3,2,2,1,5,1,1,2,2,1,2,2,2,4], \n",
        "        'Scores':[21,47,27,75,30,20,88,60,81,25,85,62,41,42,17,95,30,24,67,69,30,54,35,76,86]} \n",
        "  \n",
        "# Create DataFrame \n",
        "studentscores = pd.DataFrame(data) \n",
        "  \n",
        "# Print the output. \n",
        "studentscores "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hours</th>\n",
              "      <th>Subjects</th>\n",
              "      <th>Scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.5</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.2</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.5</td>\n",
              "      <td>4</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.5</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9.2</td>\n",
              "      <td>5</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.5</td>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8.3</td>\n",
              "      <td>4</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.7</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.7</td>\n",
              "      <td>4</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.5</td>\n",
              "      <td>2</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.3</td>\n",
              "      <td>2</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.1</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>8.9</td>\n",
              "      <td>5</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2.5</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.9</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.1</td>\n",
              "      <td>2</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7.4</td>\n",
              "      <td>2</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2.7</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>4.8</td>\n",
              "      <td>2</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3.8</td>\n",
              "      <td>2</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>6.9</td>\n",
              "      <td>2</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>7.8</td>\n",
              "      <td>4</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Hours  Subjects  Scores\n",
              "0     2.5         1      21\n",
              "1     5.1         3      47\n",
              "2     3.2         2      27\n",
              "3     8.5         4      75\n",
              "4     3.5         2      30\n",
              "5     1.5         1      20\n",
              "6     9.2         5      88\n",
              "7     5.5         3      60\n",
              "8     8.3         4      81\n",
              "9     2.7         1      25\n",
              "10    7.7         4      85\n",
              "11    5.9         3      62\n",
              "12    4.5         2      41\n",
              "13    3.3         2      42\n",
              "14    1.1         1      17\n",
              "15    8.9         5      95\n",
              "16    2.5         1      30\n",
              "17    1.9         1      24\n",
              "18    6.1         2      67\n",
              "19    7.4         2      69\n",
              "20    2.7         1      30\n",
              "21    4.8         2      54\n",
              "22    3.8         2      35\n",
              "23    6.9         2      76\n",
              "24    7.8         4      86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB6qrJrPfUTY",
        "colab_type": "code",
        "outputId": "adde531a-bf68-41ca-929c-dca15159e4ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "#from my_linear_regression import MyLinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importing the dataset\n",
        "\n",
        "X = studentscores.iloc[:, : 1].values\n",
        "z = studentscores.iloc[:, 1:2].values\n",
        "y = studentscores.iloc[:, 2].values\n",
        "print(X)\n",
        "print(y)\n",
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.5]\n",
            " [5.1]\n",
            " [3.2]\n",
            " [8.5]\n",
            " [3.5]\n",
            " [1.5]\n",
            " [9.2]\n",
            " [5.5]\n",
            " [8.3]\n",
            " [2.7]\n",
            " [7.7]\n",
            " [5.9]\n",
            " [4.5]\n",
            " [3.3]\n",
            " [1.1]\n",
            " [8.9]\n",
            " [2.5]\n",
            " [1.9]\n",
            " [6.1]\n",
            " [7.4]\n",
            " [2.7]\n",
            " [4.8]\n",
            " [3.8]\n",
            " [6.9]\n",
            " [7.8]]\n",
            "[21 47 27 75 30 20 88 60 81 25 85 62 41 42 17 95 30 24 67 69 30 54 35 76\n",
            " 86]\n",
            "[[1]\n",
            " [3]\n",
            " [2]\n",
            " [4]\n",
            " [2]\n",
            " [1]\n",
            " [5]\n",
            " [3]\n",
            " [4]\n",
            " [1]\n",
            " [4]\n",
            " [3]\n",
            " [2]\n",
            " [2]\n",
            " [1]\n",
            " [5]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZSgOgXhQO7n",
        "colab_type": "code",
        "outputId": "a4b888f4-5774-4529-c9b0-983276ea9257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.5]\n",
            " [5.1]\n",
            " [3.2]\n",
            " [8.5]\n",
            " [3.5]\n",
            " [1.5]\n",
            " [9.2]\n",
            " [5.5]\n",
            " [8.3]\n",
            " [2.7]\n",
            " [7.7]\n",
            " [5.9]\n",
            " [4.5]\n",
            " [3.3]\n",
            " [1.1]\n",
            " [8.9]\n",
            " [2.5]\n",
            " [1.9]\n",
            " [6.1]\n",
            " [7.4]\n",
            " [2.7]\n",
            " [4.8]\n",
            " [3.8]\n",
            " [6.9]\n",
            " [7.8]]\n",
            "[21 47 27 75 30 20 88 60 81 25 85 62 41 42 17 95 30 24 67 69 30 54 35 76\n",
            " 86]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxSazDuOfUTg",
        "colab_type": "code",
        "outputId": "7cce8111-9224-4358-8ad5-ea204f180045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test , z_train, z_test = train_test_split(X, y, z, test_size=1/3, random_state=0)\n",
        "\n",
        "# Fitting Simple Linear Regression to the Training set\n",
        "regressor = MyLinearRegression()\n",
        "regressor.train(X_train, y_train, z_train)\n",
        "print('Weight2: ' + str(regressor.weight2) + 'Weight1: ' + str(regressor.weight1) + ' Bias: ' + str(regressor.bias))\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = regressor.predict(X_test,z_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0\t Weight1: [2.661]\t Weight2: [1.35125]\t Bias: [40.2725]\t Cost: 150.95216741000002\n",
            "Iteration: 1\t Weight1: [3.01409057]\t Weight2: [1.54133037]\t Bias: [40.18787388]\t Cost: 145.7919049629414\n",
            "Iteration: 2\t Weight1: [3.06999653]\t Weight2: [1.58178845]\t Bias: [40.05771]\t Cost: 144.76212126549987\n",
            "Iteration: 3\t Weight1: [3.08762187]\t Weight2: [1.60287313]\t Bias: [39.92212727]\t Cost: 143.80791293510268\n",
            "Iteration: 4\t Weight1: [3.10030345]\t Weight2: [1.62135602]\t Bias: [39.78628978]\t Cost: 142.8619975376422\n",
            "Iteration: 5\t Weight1: [3.11233376]\t Weight2: [1.63939718]\t Bias: [39.65086078]\t Cost: 141.9232059366094\n",
            "Iteration: 6\t Weight1: [3.12426551]\t Weight2: [1.65727529]\t Bias: [39.515924]\t Cost: 140.99146553541112\n",
            "Iteration: 7\t Weight1: [3.13616983]\t Weight2: [1.67502677]\t Bias: [39.38148855]\t Cost: 140.066722326879\n",
            "Iteration: 8\t Weight1: [3.1480559]\t Weight2: [1.69265683]\t Bias: [39.24755396]\t Cost: 139.1489230181872\n",
            "Iteration: 9\t Weight1: [3.15992487]\t Weight2: [1.71016668]\t Bias: [39.1141185]\t Cost: 138.2380147313462\n",
            "Iteration: 10\t Weight1: [3.17177689]\t Weight2: [1.72755699]\t Bias: [38.98118031]\t Cost: 137.33394499511732\n",
            "Iteration: 11\t Weight1: [3.18361197]\t Weight2: [1.74482839]\t Bias: [38.84873749]\t Cost: 136.4366617417815\n",
            "Iteration: 12\t Weight1: [3.19543009]\t Weight2: [1.76198146]\t Bias: [38.71678819]\t Cost: 135.54611330401397\n",
            "Iteration: 13\t Weight1: [3.20723125]\t Weight2: [1.7790168]\t Bias: [38.58533053]\t Cost: 134.66224841178365\n",
            "Iteration: 14\t Weight1: [3.21901544]\t Weight2: [1.79593502]\t Bias: [38.45436264]\t Cost: 133.78501618927731\n",
            "Iteration: 15\t Weight1: [3.23078265]\t Weight2: [1.81273669]\t Bias: [38.32388267]\t Cost: 132.9143661518473\n",
            "Iteration: 16\t Weight1: [3.24253286]\t Weight2: [1.82942242]\t Bias: [38.19388877]\t Cost: 132.0502482029833\n",
            "Iteration: 17\t Weight1: [3.25426608]\t Weight2: [1.84599278]\t Bias: [38.0643791]\t Cost: 131.19261263130718\n",
            "Iteration: 18\t Weight1: [3.26598228]\t Weight2: [1.86244836]\t Bias: [37.93535183]\t Cost: 130.34141010759197\n",
            "Iteration: 19\t Weight1: [3.27768147]\t Weight2: [1.87878974]\t Bias: [37.80680512]\t Cost: 129.49659168180298\n",
            "Iteration: 20\t Weight1: [3.28936362]\t Weight2: [1.89501749]\t Bias: [37.67873716]\t Cost: 128.65810878016316\n",
            "Iteration: 21\t Weight1: [3.30102875]\t Weight2: [1.9111322]\t Bias: [37.55114614]\t Cost: 127.82591320223996\n",
            "Iteration: 22\t Weight1: [3.31267682]\t Weight2: [1.92713443]\t Bias: [37.42403024]\t Cost: 126.99995711805619\n",
            "Iteration: 23\t Weight1: [3.32430785]\t Weight2: [1.94302476]\t Bias: [37.29738767]\t Cost: 126.18019306522224\n",
            "Iteration: 24\t Weight1: [3.33592181]\t Weight2: [1.95880375]\t Bias: [37.17121664]\t Cost: 125.36657394609136\n",
            "Iteration: 25\t Weight1: [3.34751871]\t Weight2: [1.97447197]\t Bias: [37.04551536]\t Cost: 124.55905302493655\n",
            "Iteration: 26\t Weight1: [3.35909853]\t Weight2: [1.99002999]\t Bias: [36.92028205]\t Cost: 123.75758392514958\n",
            "Iteration: 27\t Weight1: [3.37066126]\t Weight2: [2.00547835]\t Bias: [36.79551494]\t Cost: 122.96212062646221\n",
            "Iteration: 28\t Weight1: [3.38220691]\t Weight2: [2.02081762]\t Bias: [36.67121227]\t Cost: 122.17261746218819\n",
            "Iteration: 29\t Weight1: [3.39373547]\t Weight2: [2.03604835]\t Bias: [36.54737227]\t Cost: 121.3890291164873\n",
            "Iteration: 30\t Weight1: [3.40524692]\t Weight2: [2.0511711]\t Bias: [36.42399319]\t Cost: 120.61131062165079\n",
            "Iteration: 31\t Weight1: [3.41674126]\t Weight2: [2.06618641]\t Bias: [36.3010733]\t Cost: 119.8394173554071\n",
            "Iteration: 32\t Weight1: [3.42821849]\t Weight2: [2.08109484]\t Bias: [36.17861084]\t Cost: 119.07330503824963\n",
            "Iteration: 33\t Weight1: [3.43967859]\t Weight2: [2.09589692]\t Bias: [36.05660409]\t Cost: 118.31292973078448\n",
            "Iteration: 34\t Weight1: [3.45112158]\t Weight2: [2.11059321]\t Bias: [35.93505133]\t Cost: 117.55824783109912\n",
            "Iteration: 35\t Weight1: [3.46254743]\t Weight2: [2.12518423]\t Bias: [35.81395084]\t Cost: 116.80921607215144\n",
            "Iteration: 36\t Weight1: [3.47395614]\t Weight2: [2.13967053]\t Bias: [35.69330089]\t Cost: 116.06579151917929\n",
            "Iteration: 37\t Weight1: [3.48534771]\t Weight2: [2.15405265]\t Bias: [35.5730998]\t Cost: 115.32793156712995\n",
            "Iteration: 38\t Weight1: [3.49672214]\t Weight2: [2.16833111]\t Bias: [35.45334586]\t Cost: 114.5955939381092\n",
            "Iteration: 39\t Weight1: [3.50807941]\t Weight2: [2.18250645]\t Bias: [35.33403737]\t Cost: 113.86873667885155\n",
            "Iteration: 40\t Weight1: [3.51941953]\t Weight2: [2.19657919]\t Bias: [35.21517266]\t Cost: 113.14731815820838\n",
            "Iteration: 41\t Weight1: [3.53074249]\t Weight2: [2.21054986]\t Bias: [35.09675004]\t Cost: 112.43129706465704\n",
            "Iteration: 42\t Weight1: [3.54204829]\t Weight2: [2.22441898]\t Bias: [34.97876784]\t Cost: 111.72063240382846\n",
            "Iteration: 43\t Weight1: [3.55333692]\t Weight2: [2.23818708]\t Bias: [34.86122439]\t Cost: 111.01528349605435\n",
            "Iteration: 44\t Weight1: [3.56460838]\t Weight2: [2.25185467]\t Bias: [34.74411803]\t Cost: 110.31520997393356\n",
            "Iteration: 45\t Weight1: [3.57586266]\t Weight2: [2.26542226]\t Bias: [34.62744712]\t Cost: 109.62037177991672\n",
            "Iteration: 46\t Weight1: [3.58709977]\t Weight2: [2.27889038]\t Bias: [34.51121]\t Cost: 108.93072916391066\n",
            "Iteration: 47\t Weight1: [3.5983197]\t Weight2: [2.29225953]\t Bias: [34.39540503]\t Cost: 108.24624268090064\n",
            "Iteration: 48\t Weight1: [3.60952244]\t Weight2: [2.30553022]\t Bias: [34.28003057]\t Cost: 107.56687318859105\n",
            "Iteration: 49\t Weight1: [3.620708]\t Weight2: [2.31870296]\t Bias: [34.16508501]\t Cost: 106.89258184506531\n",
            "Iteration: 50\t Weight1: [3.63187638]\t Weight2: [2.33177825]\t Bias: [34.05056671]\t Cost: 106.22333010646302\n",
            "Iteration: 51\t Weight1: [3.64302756]\t Weight2: [2.3447566]\t Bias: [33.93647406]\t Cost: 105.55907972467541\n",
            "Iteration: 52\t Weight1: [3.65416155]\t Weight2: [2.3576385]\t Bias: [33.82280545]\t Cost: 104.89979274505905\n",
            "Iteration: 53\t Weight1: [3.66527835]\t Weight2: [2.37042446]\t Bias: [33.70955927]\t Cost: 104.24543150416702\n",
            "Iteration: 54\t Weight1: [3.67637795]\t Weight2: [2.38311496]\t Bias: [33.59673394]\t Cost: 103.59595862749757\n",
            "Iteration: 55\t Weight1: [3.68746036]\t Weight2: [2.3957105]\t Bias: [33.48432785]\t Cost: 102.9513370272607\n",
            "Iteration: 56\t Weight1: [3.69852557]\t Weight2: [2.40821158]\t Bias: [33.37233942]\t Cost: 102.31152990016201\n",
            "Iteration: 57\t Weight1: [3.70957358]\t Weight2: [2.42061867]\t Bias: [33.26076708]\t Cost: 101.67650072520303\n",
            "Iteration: 58\t Weight1: [3.72060439]\t Weight2: [2.43293227]\t Bias: [33.14960924]\t Cost: 101.04621326149994\n",
            "Iteration: 59\t Weight1: [3.731618]\t Weight2: [2.44515286]\t Bias: [33.03886435]\t Cost: 100.42063154611807\n",
            "Iteration: 60\t Weight1: [3.74261441]\t Weight2: [2.45728093]\t Bias: [32.92853084]\t Cost: 99.79971989192398\n",
            "Iteration: 61\t Weight1: [3.75359361]\t Weight2: [2.46931694]\t Bias: [32.81860715]\t Cost: 99.18344288545374\n",
            "Iteration: 62\t Weight1: [3.76455562]\t Weight2: [2.48126139]\t Bias: [32.70909175]\t Cost: 98.57176538479807\n",
            "Iteration: 63\t Weight1: [3.77550043]\t Weight2: [2.49311473]\t Bias: [32.59998307]\t Cost: 97.9646525175038\n",
            "Iteration: 64\t Weight1: [3.78642803]\t Weight2: [2.50487746]\t Bias: [32.49127959]\t Cost: 97.36206967849171\n",
            "Iteration: 65\t Weight1: [3.79733843]\t Weight2: [2.51655004]\t Bias: [32.38297977]\t Cost: 96.76398252799035\n",
            "Iteration: 66\t Weight1: [3.80823164]\t Weight2: [2.52813293]\t Bias: [32.2750821]\t Cost: 96.17035698948628\n",
            "Iteration: 67\t Weight1: [3.81910764]\t Weight2: [2.53962661]\t Bias: [32.16758504]\t Cost: 95.58115924768968\n",
            "Iteration: 68\t Weight1: [3.82996645]\t Weight2: [2.55103154]\t Bias: [32.06048708]\t Cost: 94.99635574651634\n",
            "Iteration: 69\t Weight1: [3.84080805]\t Weight2: [2.56234818]\t Bias: [31.95378673]\t Cost: 94.41591318708501\n",
            "Iteration: 70\t Weight1: [3.85163247]\t Weight2: [2.57357699]\t Bias: [31.84748246]\t Cost: 93.83979852573029\n",
            "Iteration: 71\t Weight1: [3.86243968]\t Weight2: [2.58471843]\t Bias: [31.7415728]\t Cost: 93.26797897203107\n",
            "Iteration: 72\t Weight1: [3.87322971]\t Weight2: [2.59577295]\t Bias: [31.63605624]\t Cost: 92.7004219868544\n",
            "Iteration: 73\t Weight1: [3.88400254]\t Weight2: [2.60674102]\t Bias: [31.5309313]\t Cost: 92.13709528041407\n",
            "Iteration: 74\t Weight1: [3.89475818]\t Weight2: [2.61762308]\t Bias: [31.4261965]\t Cost: 91.57796681034486\n",
            "Iteration: 75\t Weight1: [3.90549664]\t Weight2: [2.62841958]\t Bias: [31.32185037]\t Cost: 91.02300477979135\n",
            "Iteration: 76\t Weight1: [3.91621791]\t Weight2: [2.63913097]\t Bias: [31.21789144]\t Cost: 90.47217763551184\n",
            "Iteration: 77\t Weight1: [3.92692199]\t Weight2: [2.6497577]\t Bias: [31.11431825]\t Cost: 89.92545406599669\n",
            "Iteration: 78\t Weight1: [3.9376089]\t Weight2: [2.66030021]\t Bias: [31.01112933]\t Cost: 89.38280299960158\n",
            "Iteration: 79\t Weight1: [3.94827863]\t Weight2: [2.67075894]\t Bias: [30.90832325]\t Cost: 88.84419360269506\n",
            "Iteration: 80\t Weight1: [3.95893118]\t Weight2: [2.68113433]\t Bias: [30.80589854]\t Cost: 88.30959527782045\n",
            "Iteration: 81\t Weight1: [3.96956657]\t Weight2: [2.69142681]\t Bias: [30.70385378]\t Cost: 87.77897766187242\n",
            "Iteration: 82\t Weight1: [3.98018478]\t Weight2: [2.70163684]\t Bias: [30.60218752]\t Cost: 87.2523106242871\n",
            "Iteration: 83\t Weight1: [3.99078583]\t Weight2: [2.71176483]\t Bias: [30.50089834]\t Cost: 86.72956426524675\n",
            "Iteration: 84\t Weight1: [4.00136972]\t Weight2: [2.72181122]\t Bias: [30.39998482]\t Cost: 86.2107089138981\n",
            "Iteration: 85\t Weight1: [4.01193645]\t Weight2: [2.73177644]\t Bias: [30.29944553]\t Cost: 85.69571512658474\n",
            "Iteration: 86\t Weight1: [4.02248602]\t Weight2: [2.74166091]\t Bias: [30.19927906]\t Cost: 85.18455368509294\n",
            "Iteration: 87\t Weight1: [4.03301845]\t Weight2: [2.75146507]\t Bias: [30.099484]\t Cost: 84.67719559491124\n",
            "Iteration: 88\t Weight1: [4.04353373]\t Weight2: [2.76118934]\t Bias: [30.00005896]\t Cost: 84.17361208350391\n",
            "Iteration: 89\t Weight1: [4.05403186]\t Weight2: [2.77083413]\t Bias: [29.90100253]\t Cost: 83.67377459859702\n",
            "Iteration: 90\t Weight1: [4.06451286]\t Weight2: [2.78039987]\t Bias: [29.80231333]\t Cost: 83.17765480647847\n",
            "Iteration: 91\t Weight1: [4.07497673]\t Weight2: [2.78988698]\t Bias: [29.70398996]\t Cost: 82.685224590311\n",
            "Iteration: 92\t Weight1: [4.08542347]\t Weight2: [2.79929587]\t Bias: [29.60603105]\t Cost: 82.19645604845837\n",
            "Iteration: 93\t Weight1: [4.09585308]\t Weight2: [2.80862696]\t Bias: [29.50843522]\t Cost: 81.71132149282428\n",
            "Iteration: 94\t Weight1: [4.10626558]\t Weight2: [2.81788066]\t Bias: [29.4112011]\t Cost: 81.22979344720471\n",
            "Iteration: 95\t Weight1: [4.11666096]\t Weight2: [2.82705737]\t Bias: [29.31432733]\t Cost: 80.75184464565226\n",
            "Iteration: 96\t Weight1: [4.12703924]\t Weight2: [2.83615752]\t Bias: [29.21781254]\t Cost: 80.27744803085402\n",
            "Iteration: 97\t Weight1: [4.13740041]\t Weight2: [2.84518149]\t Bias: [29.12165538]\t Cost: 79.8065767525214\n",
            "Iteration: 98\t Weight1: [4.14774448]\t Weight2: [2.85412971]\t Bias: [29.0258545]\t Cost: 79.3392041657929\n",
            "Iteration: 99\t Weight1: [4.15807147]\t Weight2: [2.86300257]\t Bias: [28.93040855]\t Cost: 78.87530382964897\n",
            "Iteration: 100\t Weight1: [4.16838137]\t Weight2: [2.87180047]\t Bias: [28.83531621]\t Cost: 78.41484950533916\n",
            "Iteration: 101\t Weight1: [4.17867418]\t Weight2: [2.88052381]\t Bias: [28.74057613]\t Cost: 77.95781515482193\n",
            "Iteration: 102\t Weight1: [4.18894993]\t Weight2: [2.88917299]\t Bias: [28.64618698]\t Cost: 77.50417493921587\n",
            "Iteration: 103\t Weight1: [4.1992086]\t Weight2: [2.89774841]\t Bias: [28.55214744]\t Cost: 77.0539032172636\n",
            "Iteration: 104\t Weight1: [4.20945022]\t Weight2: [2.90625045]\t Bias: [28.45845619]\t Cost: 76.60697454380707\n",
            "Iteration: 105\t Weight1: [4.21967478]\t Weight2: [2.91467952]\t Bias: [28.36511192]\t Cost: 76.16336366827504\n",
            "Iteration: 106\t Weight1: [4.2298823]\t Weight2: [2.92303599]\t Bias: [28.27211332]\t Cost: 75.72304553318212\n",
            "Iteration: 107\t Weight1: [4.24007277]\t Weight2: [2.93132026]\t Bias: [28.17945908]\t Cost: 75.28599527263957\n",
            "Iteration: 108\t Weight1: [4.25024621]\t Weight2: [2.93953272]\t Bias: [28.08714791]\t Cost: 74.85218821087747\n",
            "Iteration: 109\t Weight1: [4.26040262]\t Weight2: [2.94767375]\t Bias: [27.9951785]\t Cost: 74.42159986077864\n",
            "Iteration: 110\t Weight1: [4.27054201]\t Weight2: [2.95574372]\t Bias: [27.90354959]\t Cost: 73.99420592242352\n",
            "Iteration: 111\t Weight1: [4.28066439]\t Weight2: [2.96374303]\t Bias: [27.81225987]\t Cost: 73.56998228164694\n",
            "Iteration: 112\t Weight1: [4.29076976]\t Weight2: [2.97167206]\t Bias: [27.72130807]\t Cost: 73.14890500860545\n",
            "Iteration: 113\t Weight1: [4.30085813]\t Weight2: [2.97953117]\t Bias: [27.63069291]\t Cost: 72.7309503563561\n",
            "Iteration: 114\t Weight1: [4.31092952]\t Weight2: [2.98732075]\t Bias: [27.54041314]\t Cost: 72.31609475944632\n",
            "Iteration: 115\t Weight1: [4.32098392]\t Weight2: [2.99504117]\t Bias: [27.45046747]\t Cost: 71.90431483251446\n",
            "Iteration: 116\t Weight1: [4.33102135]\t Weight2: [3.0026928]\t Bias: [27.36085466]\t Cost: 71.49558736890143\n",
            "Iteration: 117\t Weight1: [4.34104181]\t Weight2: [3.01027601]\t Bias: [27.27157344]\t Cost: 71.08988933927301\n",
            "Iteration: 118\t Weight1: [4.35104531]\t Weight2: [3.01779117]\t Bias: [27.18262257]\t Cost: 70.68719789025283\n",
            "Iteration: 119\t Weight1: [4.36103186]\t Weight2: [3.02523866]\t Bias: [27.0940008]\t Cost: 70.28749034306603\n",
            "Iteration: 120\t Weight1: [4.37100147]\t Weight2: [3.03261882]\t Bias: [27.00570689]\t Cost: 69.89074419219313\n",
            "Iteration: 121\t Weight1: [4.38095415]\t Weight2: [3.03993204]\t Bias: [26.91773961]\t Cost: 69.49693710403504\n",
            "Iteration: 122\t Weight1: [4.3908899]\t Weight2: [3.04717866]\t Bias: [26.83009773]\t Cost: 69.10604691558765\n",
            "Iteration: 123\t Weight1: [4.40080874]\t Weight2: [3.05435906]\t Bias: [26.74278001]\t Cost: 68.71805163312709\n",
            "Iteration: 124\t Weight1: [4.41071067]\t Weight2: [3.06147358]\t Bias: [26.65578523]\t Cost: 68.33292943090515\n",
            "Iteration: 125\t Weight1: [4.4205957]\t Weight2: [3.0685226]\t Bias: [26.56911219]\t Cost: 67.95065864985477\n",
            "Iteration: 126\t Weight1: [4.43046384]\t Weight2: [3.07550645]\t Bias: [26.48275966]\t Cost: 67.57121779630572\n",
            "Iteration: 127\t Weight1: [4.4403151]\t Weight2: [3.0824255]\t Bias: [26.39672645]\t Cost: 67.19458554070975\n",
            "Iteration: 128\t Weight1: [4.4501495]\t Weight2: [3.08928009]\t Bias: [26.31101134]\t Cost: 66.82074071637643\n",
            "Iteration: 129\t Weight1: [4.45996703]\t Weight2: [3.09607058]\t Bias: [26.22561313]\t Cost: 66.44966231821803\n",
            "Iteration: 130\t Weight1: [4.46976771]\t Weight2: [3.10279732]\t Bias: [26.14053064]\t Cost: 66.08132950150454\n",
            "Iteration: 131\t Weight1: [4.47955154]\t Weight2: [3.10946066]\t Bias: [26.05576268]\t Cost: 65.7157215806283\n",
            "Iteration: 132\t Weight1: [4.48931855]\t Weight2: [3.11606093]\t Bias: [25.97130805]\t Cost: 65.35281802787799\n",
            "Iteration: 133\t Weight1: [4.49906873]\t Weight2: [3.12259848]\t Bias: [25.88716559]\t Cost: 64.99259847222247\n",
            "Iteration: 134\t Weight1: [4.5088021]\t Weight2: [3.12907367]\t Bias: [25.8033341]\t Cost: 64.63504269810379\n",
            "Iteration: 135\t Weight1: [4.51851867]\t Weight2: [3.13548681]\t Bias: [25.71981243]\t Cost: 64.2801306442396\n",
            "Iteration: 136\t Weight1: [4.52821845]\t Weight2: [3.14183827]\t Bias: [25.6365994]\t Cost: 63.9278424024349\n",
            "Iteration: 137\t Weight1: [4.53790144]\t Weight2: [3.14812837]\t Bias: [25.55369386]\t Cost: 63.57815821640302\n",
            "Iteration: 138\t Weight1: [4.54756767]\t Weight2: [3.15435744]\t Bias: [25.47109464]\t Cost: 63.23105848059555\n",
            "Iteration: 139\t Weight1: [4.55721713]\t Weight2: [3.16052584]\t Bias: [25.3888006]\t Cost: 62.88652373904174\n",
            "Iteration: 140\t Weight1: [4.56684984]\t Weight2: [3.16663387]\t Bias: [25.30681057]\t Cost: 62.544534684196364\n",
            "Iteration: 141\t Weight1: [4.57646581]\t Weight2: [3.17268189]\t Bias: [25.22512342]\t Cost: 62.205072155796934\n",
            "Iteration: 142\t Weight1: [4.58606505]\t Weight2: [3.17867021]\t Bias: [25.14373801]\t Cost: 61.86811713972966\n",
            "Iteration: 143\t Weight1: [4.59564758]\t Weight2: [3.18459917]\t Bias: [25.0626532]\t Cost: 61.53365076690403\n",
            "Iteration: 144\t Weight1: [4.6052134]\t Weight2: [3.1904691]\t Bias: [24.98186786]\t Cost: 61.20165431213635\n",
            "Iteration: 145\t Weight1: [4.61476252]\t Weight2: [3.19628031]\t Bias: [24.90138086]\t Cost: 60.872109193041766\n",
            "Iteration: 146\t Weight1: [4.62429496]\t Weight2: [3.20203313]\t Bias: [24.82119108]\t Cost: 60.544996968935045\n",
            "Iteration: 147\t Weight1: [4.63381072]\t Weight2: [3.20772789]\t Bias: [24.7412974]\t Cost: 60.220299339739626\n",
            "Iteration: 148\t Weight1: [4.64330983]\t Weight2: [3.2133649]\t Bias: [24.66169871]\t Cost: 59.89799814490536\n",
            "Iteration: 149\t Weight1: [4.65279228]\t Weight2: [3.21894449]\t Bias: [24.58239389]\t Cost: 59.57807536233445\n",
            "Iteration: 150\t Weight1: [4.66225809]\t Weight2: [3.22446696]\t Bias: [24.50338184]\t Cost: 59.260513107315944\n",
            "Iteration: 151\t Weight1: [4.67170728]\t Weight2: [3.22993265]\t Bias: [24.42466146]\t Cost: 58.9452936314682\n",
            "Iteration: 152\t Weight1: [4.68113985]\t Weight2: [3.23534185]\t Bias: [24.34623165]\t Cost: 58.63239932168973\n",
            "Iteration: 153\t Weight1: [4.69055582]\t Weight2: [3.2406949]\t Bias: [24.26809132]\t Cost: 58.32181269911823\n",
            "Iteration: 154\t Weight1: [4.69995519]\t Weight2: [3.24599209]\t Bias: [24.19023937]\t Cost: 58.01351641809732\n",
            "Iteration: 155\t Weight1: [4.70933799]\t Weight2: [3.25123373]\t Bias: [24.11267472]\t Cost: 57.70749326515184\n",
            "Iteration: 156\t Weight1: [4.71870422]\t Weight2: [3.25642015]\t Bias: [24.0353963]\t Cost: 57.403726157970546\n",
            "Iteration: 157\t Weight1: [4.72805389]\t Weight2: [3.26155164]\t Bias: [23.95840302]\t Cost: 57.102198144397136\n",
            "Iteration: 158\t Weight1: [4.73738702]\t Weight2: [3.2666285]\t Bias: [23.88169382]\t Cost: 56.80289240142862\n",
            "Iteration: 159\t Weight1: [4.74670362]\t Weight2: [3.27165105]\t Bias: [23.80526761]\t Cost: 56.50579223422193\n",
            "Iteration: 160\t Weight1: [4.75600371]\t Weight2: [3.27661959]\t Bias: [23.72912335]\t Cost: 56.21088107510795\n",
            "Iteration: 161\t Weight1: [4.76528729]\t Weight2: [3.28153442]\t Bias: [23.65325996]\t Cost: 55.918142482613106\n",
            "Iteration: 162\t Weight1: [4.77455437]\t Weight2: [3.28639584]\t Bias: [23.5776764]\t Cost: 55.62756014048885\n",
            "Iteration: 163\t Weight1: [4.78380498]\t Weight2: [3.29120414]\t Bias: [23.5023716]\t Cost: 55.33911785674836\n",
            "Iteration: 164\t Weight1: [4.79303911]\t Weight2: [3.29595963]\t Bias: [23.42734453]\t Cost: 55.05279956271073\n",
            "Iteration: 165\t Weight1: [4.8022568]\t Weight2: [3.3006626]\t Bias: [23.35259413]\t Cost: 54.76858931205289\n",
            "Iteration: 166\t Weight1: [4.81145804]\t Weight2: [3.30531335]\t Bias: [23.27811937]\t Cost: 54.486471279868354\n",
            "Iteration: 167\t Weight1: [4.82064286]\t Weight2: [3.30991216]\t Bias: [23.20391921]\t Cost: 54.20642976173373\n",
            "Iteration: 168\t Weight1: [4.82981126]\t Weight2: [3.31445934]\t Bias: [23.12999261]\t Cost: 53.92844917278209\n",
            "Iteration: 169\t Weight1: [4.83896325]\t Weight2: [3.31895517]\t Bias: [23.05633856]\t Cost: 53.652514046783764\n",
            "Iteration: 170\t Weight1: [4.84809886]\t Weight2: [3.32339993]\t Bias: [22.98295602]\t Cost: 53.378609035234156\n",
            "Iteration: 171\t Weight1: [4.8572181]\t Weight2: [3.32779393]\t Bias: [22.90984397]\t Cost: 53.10671890644856\n",
            "Iteration: 172\t Weight1: [4.86632097]\t Weight2: [3.33213744]\t Bias: [22.8370014]\t Cost: 52.836828544664215\n",
            "Iteration: 173\t Weight1: [4.8754075]\t Weight2: [3.33643075]\t Bias: [22.76442729]\t Cost: 52.568922949148956\n",
            "Iteration: 174\t Weight1: [4.88447769]\t Weight2: [3.34067415]\t Bias: [22.69212064]\t Cost: 52.30298723331698\n",
            "Iteration: 175\t Weight1: [4.89353157]\t Weight2: [3.34486791]\t Bias: [22.62008044]\t Cost: 52.03900662385164\n",
            "Iteration: 176\t Weight1: [4.90256913]\t Weight2: [3.34901231]\t Bias: [22.54830568]\t Cost: 51.77696645983457\n",
            "Iteration: 177\t Weight1: [4.91159041]\t Weight2: [3.35310765]\t Bias: [22.47679538]\t Cost: 51.51685219188189\n",
            "Iteration: 178\t Weight1: [4.9205954]\t Weight2: [3.35715418]\t Bias: [22.40554853]\t Cost: 51.25864938128715\n",
            "Iteration: 179\t Weight1: [4.92958413]\t Weight2: [3.3611522]\t Bias: [22.33456415]\t Cost: 51.00234369917054\n",
            "Iteration: 180\t Weight1: [4.93855661]\t Weight2: [3.36510198]\t Bias: [22.26384125]\t Cost: 50.74792092563509\n",
            "Iteration: 181\t Weight1: [4.94751285]\t Weight2: [3.36900379]\t Bias: [22.19337885]\t Cost: 50.4953669489291\n",
            "Iteration: 182\t Weight1: [4.95645288]\t Weight2: [3.3728579]\t Bias: [22.12317597]\t Cost: 50.244667764615315\n",
            "Iteration: 183\t Weight1: [4.96537669]\t Weight2: [3.37666459]\t Bias: [22.05323163]\t Cost: 49.99580947474616\n",
            "Iteration: 184\t Weight1: [4.97428431]\t Weight2: [3.38042412]\t Bias: [21.98354487]\t Cost: 49.748778287045894\n",
            "Iteration: 185\t Weight1: [4.98317575]\t Weight2: [3.38413678]\t Bias: [21.91411471]\t Cost: 49.503560514098545\n",
            "Iteration: 186\t Weight1: [4.99205103]\t Weight2: [3.38780281]\t Bias: [21.84494019]\t Cost: 49.26014257254246\n",
            "Iteration: 187\t Weight1: [5.00091016]\t Weight2: [3.3914225]\t Bias: [21.77602036]\t Cost: 49.01851098227098\n",
            "Iteration: 188\t Weight1: [5.00975315]\t Weight2: [3.39499611]\t Bias: [21.70735425]\t Cost: 48.77865236563937\n",
            "Iteration: 189\t Weight1: [5.01858003]\t Weight2: [3.39852389]\t Bias: [21.63894091]\t Cost: 48.54055344667774\n",
            "Iteration: 190\t Weight1: [5.0273908]\t Weight2: [3.40200612]\t Bias: [21.57077939]\t Cost: 48.30420105031017\n",
            "Iteration: 191\t Weight1: [5.03618548]\t Weight2: [3.40544305]\t Bias: [21.50286876]\t Cost: 48.06958210157991\n",
            "Iteration: 192\t Weight1: [5.04496408]\t Weight2: [3.40883495]\t Bias: [21.43520805]\t Cost: 47.83668362488052\n",
            "Iteration: 193\t Weight1: [5.05372662]\t Weight2: [3.41218208]\t Bias: [21.36779635]\t Cost: 47.60549274319282\n",
            "Iteration: 194\t Weight1: [5.06247312]\t Weight2: [3.41548469]\t Bias: [21.3006327]\t Cost: 47.37599667732801\n",
            "Iteration: 195\t Weight1: [5.07120359]\t Weight2: [3.41874303]\t Bias: [21.23371619]\t Cost: 47.14818274517651\n",
            "Iteration: 196\t Weight1: [5.07991804]\t Weight2: [3.42195738]\t Bias: [21.16704588]\t Cost: 46.92203836096252\n",
            "Iteration: 197\t Weight1: [5.08861649]\t Weight2: [3.42512797]\t Bias: [21.10062084]\t Cost: 46.69755103450453\n",
            "Iteration: 198\t Weight1: [5.09729896]\t Weight2: [3.42825506]\t Bias: [21.03444017]\t Cost: 46.47470837048137\n",
            "Iteration: 199\t Weight1: [5.10596546]\t Weight2: [3.43133891]\t Bias: [20.96850293]\t Cost: 46.253498067704086\n",
            "Iteration: 200\t Weight1: [5.11461601]\t Weight2: [3.43437976]\t Bias: [20.90280823]\t Cost: 46.03390791839341\n",
            "Iteration: 201\t Weight1: [5.12325062]\t Weight2: [3.43737787]\t Bias: [20.83735513]\t Cost: 45.81592580746266\n",
            "Iteration: 202\t Weight1: [5.13186931]\t Weight2: [3.44033348]\t Bias: [20.77214275]\t Cost: 45.599539711806436\n",
            "Iteration: 203\t Weight1: [5.14047209]\t Weight2: [3.44324684]\t Bias: [20.70717018]\t Cost: 45.38473769959462\n",
            "Iteration: 204\t Weight1: [5.14905898]\t Weight2: [3.44611819]\t Bias: [20.64243651]\t Cost: 45.17150792957212\n",
            "Iteration: 205\t Weight1: [5.15763]\t Weight2: [3.44894779]\t Bias: [20.57794085]\t Cost: 44.95983865036345\n",
            "Iteration: 206\t Weight1: [5.16618515]\t Weight2: [3.45173587]\t Bias: [20.51368231]\t Cost: 44.74971819978336\n",
            "Iteration: 207\t Weight1: [5.17472447]\t Weight2: [3.45448268]\t Bias: [20.44966]\t Cost: 44.54113500415234\n",
            "Iteration: 208\t Weight1: [5.18324795]\t Weight2: [3.45718845]\t Bias: [20.38587303]\t Cost: 44.334077577617684\n",
            "Iteration: 209\t Weight1: [5.19175563]\t Weight2: [3.45985343]\t Bias: [20.32232051]\t Cost: 44.12853452147956\n",
            "Iteration: 210\t Weight1: [5.20024751]\t Weight2: [3.46247786]\t Bias: [20.25900158]\t Cost: 43.924494523522505\n",
            "Iteration: 211\t Weight1: [5.20872361]\t Weight2: [3.46506197]\t Bias: [20.19591535]\t Cost: 43.72194635735199\n",
            "Iteration: 212\t Weight1: [5.21718395]\t Weight2: [3.467606]\t Bias: [20.13306095]\t Cost: 43.520878881736074\n",
            "Iteration: 213\t Weight1: [5.22562855]\t Weight2: [3.47011019]\t Bias: [20.07043751]\t Cost: 43.32128103995223\n",
            "Iteration: 214\t Weight1: [5.23405741]\t Weight2: [3.47257478]\t Bias: [20.00804416]\t Cost: 43.12314185913921\n",
            "Iteration: 215\t Weight1: [5.24247056]\t Weight2: [3.47499998]\t Bias: [19.94588004]\t Cost: 42.92645044965379\n",
            "Iteration: 216\t Weight1: [5.25086801]\t Weight2: [3.47738604]\t Bias: [19.8839443]\t Cost: 42.7311960044328\n",
            "Iteration: 217\t Weight1: [5.25924978]\t Weight2: [3.47973319]\t Bias: [19.82223607]\t Cost: 42.5373677983596\n",
            "Iteration: 218\t Weight1: [5.26761589]\t Weight2: [3.48204166]\t Bias: [19.76075451]\t Cost: 42.34495518763599\n",
            "Iteration: 219\t Weight1: [5.27596635]\t Weight2: [3.48431167]\t Bias: [19.69949875]\t Cost: 42.153947609158465\n",
            "Iteration: 220\t Weight1: [5.28430118]\t Weight2: [3.48654346]\t Bias: [19.63846797]\t Cost: 41.964334579899784\n",
            "Iteration: 221\t Weight1: [5.29262039]\t Weight2: [3.48873724]\t Bias: [19.5776613]\t Cost: 41.77610569629483\n",
            "Iteration: 222\t Weight1: [5.30092401]\t Weight2: [3.49089326]\t Bias: [19.51707792]\t Cost: 41.58925063363166\n",
            "Iteration: 223\t Weight1: [5.30921204]\t Weight2: [3.49301172]\t Bias: [19.45671698]\t Cost: 41.4037591454469\n",
            "Iteration: 224\t Weight1: [5.31748451]\t Weight2: [3.49509286]\t Bias: [19.39657766]\t Cost: 41.219621062926066\n",
            "Iteration: 225\t Weight1: [5.32574144]\t Weight2: [3.49713689]\t Bias: [19.33665911]\t Cost: 41.036826294308355\n",
            "Iteration: 226\t Weight1: [5.33398283]\t Weight2: [3.49914404]\t Bias: [19.27696052]\t Cost: 40.855364824296146\n",
            "Iteration: 227\t Weight1: [5.34220871]\t Weight2: [3.50111453]\t Bias: [19.21748106]\t Cost: 40.675226713468945\n",
            "Iteration: 228\t Weight1: [5.3504191]\t Weight2: [3.50304858]\t Bias: [19.15821991]\t Cost: 40.496402097702024\n",
            "Iteration: 229\t Weight1: [5.358614]\t Weight2: [3.5049464]\t Bias: [19.09917624]\t Cost: 40.318881187589334\n",
            "Iteration: 230\t Weight1: [5.36679345]\t Weight2: [3.50680821]\t Bias: [19.04034925]\t Cost: 40.14265426787112\n",
            "Iteration: 231\t Weight1: [5.37495745]\t Weight2: [3.50863423]\t Bias: [18.98173813]\t Cost: 39.967711696865685\n",
            "Iteration: 232\t Weight1: [5.38310602]\t Weight2: [3.51042467]\t Bias: [18.92334206]\t Cost: 39.79404390590586\n",
            "Iteration: 233\t Weight1: [5.39123918]\t Weight2: [3.51217975]\t Bias: [18.86516024]\t Cost: 39.621641398779495\n",
            "Iteration: 234\t Weight1: [5.39935695]\t Weight2: [3.51389968]\t Bias: [18.80719186]\t Cost: 39.4504947511745\n",
            "Iteration: 235\t Weight1: [5.40745934]\t Weight2: [3.51558466]\t Bias: [18.74943613]\t Cost: 39.28059461012816\n",
            "Iteration: 236\t Weight1: [5.41554637]\t Weight2: [3.51723492]\t Bias: [18.69189226]\t Cost: 39.1119316934805\n",
            "Iteration: 237\t Weight1: [5.42361807]\t Weight2: [3.51885067]\t Bias: [18.63455944]\t Cost: 38.94449678933216\n",
            "Iteration: 238\t Weight1: [5.43167444]\t Weight2: [3.5204321]\t Bias: [18.57743688]\t Cost: 38.77828075550623\n",
            "Iteration: 239\t Weight1: [5.4397155]\t Weight2: [3.52197943]\t Bias: [18.52052381]\t Cost: 38.61327451901435\n",
            "Iteration: 240\t Weight1: [5.44774128]\t Weight2: [3.52349286]\t Bias: [18.46381942]\t Cost: 38.449469075526856\n",
            "Iteration: 241\t Weight1: [5.45575178]\t Weight2: [3.52497261]\t Bias: [18.40732296]\t Cost: 38.28685548884712\n",
            "Iteration: 242\t Weight1: [5.46374703]\t Weight2: [3.52641887]\t Bias: [18.35103362]\t Cost: 38.1254248903899\n",
            "Iteration: 243\t Weight1: [5.47172705]\t Weight2: [3.52783185]\t Bias: [18.29495065]\t Cost: 37.96516847866365\n",
            "Iteration: 244\t Weight1: [5.47969185]\t Weight2: [3.52921175]\t Bias: [18.23907326]\t Cost: 37.80607751875694\n",
            "Iteration: 245\t Weight1: [5.48764145]\t Weight2: [3.53055877]\t Bias: [18.18340069]\t Cost: 37.64814334182875\n",
            "Iteration: 246\t Weight1: [5.49557587]\t Weight2: [3.53187312]\t Bias: [18.12793216]\t Cost: 37.49135734460277\n",
            "Iteration: 247\t Weight1: [5.50349512]\t Weight2: [3.53315499]\t Bias: [18.07266693]\t Cost: 37.335710988865486\n",
            "Iteration: 248\t Weight1: [5.51139923]\t Weight2: [3.53440459]\t Bias: [18.01760422]\t Cost: 37.18119580096836\n",
            "Iteration: 249\t Weight1: [5.51928821]\t Weight2: [3.5356221]\t Bias: [17.96274327]\t Cost: 37.0278033713336\n",
            "Iteration: 250\t Weight1: [5.52716207]\t Weight2: [3.53680773]\t Bias: [17.90808334]\t Cost: 36.87552535396384\n",
            "Iteration: 251\t Weight1: [5.53502085]\t Weight2: [3.53796168]\t Bias: [17.85362367]\t Cost: 36.72435346595572\n",
            "Iteration: 252\t Weight1: [5.54286455]\t Weight2: [3.53908414]\t Bias: [17.79936351]\t Cost: 36.574279487017094\n",
            "Iteration: 253\t Weight1: [5.5506932]\t Weight2: [3.54017529]\t Bias: [17.74530211]\t Cost: 36.42529525898792\n",
            "Iteration: 254\t Weight1: [5.5585068]\t Weight2: [3.54123535]\t Bias: [17.69143873]\t Cost: 36.27739268536497\n",
            "Iteration: 255\t Weight1: [5.56630539]\t Weight2: [3.54226449]\t Bias: [17.63777264]\t Cost: 36.13056373083014\n",
            "Iteration: 256\t Weight1: [5.57408898]\t Weight2: [3.54326291]\t Bias: [17.58430308]\t Cost: 35.98480042078248\n",
            "Iteration: 257\t Weight1: [5.58185758]\t Weight2: [3.54423079]\t Bias: [17.53102933]\t Cost: 35.840094840873604\n",
            "Iteration: 258\t Weight1: [5.58961122]\t Weight2: [3.54516834]\t Bias: [17.47795065]\t Cost: 35.696439136547056\n",
            "Iteration: 259\t Weight1: [5.59734991]\t Weight2: [3.54607573]\t Bias: [17.42506631]\t Cost: 35.55382551258081\n",
            "Iteration: 260\t Weight1: [5.60507367]\t Weight2: [3.54695316]\t Bias: [17.3723756]\t Cost: 35.412246232633706\n",
            "Iteration: 261\t Weight1: [5.61278252]\t Weight2: [3.54780081]\t Bias: [17.31987777]\t Cost: 35.27169361879501\n",
            "Iteration: 262\t Weight1: [5.62047648]\t Weight2: [3.54861887]\t Bias: [17.26757212]\t Cost: 35.13216005113778\n",
            "Iteration: 263\t Weight1: [5.62815556]\t Weight2: [3.54940752]\t Bias: [17.21545792]\t Cost: 34.99363796727544\n",
            "Iteration: 264\t Weight1: [5.63581979]\t Weight2: [3.55016694]\t Bias: [17.16353445]\t Cost: 34.856119861921854\n",
            "Iteration: 265\t Weight1: [5.64346918]\t Weight2: [3.55089732]\t Bias: [17.11180101]\t Cost: 34.719598286454804\n",
            "Iteration: 266\t Weight1: [5.65110376]\t Weight2: [3.55159884]\t Bias: [17.06025688]\t Cost: 34.5840658484829\n",
            "Iteration: 267\t Weight1: [5.65872354]\t Weight2: [3.55227168]\t Bias: [17.00890136]\t Cost: 34.44951521141559\n",
            "Iteration: 268\t Weight1: [5.66632853]\t Weight2: [3.55291603]\t Bias: [16.95773374]\t Cost: 34.31593909403682\n",
            "Iteration: 269\t Weight1: [5.67391876]\t Weight2: [3.55353205]\t Bias: [16.90675331]\t Cost: 34.183330270081754\n",
            "Iteration: 270\t Weight1: [5.68149425]\t Weight2: [3.55411994]\t Bias: [16.85595938]\t Cost: 34.051681567816786\n",
            "Iteration: 271\t Weight1: [5.68905502]\t Weight2: [3.55467986]\t Bias: [16.80535125]\t Cost: 33.920985869622854\n",
            "Iteration: 272\t Weight1: [5.69660107]\t Weight2: [3.555212]\t Bias: [16.75492823]\t Cost: 33.791236111581924\n",
            "Iteration: 273\t Weight1: [5.70413244]\t Weight2: [3.55571652]\t Bias: [16.70468962]\t Cost: 33.66242528306666\n",
            "Iteration: 274\t Weight1: [5.71164914]\t Weight2: [3.55619361]\t Bias: [16.65463474]\t Cost: 33.53454642633327\n",
            "Iteration: 275\t Weight1: [5.71915119]\t Weight2: [3.55664345]\t Bias: [16.6047629]\t Cost: 33.407592636117506\n",
            "Iteration: 276\t Weight1: [5.72663861]\t Weight2: [3.55706619]\t Bias: [16.55507341]\t Cost: 33.28155705923375\n",
            "Iteration: 277\t Weight1: [5.73411142]\t Weight2: [3.55746202]\t Bias: [16.50556559]\t Cost: 33.1564328941772\n",
            "Iteration: 278\t Weight1: [5.74156963]\t Weight2: [3.5578311]\t Bias: [16.45623877]\t Cost: 33.03221339072909\n",
            "Iteration: 279\t Weight1: [5.74901327]\t Weight2: [3.55817361]\t Bias: [16.40709226]\t Cost: 32.90889184956512\n",
            "Iteration: 280\t Weight1: [5.75644235]\t Weight2: [3.55848972]\t Bias: [16.3581254]\t Cost: 32.78646162186656\n",
            "Iteration: 281\t Weight1: [5.7638569]\t Weight2: [3.55877959]\t Bias: [16.30933752]\t Cost: 32.66491610893469\n",
            "Iteration: 282\t Weight1: [5.77125693]\t Weight2: [3.5590434]\t Bias: [16.26072794]\t Cost: 32.544248761808085\n",
            "Iteration: 283\t Weight1: [5.77864246]\t Weight2: [3.55928131]\t Bias: [16.21229599]\t Cost: 32.42445308088284\n",
            "Iteration: 284\t Weight1: [5.78601351]\t Weight2: [3.55949349]\t Bias: [16.16404102]\t Cost: 32.30552261553559\n",
            "Iteration: 285\t Weight1: [5.79337009]\t Weight2: [3.55968011]\t Bias: [16.11596237]\t Cost: 32.18745096374985\n",
            "Iteration: 286\t Weight1: [5.80071224]\t Weight2: [3.55984132]\t Bias: [16.06805937]\t Cost: 32.07023177174467\n",
            "Iteration: 287\t Weight1: [5.80803997]\t Weight2: [3.5599773]\t Bias: [16.02033137]\t Cost: 31.953858733606555\n",
            "Iteration: 288\t Weight1: [5.81535329]\t Weight2: [3.5600882]\t Bias: [15.97277772]\t Cost: 31.838325590924207\n",
            "Iteration: 289\t Weight1: [5.82265222]\t Weight2: [3.56017419]\t Bias: [15.92539776]\t Cost: 31.723626132425753\n",
            "Iteration: 290\t Weight1: [5.82993679]\t Weight2: [3.56023543]\t Bias: [15.87819086]\t Cost: 31.609754193619093\n",
            "Iteration: 291\t Weight1: [5.83720702]\t Weight2: [3.56027209]\t Bias: [15.83115635]\t Cost: 31.49670365643508\n",
            "Iteration: 292\t Weight1: [5.84446291]\t Weight2: [3.56028432]\t Bias: [15.78429359]\t Cost: 31.38446844887296\n",
            "Iteration: 293\t Weight1: [5.8517045]\t Weight2: [3.56027227]\t Bias: [15.73760196]\t Cost: 31.273042544649076\n",
            "Iteration: 294\t Weight1: [5.8589318]\t Weight2: [3.56023612]\t Bias: [15.6910808]\t Cost: 31.162419962848073\n",
            "Iteration: 295\t Weight1: [5.86614483]\t Weight2: [3.56017601]\t Bias: [15.64472948]\t Cost: 31.05259476757668\n",
            "Iteration: 296\t Weight1: [5.87334362]\t Weight2: [3.56009211]\t Bias: [15.59854737]\t Cost: 30.943561067620333\n",
            "Iteration: 297\t Weight1: [5.88052817]\t Weight2: [3.55998457]\t Bias: [15.55253384]\t Cost: 30.83531301610235\n",
            "Iteration: 298\t Weight1: [5.88769851]\t Weight2: [3.55985355]\t Bias: [15.50668825]\t Cost: 30.727844810145722\n",
            "Iteration: 299\t Weight1: [5.89485465]\t Weight2: [3.55969919]\t Bias: [15.46100998]\t Cost: 30.621150690537597\n",
            "Iteration: 300\t Weight1: [5.90199663]\t Weight2: [3.55952166]\t Bias: [15.41549841]\t Cost: 30.51522494139622\n",
            "Iteration: 301\t Weight1: [5.90912445]\t Weight2: [3.55932111]\t Bias: [15.37015291]\t Cost: 30.41006188984056\n",
            "Iteration: 302\t Weight1: [5.91623814]\t Weight2: [3.55909768]\t Bias: [15.32497286]\t Cost: 30.305655905662384\n",
            "Iteration: 303\t Weight1: [5.92333771]\t Weight2: [3.55885154]\t Bias: [15.27995765]\t Cost: 30.202001401000903\n",
            "Iteration: 304\t Weight1: [5.93042319]\t Weight2: [3.55858283]\t Bias: [15.23510667]\t Cost: 30.0990928300199\n",
            "Iteration: 305\t Weight1: [5.93749459]\t Weight2: [3.5582917]\t Bias: [15.19041929]\t Cost: 29.99692468858742\n",
            "Iteration: 306\t Weight1: [5.94455194]\t Weight2: [3.5579783]\t Bias: [15.14589491]\t Cost: 29.895491513957808\n",
            "Iteration: 307\t Weight1: [5.95159525]\t Weight2: [3.55764278]\t Bias: [15.10153292]\t Cost: 29.794787884456237\n",
            "Iteration: 308\t Weight1: [5.95862454]\t Weight2: [3.55728529]\t Bias: [15.05733272]\t Cost: 29.694808419165685\n",
            "Iteration: 309\t Weight1: [5.96563984]\t Weight2: [3.55690598]\t Bias: [15.01329369]\t Cost: 29.595547777616375\n",
            "Iteration: 310\t Weight1: [5.97264116]\t Weight2: [3.55650498]\t Bias: [14.96941525]\t Cost: 29.49700065947743\n",
            "Iteration: 311\t Weight1: [5.97962851]\t Weight2: [3.55608245]\t Bias: [14.9256968]\t Cost: 29.399161804251115\n",
            "Iteration: 312\t Weight1: [5.98660193]\t Weight2: [3.55563854]\t Bias: [14.88213772]\t Cost: 29.302025990969284\n",
            "Iteration: 313\t Weight1: [5.99356143]\t Weight2: [3.55517338]\t Bias: [14.83873744]\t Cost: 29.20558803789216\n",
            "Iteration: 314\t Weight1: [6.00050703]\t Weight2: [3.55468711]\t Bias: [14.79549536]\t Cost: 29.109842802209577\n",
            "Iteration: 315\t Weight1: [6.00743875]\t Weight2: [3.55417989]\t Bias: [14.75241089]\t Cost: 29.014785179744337\n",
            "Iteration: 316\t Weight1: [6.01435661]\t Weight2: [3.55365186]\t Bias: [14.70948343]\t Cost: 28.920410104657993\n",
            "Iteration: 317\t Weight1: [6.02126063]\t Weight2: [3.55310315]\t Bias: [14.66671242]\t Cost: 28.82671254915878\n",
            "Iteration: 318\t Weight1: [6.02815083]\t Weight2: [3.5525339]\t Bias: [14.62409726]\t Cost: 28.733687523211938\n",
            "Iteration: 319\t Weight1: [6.03502723]\t Weight2: [3.55194426]\t Bias: [14.58163737]\t Cost: 28.641330074252057\n",
            "Iteration: 320\t Weight1: [6.04188984]\t Weight2: [3.55133436]\t Bias: [14.53933218]\t Cost: 28.549635286897825\n",
            "Iteration: 321\t Weight1: [6.04873869]\t Weight2: [3.55070435]\t Bias: [14.4971811]\t Cost: 28.45859828266894\n",
            "Iteration: 322\t Weight1: [6.0555738]\t Weight2: [3.55005435]\t Bias: [14.45518357]\t Cost: 28.368214219704985\n",
            "Iteration: 323\t Weight1: [6.06239519]\t Weight2: [3.54938452]\t Bias: [14.41333901]\t Cost: 28.2784782924869\n",
            "Iteration: 324\t Weight1: [6.06920287]\t Weight2: [3.54869498]\t Bias: [14.37164685]\t Cost: 28.189385731560023\n",
            "Iteration: 325\t Weight1: [6.07599687]\t Weight2: [3.54798586]\t Bias: [14.33010653]\t Cost: 28.10093180325984\n",
            "Iteration: 326\t Weight1: [6.0827772]\t Weight2: [3.54725732]\t Bias: [14.28871747]\t Cost: 28.0131118094394\n",
            "Iteration: 327\t Weight1: [6.0895439]\t Weight2: [3.54650947]\t Bias: [14.24747911]\t Cost: 27.925921087199068\n",
            "Iteration: 328\t Weight1: [6.09629696]\t Weight2: [3.54574245]\t Bias: [14.2063909]\t Cost: 27.839355008618295\n",
            "Iteration: 329\t Weight1: [6.10303643]\t Weight2: [3.5449564]\t Bias: [14.16545228]\t Cost: 27.753408980489365\n",
            "Iteration: 330\t Weight1: [6.10976231]\t Weight2: [3.54415145]\t Bias: [14.12466268]\t Cost: 27.66807844405336\n",
            "Iteration: 331\t Weight1: [6.11647462]\t Weight2: [3.54332773]\t Bias: [14.08402155]\t Cost: 27.58335887473802\n",
            "Iteration: 332\t Weight1: [6.12317339]\t Weight2: [3.54248536]\t Bias: [14.04352834]\t Cost: 27.499245781897574\n",
            "Iteration: 333\t Weight1: [6.12985863]\t Weight2: [3.54162449]\t Bias: [14.0031825]\t Cost: 27.415734708554854\n",
            "Iteration: 334\t Weight1: [6.13653037]\t Weight2: [3.54074524]\t Bias: [13.96298348]\t Cost: 27.332821231144923\n",
            "Iteration: 335\t Weight1: [6.14318863]\t Weight2: [3.53984773]\t Bias: [13.92293073]\t Cost: 27.250500959261206\n",
            "Iteration: 336\t Weight1: [6.14983341]\t Weight2: [3.53893211]\t Bias: [13.88302371]\t Cost: 27.168769535403108\n",
            "Iteration: 337\t Weight1: [6.15646476]\t Weight2: [3.53799849]\t Bias: [13.84326187]\t Cost: 27.087622634725854\n",
            "Iteration: 338\t Weight1: [6.16308267]\t Weight2: [3.537047]\t Bias: [13.80364468]\t Cost: 27.007055964792162\n",
            "Iteration: 339\t Weight1: [6.16968718]\t Weight2: [3.53607777]\t Bias: [13.7641716]\t Cost: 26.92706526532582\n",
            "Iteration: 340\t Weight1: [6.17627831]\t Weight2: [3.53509092]\t Bias: [13.72484209]\t Cost: 26.84764630796718\n",
            "Iteration: 341\t Weight1: [6.18285606]\t Weight2: [3.53408659]\t Bias: [13.68565561]\t Cost: 26.768794896030453\n",
            "Iteration: 342\t Weight1: [6.18942047]\t Weight2: [3.53306489]\t Bias: [13.64661164]\t Cost: 26.690506864262986\n",
            "Iteration: 343\t Weight1: [6.19597156]\t Weight2: [3.53202594]\t Bias: [13.60770964]\t Cost: 26.61277807860638\n",
            "Iteration: 344\t Weight1: [6.20250934]\t Weight2: [3.53096987]\t Bias: [13.56894908]\t Cost: 26.535604435959257\n",
            "Iteration: 345\t Weight1: [6.20903383]\t Weight2: [3.52989681]\t Bias: [13.53032945]\t Cost: 26.458981863942135\n",
            "Iteration: 346\t Weight1: [6.21554505]\t Weight2: [3.52880688]\t Bias: [13.49185021]\t Cost: 26.38290632066382\n",
            "Iteration: 347\t Weight1: [6.22204303]\t Weight2: [3.52770019]\t Bias: [13.45351084]\t Cost: 26.307373794489834\n",
            "Iteration: 348\t Weight1: [6.22852778]\t Weight2: [3.52657686]\t Bias: [13.41531082]\t Cost: 26.23238030381252\n",
            "Iteration: 349\t Weight1: [6.23499932]\t Weight2: [3.52543703]\t Bias: [13.37724964]\t Cost: 26.157921896822863\n",
            "Iteration: 350\t Weight1: [6.24145768]\t Weight2: [3.5242808]\t Bias: [13.33932678]\t Cost: 26.083994651284094\n",
            "Iteration: 351\t Weight1: [6.24790287]\t Weight2: [3.52310829]\t Bias: [13.30154171]\t Cost: 26.010594674307143\n",
            "Iteration: 352\t Weight1: [6.25433491]\t Weight2: [3.52191963]\t Bias: [13.26389394]\t Cost: 25.93771810212765\n",
            "Iteration: 353\t Weight1: [6.26075383]\t Weight2: [3.52071493]\t Bias: [13.22638295]\t Cost: 25.865361099884776\n",
            "Iteration: 354\t Weight1: [6.26715964]\t Weight2: [3.51949431]\t Bias: [13.18900823]\t Cost: 25.79351986140169\n",
            "Iteration: 355\t Weight1: [6.27355236]\t Weight2: [3.51825789]\t Bias: [13.15176927]\t Cost: 25.72219060896777\n",
            "Iteration: 356\t Weight1: [6.27993201]\t Weight2: [3.51700577]\t Bias: [13.11466557]\t Cost: 25.651369593122457\n",
            "Iteration: 357\t Weight1: [6.28629862]\t Weight2: [3.51573808]\t Bias: [13.07769663]\t Cost: 25.581053092440726\n",
            "Iteration: 358\t Weight1: [6.29265219]\t Weight2: [3.51445493]\t Bias: [13.04086194]\t Cost: 25.5112374133203\n",
            "Iteration: 359\t Weight1: [6.29899276]\t Weight2: [3.51315643]\t Bias: [13.00416102]\t Cost: 25.441918889770392\n",
            "Iteration: 360\t Weight1: [6.30532035]\t Weight2: [3.5118427]\t Bias: [12.96759335]\t Cost: 25.373093883202124\n",
            "Iteration: 361\t Weight1: [6.31163496]\t Weight2: [3.51051386]\t Bias: [12.93115844]\t Cost: 25.304758782220564\n",
            "Iteration: 362\t Weight1: [6.31793663]\t Weight2: [3.50917]\t Bias: [12.89485581]\t Cost: 25.236910002418345\n",
            "Iteration: 363\t Weight1: [6.32422537]\t Weight2: [3.50781125]\t Bias: [12.85868495]\t Cost: 25.169543986170815\n",
            "Iteration: 364\t Weight1: [6.33050121]\t Weight2: [3.50643771]\t Bias: [12.82264538]\t Cost: 25.102657202432873\n",
            "Iteration: 365\t Weight1: [6.33676415]\t Weight2: [3.50504951]\t Bias: [12.78673662]\t Cost: 25.036246146537273\n",
            "Iteration: 366\t Weight1: [6.34301423]\t Weight2: [3.50364673]\t Bias: [12.75095817]\t Cost: 24.970307339994434\n",
            "Iteration: 367\t Weight1: [6.34925146]\t Weight2: [3.50222951]\t Bias: [12.71530955]\t Cost: 24.904837330293986\n",
            "Iteration: 368\t Weight1: [6.35547587]\t Weight2: [3.50079793]\t Bias: [12.67979028]\t Cost: 24.839832690707574\n",
            "Iteration: 369\t Weight1: [6.36168746]\t Weight2: [3.49935212]\t Bias: [12.64439988]\t Cost: 24.775290020093372\n",
            "Iteration: 370\t Weight1: [6.36788627]\t Weight2: [3.49789219]\t Bias: [12.60913787]\t Cost: 24.71120594270205\n",
            "Iteration: 371\t Weight1: [6.37407231]\t Weight2: [3.49641822]\t Bias: [12.57400377]\t Cost: 24.6475771079841\n",
            "Iteration: 372\t Weight1: [6.38024561]\t Weight2: [3.49493035]\t Bias: [12.53899711]\t Cost: 24.584400190398867\n",
            "Iteration: 373\t Weight1: [6.38640617]\t Weight2: [3.49342866]\t Bias: [12.50411741]\t Cost: 24.521671889224848\n",
            "Iteration: 374\t Weight1: [6.39255403]\t Weight2: [3.49191327]\t Bias: [12.46936421]\t Cost: 24.459388928371624\n",
            "Iteration: 375\t Weight1: [6.3986892]\t Weight2: [3.49038428]\t Bias: [12.43473702]\t Cost: 24.397548056192942\n",
            "Iteration: 376\t Weight1: [6.40481171]\t Weight2: [3.48884179]\t Bias: [12.4002354]\t Cost: 24.336146045301607\n",
            "Iteration: 377\t Weight1: [6.41092156]\t Weight2: [3.48728591]\t Bias: [12.36585886]\t Cost: 24.27517969238552\n",
            "Iteration: 378\t Weight1: [6.41701879]\t Weight2: [3.48571675]\t Bias: [12.33160695]\t Cost: 24.214645818025204\n",
            "Iteration: 379\t Weight1: [6.42310341]\t Weight2: [3.4841344]\t Bias: [12.2974792]\t Cost: 24.154541266512812\n",
            "Iteration: 380\t Weight1: [6.42917544]\t Weight2: [3.48253897]\t Bias: [12.26347515]\t Cost: 24.094862905672304\n",
            "Iteration: 381\t Weight1: [6.43523491]\t Weight2: [3.48093056]\t Bias: [12.22959434]\t Cost: 24.03560762668134\n",
            "Iteration: 382\t Weight1: [6.44128182]\t Weight2: [3.47930926]\t Bias: [12.19583632]\t Cost: 23.97677234389414\n",
            "Iteration: 383\t Weight1: [6.44731621]\t Weight2: [3.47767519]\t Bias: [12.16220062]\t Cost: 23.91835399466606\n",
            "Iteration: 384\t Weight1: [6.45333809]\t Weight2: [3.47602844]\t Bias: [12.1286868]\t Cost: 23.86034953917928\n",
            "Iteration: 385\t Weight1: [6.45934749]\t Weight2: [3.47436911]\t Bias: [12.0952944]\t Cost: 23.802755960269938\n",
            "Iteration: 386\t Weight1: [6.46534442]\t Weight2: [3.4726973]\t Bias: [12.06202298]\t Cost: 23.74557026325651\n",
            "Iteration: 387\t Weight1: [6.47132889]\t Weight2: [3.47101311]\t Bias: [12.02887207]\t Cost: 23.688789475769596\n",
            "Iteration: 388\t Weight1: [6.47730094]\t Weight2: [3.46931663]\t Bias: [11.99584125]\t Cost: 23.632410647582958\n",
            "Iteration: 389\t Weight1: [6.48326059]\t Weight2: [3.46760797]\t Bias: [11.96293005]\t Cost: 23.576430850445828\n",
            "Iteration: 390\t Weight1: [6.48920784]\t Weight2: [3.46588722]\t Bias: [11.93013804]\t Cost: 23.52084717791658\n",
            "Iteration: 391\t Weight1: [6.49514273]\t Weight2: [3.46415448]\t Bias: [11.89746477]\t Cost: 23.46565674519757\n",
            "Iteration: 392\t Weight1: [6.50106527]\t Weight2: [3.46240984]\t Bias: [11.86490981]\t Cost: 23.410856688971307\n",
            "Iteration: 393\t Weight1: [6.50697548]\t Weight2: [3.46065339]\t Bias: [11.83247271]\t Cost: 23.356444167237957\n",
            "Iteration: 394\t Weight1: [6.51287338]\t Weight2: [3.45888525]\t Bias: [11.80015304]\t Cost: 23.302416359153888\n",
            "Iteration: 395\t Weight1: [6.518759]\t Weight2: [3.45710549]\t Bias: [11.76795036]\t Cost: 23.248770464871598\n",
            "Iteration: 396\t Weight1: [6.52463235]\t Weight2: [3.45531421]\t Bias: [11.73586424]\t Cost: 23.195503705380855\n",
            "Iteration: 397\t Weight1: [6.53049344]\t Weight2: [3.45351151]\t Bias: [11.70389425]\t Cost: 23.142613322351114\n",
            "Iteration: 398\t Weight1: [6.53634231]\t Weight2: [3.45169748]\t Bias: [11.67203995]\t Cost: 23.090096577974883\n",
            "Iteration: 399\t Weight1: [6.54217898]\t Weight2: [3.44987221]\t Bias: [11.64030092]\t Cost: 23.037950754812613\n",
            "Iteration: 400\t Weight1: [6.54800345]\t Weight2: [3.44803579]\t Bias: [11.60867673]\t Cost: 22.98617315563858\n",
            "Iteration: 401\t Weight1: [6.55381575]\t Weight2: [3.44618832]\t Bias: [11.57716695]\t Cost: 22.93476110328803\n",
            "Iteration: 402\t Weight1: [6.55961591]\t Weight2: [3.44432988]\t Bias: [11.54577116]\t Cost: 22.883711940505375\n",
            "Iteration: 403\t Weight1: [6.56540394]\t Weight2: [3.44246058]\t Bias: [11.51448894]\t Cost: 22.833023029793758\n",
            "Iteration: 404\t Weight1: [6.57117986]\t Weight2: [3.44058048]\t Bias: [11.48331987]\t Cost: 22.78269175326554\n",
            "Iteration: 405\t Weight1: [6.57694369]\t Weight2: [3.4386897]\t Bias: [11.45226352]\t Cost: 22.732715512494085\n",
            "Iteration: 406\t Weight1: [6.58269545]\t Weight2: [3.43678831]\t Bias: [11.42131948]\t Cost: 22.683091728366694\n",
            "Iteration: 407\t Weight1: [6.58843516]\t Weight2: [3.4348764]\t Bias: [11.39048733]\t Cost: 22.633817840938455\n",
            "Iteration: 408\t Weight1: [6.59416284]\t Weight2: [3.43295407]\t Bias: [11.35976667]\t Cost: 22.584891309287507\n",
            "Iteration: 409\t Weight1: [6.59987851]\t Weight2: [3.43102139]\t Bias: [11.32915707]\t Cost: 22.53630961137122\n",
            "Iteration: 410\t Weight1: [6.6055822]\t Weight2: [3.42907847]\t Bias: [11.29865812]\t Cost: 22.488070243883435\n",
            "Iteration: 411\t Weight1: [6.61127391]\t Weight2: [3.42712537]\t Bias: [11.26826941]\t Cost: 22.440170722113038\n",
            "Iteration: 412\t Weight1: [6.61695367]\t Weight2: [3.4251622]\t Bias: [11.23799055]\t Cost: 22.392608579803298\n",
            "Iteration: 413\t Weight1: [6.62262151]\t Weight2: [3.42318904]\t Bias: [11.20782111]\t Cost: 22.345381369012543\n",
            "Iteration: 414\t Weight1: [6.62827743]\t Weight2: [3.42120596]\t Bias: [11.17776069]\t Cost: 22.298486659975794\n",
            "Iteration: 415\t Weight1: [6.63392146]\t Weight2: [3.41921307]\t Bias: [11.1478089]\t Cost: 22.2519220409674\n",
            "Iteration: 416\t Weight1: [6.63955363]\t Weight2: [3.41721043]\t Bias: [11.11796532]\t Cost: 22.20568511816485\n",
            "Iteration: 417\t Weight1: [6.64517394]\t Weight2: [3.41519814]\t Bias: [11.08822956]\t Cost: 22.15977351551354\n",
            "Iteration: 418\t Weight1: [6.65078242]\t Weight2: [3.41317628]\t Bias: [11.05860121]\t Cost: 22.114184874592613\n",
            "Iteration: 419\t Weight1: [6.65637909]\t Weight2: [3.41114493]\t Bias: [11.02907989]\t Cost: 22.068916854481756\n",
            "Iteration: 420\t Weight1: [6.66196397]\t Weight2: [3.40910418]\t Bias: [10.99966519]\t Cost: 22.02396713162917\n",
            "Iteration: 421\t Weight1: [6.66753707]\t Weight2: [3.4070541]\t Bias: [10.97035671]\t Cost: 21.979333399720257\n",
            "Iteration: 422\t Weight1: [6.67309843]\t Weight2: [3.40499479]\t Bias: [10.94115408]\t Cost: 21.935013369547804\n",
            "Iteration: 423\t Weight1: [6.67864805]\t Weight2: [3.40292631]\t Bias: [10.91205689]\t Cost: 21.891004768882514\n",
            "Iteration: 424\t Weight1: [6.68418596]\t Weight2: [3.40084875]\t Bias: [10.88306475]\t Cost: 21.847305342345162\n",
            "Iteration: 425\t Weight1: [6.68971218]\t Weight2: [3.3987622]\t Bias: [10.85417727]\t Cost: 21.80391285127922\n",
            "Iteration: 426\t Weight1: [6.69522673]\t Weight2: [3.39666673]\t Bias: [10.82539408]\t Cost: 21.760825073624797\n",
            "Iteration: 427\t Weight1: [6.70072962]\t Weight2: [3.39456242]\t Bias: [10.79671477]\t Cost: 21.718039803793385\n",
            "Iteration: 428\t Weight1: [6.70622088]\t Weight2: [3.39244935]\t Bias: [10.76813898]\t Cost: 21.675554852543563\n",
            "Iteration: 429\t Weight1: [6.71170052]\t Weight2: [3.3903276]\t Bias: [10.7396663]\t Cost: 21.633368046857694\n",
            "Iteration: 430\t Weight1: [6.71716857]\t Weight2: [3.38819725]\t Bias: [10.71129637]\t Cost: 21.59147722981962\n",
            "Iteration: 431\t Weight1: [6.72262505]\t Weight2: [3.38605837]\t Bias: [10.68302881]\t Cost: 21.549880260493076\n",
            "Iteration: 432\t Weight1: [6.72806997]\t Weight2: [3.38391105]\t Bias: [10.65486322]\t Cost: 21.508575013801348\n",
            "Iteration: 433\t Weight1: [6.73350336]\t Weight2: [3.38175536]\t Bias: [10.62679925]\t Cost: 21.4675593804075\n",
            "Iteration: 434\t Weight1: [6.73892523]\t Weight2: [3.37959137]\t Bias: [10.5988365]\t Cost: 21.426831266595904\n",
            "Iteration: 435\t Weight1: [6.74433561]\t Weight2: [3.37741917]\t Bias: [10.57097461]\t Cost: 21.386388594154276\n",
            "Iteration: 436\t Weight1: [6.74973451]\t Weight2: [3.37523883]\t Bias: [10.54321321]\t Cost: 21.346229300256905\n",
            "Iteration: 437\t Weight1: [6.75512195]\t Weight2: [3.37305042]\t Bias: [10.51555191]\t Cost: 21.306351337348655\n",
            "Iteration: 438\t Weight1: [6.76049796]\t Weight2: [3.37085402]\t Bias: [10.48799036]\t Cost: 21.266752673029895\n",
            "Iteration: 439\t Weight1: [6.76586255]\t Weight2: [3.36864971]\t Bias: [10.46052818]\t Cost: 21.22743128994222\n",
            "Iteration: 440\t Weight1: [6.77121574]\t Weight2: [3.36643756]\t Bias: [10.43316501]\t Cost: 21.188385185655147\n",
            "Iteration: 441\t Weight1: [6.77655755]\t Weight2: [3.36421764]\t Bias: [10.40590048]\t Cost: 21.14961237255369\n",
            "Iteration: 442\t Weight1: [6.78188801]\t Weight2: [3.36199002]\t Bias: [10.37873422]\t Cost: 21.111110877726617\n",
            "Iteration: 443\t Weight1: [6.78720713]\t Weight2: [3.35975479]\t Bias: [10.35166587]\t Cost: 21.072878742855774\n",
            "Iteration: 444\t Weight1: [6.79251493]\t Weight2: [3.357512]\t Bias: [10.32469508]\t Cost: 21.034914024106154\n",
            "Iteration: 445\t Weight1: [6.79781142]\t Weight2: [3.35526174]\t Bias: [10.29782147]\t Cost: 20.997214792016823\n",
            "Iteration: 446\t Weight1: [6.80309664]\t Weight2: [3.35300408]\t Bias: [10.2710447]\t Cost: 20.95977913139255\n",
            "Iteration: 447\t Weight1: [6.8083706]\t Weight2: [3.35073908]\t Bias: [10.24436439]\t Cost: 20.922605141196605\n",
            "Iteration: 448\t Weight1: [6.81363331]\t Weight2: [3.34846682]\t Bias: [10.21778021]\t Cost: 20.88569093444393\n",
            "Iteration: 449\t Weight1: [6.81888481]\t Weight2: [3.34618737]\t Bias: [10.19129178]\t Cost: 20.849034638095475\n",
            "Iteration: 450\t Weight1: [6.8241251]\t Weight2: [3.3439008]\t Bias: [10.16489876]\t Cost: 20.812634392953196\n",
            "Iteration: 451\t Weight1: [6.8293542]\t Weight2: [3.34160717]\t Bias: [10.1386008]\t Cost: 20.776488353555898\n",
            "Iteration: 452\t Weight1: [6.83457215]\t Weight2: [3.33930657]\t Bias: [10.11239753]\t Cost: 20.740594688075692\n",
            "Iteration: 453\t Weight1: [6.83977895]\t Weight2: [3.33699905]\t Bias: [10.08628863]\t Cost: 20.704951578215624\n",
            "Iteration: 454\t Weight1: [6.84497463]\t Weight2: [3.33468469]\t Bias: [10.06027372]\t Cost: 20.669557219107674\n",
            "Iteration: 455\t Weight1: [6.8501592]\t Weight2: [3.33236356]\t Bias: [10.03435248]\t Cost: 20.634409819211825\n",
            "Iteration: 456\t Weight1: [6.85533268]\t Weight2: [3.33003571]\t Bias: [10.00852455]\t Cost: 20.59950760021571\n",
            "Iteration: 457\t Weight1: [6.8604951]\t Weight2: [3.32770123]\t Bias: [9.98278959]\t Cost: 20.564848796935195\n",
            "Iteration: 458\t Weight1: [6.86564647]\t Weight2: [3.32536017]\t Bias: [9.95714725]\t Cost: 20.530431657215555\n",
            "Iteration: 459\t Weight1: [6.87078682]\t Weight2: [3.32301261]\t Bias: [9.93159719]\t Cost: 20.496254441833504\n",
            "Iteration: 460\t Weight1: [6.87591615]\t Weight2: [3.32065861]\t Bias: [9.90613907]\t Cost: 20.462315424399957\n",
            "Iteration: 461\t Weight1: [6.8810345]\t Weight2: [3.31829824]\t Bias: [9.88077256]\t Cost: 20.42861289126356\n",
            "Iteration: 462\t Weight1: [6.88614188]\t Weight2: [3.31593156]\t Bias: [9.85549731]\t Cost: 20.395145141414773\n",
            "Iteration: 463\t Weight1: [6.89123831]\t Weight2: [3.31355864]\t Bias: [9.83031299]\t Cost: 20.361910486391057\n",
            "Iteration: 464\t Weight1: [6.8963238]\t Weight2: [3.31117954]\t Bias: [9.80521926]\t Cost: 20.328907250182343\n",
            "Iteration: 465\t Weight1: [6.90139839]\t Weight2: [3.30879433]\t Bias: [9.78021579]\t Cost: 20.2961337691376\n",
            "Iteration: 466\t Weight1: [6.90646208]\t Weight2: [3.30640307]\t Bias: [9.75530224]\t Cost: 20.263588391871828\n",
            "Iteration: 467\t Weight1: [6.9115149]\t Weight2: [3.30400582]\t Bias: [9.73047829]\t Cost: 20.23126947917396\n",
            "Iteration: 468\t Weight1: [6.91655686]\t Weight2: [3.30160266]\t Bias: [9.70574359]\t Cost: 20.199175403915287\n",
            "Iteration: 469\t Weight1: [6.92158799]\t Weight2: [3.29919364]\t Bias: [9.68109783]\t Cost: 20.16730455095889\n",
            "Iteration: 470\t Weight1: [6.9266083]\t Weight2: [3.29677883]\t Bias: [9.65654068]\t Cost: 20.135655317069293\n",
            "Iteration: 471\t Weight1: [6.93161782]\t Weight2: [3.29435828]\t Bias: [9.6320718]\t Cost: 20.104226110823245\n",
            "Iteration: 472\t Weight1: [6.93661656]\t Weight2: [3.29193206]\t Bias: [9.60769087]\t Cost: 20.073015352520947\n",
            "Iteration: 473\t Weight1: [6.94160454]\t Weight2: [3.28950024]\t Bias: [9.58339757]\t Cost: 20.042021474097982\n",
            "Iteration: 474\t Weight1: [6.94658179]\t Weight2: [3.28706287]\t Bias: [9.55919158]\t Cost: 20.011242919037993\n",
            "Iteration: 475\t Weight1: [6.95154831]\t Weight2: [3.28462002]\t Bias: [9.53507257]\t Cost: 19.98067814228593\n",
            "Iteration: 476\t Weight1: [6.95650413]\t Weight2: [3.28217174]\t Bias: [9.51104022]\t Cost: 19.950325610162043\n",
            "Iteration: 477\t Weight1: [6.96144927]\t Weight2: [3.2797181]\t Bias: [9.48709421]\t Cost: 19.920183800276444\n",
            "Iteration: 478\t Weight1: [6.96638375]\t Weight2: [3.27725915]\t Bias: [9.46323423]\t Cost: 19.890251201444425\n",
            "Iteration: 479\t Weight1: [6.97130759]\t Weight2: [3.27479496]\t Bias: [9.43945995]\t Cost: 19.8605263136023\n",
            "Iteration: 480\t Weight1: [6.9762208]\t Weight2: [3.27232559]\t Bias: [9.41577107]\t Cost: 19.83100764772404\n",
            "Iteration: 481\t Weight1: [6.9811234]\t Weight2: [3.26985109]\t Bias: [9.39216726]\t Cost: 19.801693725738296\n",
            "Iteration: 482\t Weight1: [6.98601542]\t Weight2: [3.26737152]\t Bias: [9.36864821]\t Cost: 19.772583080446378\n",
            "Iteration: 483\t Weight1: [6.99089687]\t Weight2: [3.26488695]\t Bias: [9.34521362]\t Cost: 19.743674255440588\n",
            "Iteration: 484\t Weight1: [6.99576778]\t Weight2: [3.26239742]\t Bias: [9.32186316]\t Cost: 19.714965805023287\n",
            "Iteration: 485\t Weight1: [7.00062815]\t Weight2: [3.25990301]\t Bias: [9.29859653]\t Cost: 19.686456294126657\n",
            "Iteration: 486\t Weight1: [7.00547802]\t Weight2: [3.25740376]\t Bias: [9.27541342]\t Cost: 19.658144298232816\n",
            "Iteration: 487\t Weight1: [7.01031739]\t Weight2: [3.25489973]\t Bias: [9.25231353]\t Cost: 19.63002840329485\n",
            "Iteration: 488\t Weight1: [7.01514629]\t Weight2: [3.25239098]\t Bias: [9.22929654]\t Cost: 19.60210720565824\n",
            "Iteration: 489\t Weight1: [7.01996473]\t Weight2: [3.24987757]\t Bias: [9.20636215]\t Cost: 19.574379311982977\n",
            "Iteration: 490\t Weight1: [7.02477274]\t Weight2: [3.24735955]\t Bias: [9.18351005]\t Cost: 19.546843339166212\n",
            "Iteration: 491\t Weight1: [7.02957034]\t Weight2: [3.24483697]\t Bias: [9.16073995]\t Cost: 19.519497914265585\n",
            "Iteration: 492\t Weight1: [7.03435754]\t Weight2: [3.2423099]\t Bias: [9.13805154]\t Cost: 19.492341674422985\n",
            "Iteration: 493\t Weight1: [7.03913436]\t Weight2: [3.23977839]\t Bias: [9.11544452]\t Cost: 19.465373266789076\n",
            "Iteration: 494\t Weight1: [7.04390082]\t Weight2: [3.23724249]\t Bias: [9.09291859]\t Cost: 19.438591348448234\n",
            "Iteration: 495\t Weight1: [7.04865694]\t Weight2: [3.23470226]\t Bias: [9.07047345]\t Cost: 19.411994586344157\n",
            "Iteration: 496\t Weight1: [7.05340274]\t Weight2: [3.23215776]\t Bias: [9.0481088]\t Cost: 19.385581657206018\n",
            "Iteration: 497\t Weight1: [7.05813823]\t Weight2: [3.22960903]\t Bias: [9.02582436]\t Cost: 19.359351247475132\n",
            "Iteration: 498\t Weight1: [7.06286344]\t Weight2: [3.22705613]\t Bias: [9.00361981]\t Cost: 19.333302053232238\n",
            "Iteration: 499\t Weight1: [7.06757839]\t Weight2: [3.22449911]\t Bias: [8.98149488]\t Cost: 19.30743278012529\n",
            "Iteration: 500\t Weight1: [7.07228309]\t Weight2: [3.22193803]\t Bias: [8.95944926]\t Cost: 19.28174214329791\n",
            "Iteration: 501\t Weight1: [7.07697756]\t Weight2: [3.21937294]\t Bias: [8.93748266]\t Cost: 19.256228867318168\n",
            "Iteration: 502\t Weight1: [7.08166182]\t Weight2: [3.21680389]\t Bias: [8.91559479]\t Cost: 19.230891686108084\n",
            "Iteration: 503\t Weight1: [7.08633589]\t Weight2: [3.21423093]\t Bias: [8.89378537]\t Cost: 19.20572934287364\n",
            "Iteration: 504\t Weight1: [7.09099979]\t Weight2: [3.21165412]\t Bias: [8.87205411]\t Cost: 19.180740590035235\n",
            "Iteration: 505\t Weight1: [7.09565354]\t Weight2: [3.2090735]\t Bias: [8.8504007]\t Cost: 19.155924189158807\n",
            "Iteration: 506\t Weight1: [7.10029715]\t Weight2: [3.20648914]\t Bias: [8.82882488]\t Cost: 19.131278910887318\n",
            "Iteration: 507\t Weight1: [7.10493064]\t Weight2: [3.20390107]\t Bias: [8.80732636]\t Cost: 19.1068035348729\n",
            "Iteration: 508\t Weight1: [7.10955404]\t Weight2: [3.20130935]\t Bias: [8.78590484]\t Cost: 19.082496849709425\n",
            "Iteration: 509\t Weight1: [7.11416736]\t Weight2: [3.19871404]\t Bias: [8.76456005]\t Cost: 19.05835765286561\n",
            "Iteration: 510\t Weight1: [7.11877061]\t Weight2: [3.19611517]\t Bias: [8.74329171]\t Cost: 19.034384750618706\n",
            "Iteration: 511\t Weight1: [7.12336383]\t Weight2: [3.19351281]\t Bias: [8.72209953]\t Cost: 19.01057695798852\n",
            "Iteration: 512\t Weight1: [7.12794702]\t Weight2: [3.19090699]\t Bias: [8.70098323]\t Cost: 18.98693309867212\n",
            "Iteration: 513\t Weight1: [7.13252021]\t Weight2: [3.18829777]\t Bias: [8.67994254]\t Cost: 18.96345200497898\n",
            "Iteration: 514\t Weight1: [7.13708341]\t Weight2: [3.1856852]\t Bias: [8.65897717]\t Cost: 18.940132517766493\n",
            "Iteration: 515\t Weight1: [7.14163664]\t Weight2: [3.18306933]\t Bias: [8.63808686]\t Cost: 18.916973486376136\n",
            "Iteration: 516\t Weight1: [7.14617993]\t Weight2: [3.1804502]\t Bias: [8.61727131]\t Cost: 18.893973768570092\n",
            "Iteration: 517\t Weight1: [7.15071328]\t Weight2: [3.17782786]\t Bias: [8.59653027]\t Cost: 18.871132230468262\n",
            "Iteration: 518\t Weight1: [7.15523672]\t Weight2: [3.17520237]\t Bias: [8.57586345]\t Cost: 18.848447746485814\n",
            "Iteration: 519\t Weight1: [7.15975026]\t Weight2: [3.17257376]\t Bias: [8.55527058]\t Cost: 18.82591919927131\n",
            "Iteration: 520\t Weight1: [7.16425393]\t Weight2: [3.16994209]\t Bias: [8.5347514]\t Cost: 18.80354547964499\n",
            "Iteration: 521\t Weight1: [7.16874775]\t Weight2: [3.1673074]\t Bias: [8.51430562]\t Cost: 18.78132548653796\n",
            "Iteration: 522\t Weight1: [7.17323172]\t Weight2: [3.16466973]\t Bias: [8.49393298]\t Cost: 18.75925812693147\n",
            "Iteration: 523\t Weight1: [7.17770587]\t Weight2: [3.16202915]\t Bias: [8.47363321]\t Cost: 18.737342315796802\n",
            "Iteration: 524\t Weight1: [7.18217022]\t Weight2: [3.15938568]\t Bias: [8.45340605]\t Cost: 18.71557697603571\n",
            "Iteration: 525\t Weight1: [7.18662478]\t Weight2: [3.15673938]\t Bias: [8.43325122]\t Cost: 18.693961038421076\n",
            "Iteration: 526\t Weight1: [7.19106958]\t Weight2: [3.1540903]\t Bias: [8.41316847]\t Cost: 18.67249344153825\n",
            "Iteration: 527\t Weight1: [7.19550463]\t Weight2: [3.15143847]\t Bias: [8.39315752]\t Cost: 18.651173131726672\n",
            "Iteration: 528\t Weight1: [7.19992995]\t Weight2: [3.14878395]\t Bias: [8.37321811]\t Cost: 18.629999063022062\n",
            "Iteration: 529\t Weight1: [7.20434556]\t Weight2: [3.14612677]\t Bias: [8.35334998]\t Cost: 18.608970197098895\n",
            "Iteration: 530\t Weight1: [7.20875148]\t Weight2: [3.14346699]\t Bias: [8.33355287]\t Cost: 18.58808550321349\n",
            "Iteration: 531\t Weight1: [7.21314772]\t Weight2: [3.14080464]\t Bias: [8.31382651]\t Cost: 18.56734395814738\n",
            "Iteration: 532\t Weight1: [7.2175343]\t Weight2: [3.13813977]\t Bias: [8.29417065]\t Cost: 18.546744546151256\n",
            "Iteration: 533\t Weight1: [7.22191124]\t Weight2: [3.13547243]\t Bias: [8.27458503]\t Cost: 18.526286258889144\n",
            "Iteration: 534\t Weight1: [7.22627857]\t Weight2: [3.13280266]\t Bias: [8.25506939]\t Cost: 18.505968095383174\n",
            "Iteration: 535\t Weight1: [7.23063629]\t Weight2: [3.1301305]\t Bias: [8.23562348]\t Cost: 18.48578906195874\n",
            "Iteration: 536\t Weight1: [7.23498442]\t Weight2: [3.12745599]\t Bias: [8.21624703]\t Cost: 18.465748172189947\n",
            "Iteration: 537\t Weight1: [7.23932299]\t Weight2: [3.12477917]\t Bias: [8.19693979]\t Cost: 18.44584444684571\n",
            "Iteration: 538\t Weight1: [7.24365201]\t Weight2: [3.1221001]\t Bias: [8.17770151]\t Cost: 18.426076913835985\n",
            "Iteration: 539\t Weight1: [7.2479715]\t Weight2: [3.11941881]\t Bias: [8.15853194]\t Cost: 18.4064446081586\n",
            "Iteration: 540\t Weight1: [7.25228148]\t Weight2: [3.11673534]\t Bias: [8.13943082]\t Cost: 18.386946571846444\n",
            "Iteration: 541\t Weight1: [7.25658196]\t Weight2: [3.11404973]\t Bias: [8.1203979]\t Cost: 18.367581853915002\n",
            "Iteration: 542\t Weight1: [7.26087297]\t Weight2: [3.11136204]\t Bias: [8.10143294]\t Cost: 18.34834951031038\n",
            "Iteration: 543\t Weight1: [7.26515452]\t Weight2: [3.10867229]\t Bias: [8.08253567]\t Cost: 18.32924860385765\n",
            "Iteration: 544\t Weight1: [7.26942662]\t Weight2: [3.10598053]\t Bias: [8.06370586]\t Cost: 18.31027820420954\n",
            "Iteration: 545\t Weight1: [7.2736893]\t Weight2: [3.10328679]\t Bias: [8.04494326]\t Cost: 18.291437387795714\n",
            "Iteration: 546\t Weight1: [7.27794258]\t Weight2: [3.10059113]\t Bias: [8.02624762]\t Cost: 18.272725237772175\n",
            "Iteration: 547\t Weight1: [7.28218647]\t Weight2: [3.09789358]\t Bias: [8.00761869]\t Cost: 18.25414084397127\n",
            "Iteration: 548\t Weight1: [7.28642099]\t Weight2: [3.09519417]\t Bias: [7.98905623]\t Cost: 18.235683302851946\n",
            "Iteration: 549\t Weight1: [7.29064616]\t Weight2: [3.09249296]\t Bias: [7.97055999]\t Cost: 18.21735171745037\n",
            "Iteration: 550\t Weight1: [7.294862]\t Weight2: [3.08978997]\t Bias: [7.95212974]\t Cost: 18.199145197331074\n",
            "Iteration: 551\t Weight1: [7.29906851]\t Weight2: [3.08708526]\t Bias: [7.93376523]\t Cost: 18.18106285853827\n",
            "Iteration: 552\t Weight1: [7.30326573]\t Weight2: [3.08437885]\t Bias: [7.91546623]\t Cost: 18.1631038235477\n",
            "Iteration: 553\t Weight1: [7.30745367]\t Weight2: [3.08167078]\t Bias: [7.89723248]\t Cost: 18.145267221218713\n",
            "Iteration: 554\t Weight1: [7.31163235]\t Weight2: [3.0789611]\t Bias: [7.87906375]\t Cost: 18.127552186746865\n",
            "Iteration: 555\t Weight1: [7.31580178]\t Weight2: [3.07624985]\t Bias: [7.8609598]\t Cost: 18.109957861616692\n",
            "Iteration: 556\t Weight1: [7.31996198]\t Weight2: [3.07353705]\t Bias: [7.8429204]\t Cost: 18.09248339355494\n",
            "Iteration: 557\t Weight1: [7.32411297]\t Weight2: [3.07082275]\t Bias: [7.82494531]\t Cost: 18.07512793648423\n",
            "Iteration: 558\t Weight1: [7.32825477]\t Weight2: [3.06810699]\t Bias: [7.80703429]\t Cost: 18.057890650476907\n",
            "Iteration: 559\t Weight1: [7.3323874]\t Weight2: [3.0653898]\t Bias: [7.78918711]\t Cost: 18.0407707017093\n",
            "Iteration: 560\t Weight1: [7.33651087]\t Weight2: [3.06267122]\t Bias: [7.77140353]\t Cost: 18.02376726241644\n",
            "Iteration: 561\t Weight1: [7.34062519]\t Weight2: [3.05995129]\t Bias: [7.75368333]\t Cost: 18.00687951084688\n",
            "Iteration: 562\t Weight1: [7.3447304]\t Weight2: [3.05723005]\t Bias: [7.73602626]\t Cost: 17.99010663121818\n",
            "Iteration: 563\t Weight1: [7.3488265]\t Weight2: [3.05450752]\t Bias: [7.7184321]\t Cost: 17.973447813672365\n",
            "Iteration: 564\t Weight1: [7.35291351]\t Weight2: [3.05178375]\t Bias: [7.70090062]\t Cost: 17.956902254232\n",
            "Iteration: 565\t Weight1: [7.35699146]\t Weight2: [3.04905878]\t Bias: [7.68343158]\t Cost: 17.940469154756563\n",
            "Iteration: 566\t Weight1: [7.36106035]\t Weight2: [3.04633263]\t Bias: [7.66602476]\t Cost: 17.924147722898933\n",
            "Iteration: 567\t Weight1: [7.3651202]\t Weight2: [3.04360535]\t Bias: [7.64867994]\t Cost: 17.90793717206247\n",
            "Iteration: 568\t Weight1: [7.36917104]\t Weight2: [3.04087697]\t Bias: [7.63139688]\t Cost: 17.891836721358278\n",
            "Iteration: 569\t Weight1: [7.37321288]\t Weight2: [3.03814752]\t Bias: [7.61417535]\t Cost: 17.8758455955628\n",
            "Iteration: 570\t Weight1: [7.37724574]\t Weight2: [3.03541704]\t Bias: [7.59701514]\t Cost: 17.8599630250758\n",
            "Iteration: 571\t Weight1: [7.38126963]\t Weight2: [3.03268557]\t Bias: [7.57991602]\t Cost: 17.844188245878566\n",
            "Iteration: 572\t Weight1: [7.38528457]\t Weight2: [3.02995313]\t Bias: [7.56287776]\t Cost: 17.828520499492566\n",
            "Iteration: 573\t Weight1: [7.38929058]\t Weight2: [3.02721977]\t Bias: [7.54590015]\t Cost: 17.81295903293814\n",
            "Iteration: 574\t Weight1: [7.39328768]\t Weight2: [3.02448551]\t Bias: [7.52898295]\t Cost: 17.797503098693962\n",
            "Iteration: 575\t Weight1: [7.39727588]\t Weight2: [3.0217504]\t Bias: [7.51212595]\t Cost: 17.782151954656303\n",
            "Iteration: 576\t Weight1: [7.4012552]\t Weight2: [3.01901445]\t Bias: [7.49532893]\t Cost: 17.766904864099\n",
            "Iteration: 577\t Weight1: [7.40522566]\t Weight2: [3.01627772]\t Bias: [7.47859167]\t Cost: 17.75176109563345\n",
            "Iteration: 578\t Weight1: [7.40918727]\t Weight2: [3.01354023]\t Bias: [7.46191395]\t Cost: 17.736719923169098\n",
            "Iteration: 579\t Weight1: [7.41314006]\t Weight2: [3.01080201]\t Bias: [7.44529555]\t Cost: 17.721780625874132\n",
            "Iteration: 580\t Weight1: [7.41708404]\t Weight2: [3.0080631]\t Bias: [7.42873626]\t Cost: 17.706942488136438\n",
            "Iteration: 581\t Weight1: [7.42101922]\t Weight2: [3.00532353]\t Bias: [7.41223586]\t Cost: 17.692204799524976\n",
            "Iteration: 582\t Weight1: [7.42494563]\t Weight2: [3.00258333]\t Bias: [7.39579413]\t Cost: 17.677566854751323\n",
            "Iteration: 583\t Weight1: [7.42886328]\t Weight2: [2.99984253]\t Bias: [7.37941085]\t Cost: 17.663027953631563\n",
            "Iteration: 584\t Weight1: [7.43277218]\t Weight2: [2.99710117]\t Bias: [7.36308583]\t Cost: 17.648587401048495\n",
            "Iteration: 585\t Weight1: [7.43667236]\t Weight2: [2.99435928]\t Bias: [7.34681884]\t Cost: 17.634244506914023\n",
            "Iteration: 586\t Weight1: [7.44056384]\t Weight2: [2.99161688]\t Bias: [7.33060966]\t Cost: 17.61999858613193\n",
            "Iteration: 587\t Weight1: [7.44444662]\t Weight2: [2.98887402]\t Bias: [7.3144581]\t Cost: 17.605848958560927\n",
            "Iteration: 588\t Weight1: [7.44832073]\t Weight2: [2.98613072]\t Bias: [7.29836393]\t Cost: 17.591794948977892\n",
            "Iteration: 589\t Weight1: [7.45218618]\t Weight2: [2.98338701]\t Bias: [7.28232695]\t Cost: 17.577835887041477\n",
            "Iteration: 590\t Weight1: [7.45604299]\t Weight2: [2.98064292]\t Bias: [7.26634696]\t Cost: 17.563971107255973\n",
            "Iteration: 591\t Weight1: [7.45989117]\t Weight2: [2.97789849]\t Bias: [7.25042373]\t Cost: 17.550199948935393\n",
            "Iteration: 592\t Weight1: [7.46373075]\t Weight2: [2.97515374]\t Bias: [7.23455706]\t Cost: 17.536521756167897\n",
            "Iteration: 593\t Weight1: [7.46756175]\t Weight2: [2.9724087]\t Bias: [7.21874676]\t Cost: 17.52293587778044\n",
            "Iteration: 594\t Weight1: [7.47138416]\t Weight2: [2.96966341]\t Bias: [7.2029926]\t Cost: 17.50944166730369\n",
            "Iteration: 595\t Weight1: [7.47519803]\t Weight2: [2.9669179]\t Bias: [7.18729439]\t Cost: 17.49603848293725\n",
            "Iteration: 596\t Weight1: [7.47900335]\t Weight2: [2.96417218]\t Bias: [7.17165192]\t Cost: 17.482725687515078\n",
            "Iteration: 597\t Weight1: [7.48280015]\t Weight2: [2.9614263]\t Bias: [7.15606499]\t Cost: 17.46950264847126\n",
            "Iteration: 598\t Weight1: [7.48658845]\t Weight2: [2.95868029]\t Bias: [7.14053339]\t Cost: 17.456368737805835\n",
            "Iteration: 599\t Weight1: [7.49036825]\t Weight2: [2.95593416]\t Bias: [7.12505693]\t Cost: 17.443323332051243\n",
            "Iteration: 600\t Weight1: [7.49413959]\t Weight2: [2.95318796]\t Bias: [7.1096354]\t Cost: 17.430365812238623\n",
            "Iteration: 601\t Weight1: [7.49790247]\t Weight2: [2.9504417]\t Bias: [7.09426859]\t Cost: 17.417495563864673\n",
            "Iteration: 602\t Weight1: [7.50165691]\t Weight2: [2.94769542]\t Bias: [7.07895632]\t Cost: 17.404711976858525\n",
            "Iteration: 603\t Weight1: [7.50540293]\t Weight2: [2.94494914]\t Bias: [7.06369838]\t Cost: 17.392014445549037\n",
            "Iteration: 604\t Weight1: [7.50914054]\t Weight2: [2.9422029]\t Bias: [7.04849458]\t Cost: 17.37940236863236\n",
            "Iteration: 605\t Weight1: [7.51286976]\t Weight2: [2.93945672]\t Bias: [7.03334471]\t Cost: 17.366875149139485\n",
            "Iteration: 606\t Weight1: [7.51659061]\t Weight2: [2.93671063]\t Bias: [7.01824857]\t Cost: 17.354432194404335\n",
            "Iteration: 607\t Weight1: [7.52030311]\t Weight2: [2.93396466]\t Bias: [7.00320598]\t Cost: 17.342072916031963\n",
            "Iteration: 608\t Weight1: [7.52400726]\t Weight2: [2.93121883]\t Bias: [6.98821674]\t Cost: 17.32979672986699\n",
            "Iteration: 609\t Weight1: [7.5277031]\t Weight2: [2.92847317]\t Bias: [6.97328065]\t Cost: 17.317603055962238\n",
            "Iteration: 610\t Weight1: [7.53139062]\t Weight2: [2.92572771]\t Bias: [6.95839752]\t Cost: 17.30549131854776\n",
            "Iteration: 611\t Weight1: [7.53506986]\t Weight2: [2.92298247]\t Bias: [6.94356716]\t Cost: 17.29346094599991\n",
            "Iteration: 612\t Weight1: [7.53874082]\t Weight2: [2.92023749]\t Bias: [6.92878936]\t Cost: 17.281511370810772\n",
            "Iteration: 613\t Weight1: [7.54240353]\t Weight2: [2.91749278]\t Bias: [6.91406395]\t Cost: 17.269642029557726\n",
            "Iteration: 614\t Weight1: [7.54605799]\t Weight2: [2.91474838]\t Bias: [6.89939073]\t Cost: 17.257852362873408\n",
            "Iteration: 615\t Weight1: [7.54970424]\t Weight2: [2.91200431]\t Bias: [6.88476951]\t Cost: 17.246141815415644\n",
            "Iteration: 616\t Weight1: [7.55334227]\t Weight2: [2.9092606]\t Bias: [6.87020009]\t Cost: 17.23450983583786\n",
            "Iteration: 617\t Weight1: [7.55697211]\t Weight2: [2.90651726]\t Bias: [6.8556823]\t Cost: 17.222955876759528\n",
            "Iteration: 618\t Weight1: [7.56059378]\t Weight2: [2.90377434]\t Bias: [6.84121594]\t Cost: 17.21147939473698\n",
            "Iteration: 619\t Weight1: [7.56420728]\t Weight2: [2.90103185]\t Bias: [6.82680082]\t Cost: 17.20007985023429\n",
            "Iteration: 620\t Weight1: [7.56781265]\t Weight2: [2.89828981]\t Bias: [6.81243677]\t Cost: 17.188756707594557\n",
            "Iteration: 621\t Weight1: [7.57140989]\t Weight2: [2.89554826]\t Bias: [6.79812358]\t Cost: 17.17750943501122\n",
            "Iteration: 622\t Weight1: [7.57499901]\t Weight2: [2.89280722]\t Bias: [6.78386108]\t Cost: 17.166337504499673\n",
            "Iteration: 623\t Weight1: [7.57858005]\t Weight2: [2.89006671]\t Bias: [6.76964909]\t Cost: 17.15524039186915\n",
            "Iteration: 624\t Weight1: [7.582153]\t Weight2: [2.88732676]\t Bias: [6.75548741]\t Cost: 17.14421757669472\n",
            "Iteration: 625\t Weight1: [7.5857179]\t Weight2: [2.88458739]\t Bias: [6.74137586]\t Cost: 17.133268542289578\n",
            "Iteration: 626\t Weight1: [7.58927474]\t Weight2: [2.88184863]\t Bias: [6.72731427]\t Cost: 17.122392775677415\n",
            "Iteration: 627\t Weight1: [7.59282356]\t Weight2: [2.8791105]\t Bias: [6.71330245]\t Cost: 17.11158976756521\n",
            "Iteration: 628\t Weight1: [7.59636437]\t Weight2: [2.87637302]\t Bias: [6.69934021]\t Cost: 17.100859012315958\n",
            "Iteration: 629\t Weight1: [7.59989717]\t Weight2: [2.87363622]\t Bias: [6.68542738]\t Cost: 17.090200007921883\n",
            "Iteration: 630\t Weight1: [7.603422]\t Weight2: [2.87090013]\t Bias: [6.67156378]\t Cost: 17.07961225597756\n",
            "Iteration: 631\t Weight1: [7.60693886]\t Weight2: [2.86816476]\t Bias: [6.65774923]\t Cost: 17.069095261653544\n",
            "Iteration: 632\t Weight1: [7.61044777]\t Weight2: [2.86543013]\t Bias: [6.64398354]\t Cost: 17.058648533669977\n",
            "Iteration: 633\t Weight1: [7.61394875]\t Weight2: [2.86269628]\t Bias: [6.63026655]\t Cost: 17.048271584270417\n",
            "Iteration: 634\t Weight1: [7.61744181]\t Weight2: [2.85996322]\t Bias: [6.61659807]\t Cost: 17.037963929195985\n",
            "Iteration: 635\t Weight1: [7.62092696]\t Weight2: [2.85723098]\t Bias: [6.60297793]\t Cost: 17.027725087659565\n",
            "Iteration: 636\t Weight1: [7.62440423]\t Weight2: [2.85449958]\t Bias: [6.58940595]\t Cost: 17.01755458232031\n",
            "Iteration: 637\t Weight1: [7.62787364]\t Weight2: [2.85176904]\t Bias: [6.57588196]\t Cost: 17.007451939258257\n",
            "Iteration: 638\t Weight1: [7.63133518]\t Weight2: [2.84903939]\t Bias: [6.56240578]\t Cost: 16.99741668794919\n",
            "Iteration: 639\t Weight1: [7.63478889]\t Weight2: [2.84631064]\t Bias: [6.54897723]\t Cost: 16.987448361239633\n",
            "Iteration: 640\t Weight1: [7.63823478]\t Weight2: [2.84358283]\t Bias: [6.53559615]\t Cost: 16.977546495322095\n",
            "Iteration: 641\t Weight1: [7.64167286]\t Weight2: [2.84085596]\t Bias: [6.52226236]\t Cost: 16.96771062971051\n",
            "Iteration: 642\t Weight1: [7.64510315]\t Weight2: [2.83813007]\t Bias: [6.50897569]\t Cost: 16.95794030721567\n",
            "Iteration: 643\t Weight1: [7.64852566]\t Weight2: [2.83540517]\t Bias: [6.49573596]\t Cost: 16.948235073921182\n",
            "Iteration: 644\t Weight1: [7.65194042]\t Weight2: [2.83268128]\t Bias: [6.48254301]\t Cost: 16.938594479159292\n",
            "Iteration: 645\t Weight1: [7.65534743]\t Weight2: [2.82995843]\t Bias: [6.46939667]\t Cost: 16.92901807548706\n",
            "Iteration: 646\t Weight1: [7.65874671]\t Weight2: [2.82723664]\t Bias: [6.45629677]\t Cost: 16.91950541866267\n",
            "Iteration: 647\t Weight1: [7.66213828]\t Weight2: [2.82451593]\t Bias: [6.44324313]\t Cost: 16.910056067621905\n",
            "Iteration: 648\t Weight1: [7.66552215]\t Weight2: [2.82179632]\t Bias: [6.43023559]\t Cost: 16.900669584454825\n",
            "Iteration: 649\t Weight1: [7.66889834]\t Weight2: [2.81907783]\t Bias: [6.41727399]\t Cost: 16.891345534382555\n",
            "Iteration: 650\t Weight1: [7.67226687]\t Weight2: [2.81636048]\t Bias: [6.40435815]\t Cost: 16.882083485734384\n",
            "Iteration: 651\t Weight1: [7.67562774]\t Weight2: [2.81364429]\t Bias: [6.3914879]\t Cost: 16.872883009924852\n",
            "Iteration: 652\t Weight1: [7.67898098]\t Weight2: [2.81092928]\t Bias: [6.37866309]\t Cost: 16.863743681431178\n",
            "Iteration: 653\t Weight1: [7.6823266]\t Weight2: [2.80821548]\t Bias: [6.36588355]\t Cost: 16.854665077770743\n",
            "Iteration: 654\t Weight1: [7.68566462]\t Weight2: [2.80550289]\t Bias: [6.35314911]\t Cost: 16.845646779478805\n",
            "Iteration: 655\t Weight1: [7.68899505]\t Weight2: [2.80279155]\t Bias: [6.34045961]\t Cost: 16.836688370086353\n",
            "Iteration: 656\t Weight1: [7.69231791]\t Weight2: [2.80008147]\t Bias: [6.32781488]\t Cost: 16.827789436098087\n",
            "Iteration: 657\t Weight1: [7.69563321]\t Weight2: [2.79737267]\t Bias: [6.31521477]\t Cost: 16.818949566970712\n",
            "Iteration: 658\t Weight1: [7.69894096]\t Weight2: [2.79466516]\t Bias: [6.3026591]\t Cost: 16.810168355091157\n",
            "Iteration: 659\t Weight1: [7.70224119]\t Weight2: [2.79195898]\t Bias: [6.29014773]\t Cost: 16.801445395755213\n",
            "Iteration: 660\t Weight1: [7.70553391]\t Weight2: [2.78925413]\t Bias: [6.27768048]\t Cost: 16.792780287146105\n",
            "Iteration: 661\t Weight1: [7.70881913]\t Weight2: [2.78655065]\t Bias: [6.2652572]\t Cost: 16.78417263031341\n",
            "Iteration: 662\t Weight1: [7.71209687]\t Weight2: [2.78384853]\t Bias: [6.25287773]\t Cost: 16.775622029152004\n",
            "Iteration: 663\t Weight1: [7.71536715]\t Weight2: [2.78114782]\t Bias: [6.24054191]\t Cost: 16.767128090381217\n",
            "Iteration: 664\t Weight1: [7.71862998]\t Weight2: [2.77844851]\t Bias: [6.22824958]\t Cost: 16.758690423524175\n",
            "Iteration: 665\t Weight1: [7.72188537]\t Weight2: [2.77575064]\t Bias: [6.21600057]\t Cost: 16.7503086408872\n",
            "Iteration: 666\t Weight1: [7.72513334]\t Weight2: [2.77305422]\t Bias: [6.20379475]\t Cost: 16.741982357539467\n",
            "Iteration: 667\t Weight1: [7.7283739]\t Weight2: [2.77035926]\t Bias: [6.19163194]\t Cost: 16.73371119129277\n",
            "Iteration: 668\t Weight1: [7.73160708]\t Weight2: [2.76766579]\t Bias: [6.17951199]\t Cost: 16.72549476268143\n",
            "Iteration: 669\t Weight1: [7.73483288]\t Weight2: [2.76497383]\t Bias: [6.16743475]\t Cost: 16.71733269494237\n",
            "Iteration: 670\t Weight1: [7.73805132]\t Weight2: [2.76228338]\t Bias: [6.15540006]\t Cost: 16.709224613995296\n",
            "Iteration: 671\t Weight1: [7.74126242]\t Weight2: [2.75959448]\t Bias: [6.14340777]\t Cost: 16.70117014842315\n",
            "Iteration: 672\t Weight1: [7.74446619]\t Weight2: [2.75690713]\t Bias: [6.13145772]\t Cost: 16.693168929452536\n",
            "Iteration: 673\t Weight1: [7.74766265]\t Weight2: [2.75422136]\t Bias: [6.11954976]\t Cost: 16.685220590934403\n",
            "Iteration: 674\t Weight1: [7.7508518]\t Weight2: [2.75153717]\t Bias: [6.10768373]\t Cost: 16.67732476932488\n",
            "Iteration: 675\t Weight1: [7.75403367]\t Weight2: [2.7488546]\t Bias: [6.09585949]\t Cost: 16.669481103666154\n",
            "Iteration: 676\t Weight1: [7.75720828]\t Weight2: [2.74617365]\t Bias: [6.08407688]\t Cost: 16.661689235567643\n",
            "Iteration: 677\t Weight1: [7.76037562]\t Weight2: [2.74349434]\t Bias: [6.07233575]\t Cost: 16.653948809187202\n",
            "Iteration: 678\t Weight1: [7.76353573]\t Weight2: [2.7408167]\t Bias: [6.06063596]\t Cost: 16.646259471212375\n",
            "Iteration: 679\t Weight1: [7.76668862]\t Weight2: [2.73814072]\t Bias: [6.04897734]\t Cost: 16.638620870842114\n",
            "Iteration: 680\t Weight1: [7.76983429]\t Weight2: [2.73546644]\t Bias: [6.03735976]\t Cost: 16.631032659768266\n",
            "Iteration: 681\t Weight1: [7.77297277]\t Weight2: [2.73279387]\t Bias: [6.02578306]\t Cost: 16.62349449215737\n",
            "Iteration: 682\t Weight1: [7.77610407]\t Weight2: [2.73012302]\t Bias: [6.01424709]\t Cost: 16.616006024632668\n",
            "Iteration: 683\t Weight1: [7.77922821]\t Weight2: [2.72745392]\t Bias: [6.00275171]\t Cost: 16.60856691625609\n",
            "Iteration: 684\t Weight1: [7.78234519]\t Weight2: [2.72478657]\t Bias: [5.99129677]\t Cost: 16.60117682851045\n",
            "Iteration: 685\t Weight1: [7.78545504]\t Weight2: [2.72212099]\t Bias: [5.97988212]\t Cost: 16.593835425281757\n",
            "Iteration: 686\t Weight1: [7.78855777]\t Weight2: [2.7194572]\t Bias: [5.96850762]\t Cost: 16.586542372841706\n",
            "Iteration: 687\t Weight1: [7.79165339]\t Weight2: [2.71679521]\t Bias: [5.95717312]\t Cost: 16.57929733983023\n",
            "Iteration: 688\t Weight1: [7.79474192]\t Weight2: [2.71413505]\t Bias: [5.94587848]\t Cost: 16.572099997238265\n",
            "Iteration: 689\t Weight1: [7.79782337]\t Weight2: [2.71147671]\t Bias: [5.93462354]\t Cost: 16.56495001839049\n",
            "Iteration: 690\t Weight1: [7.80089777]\t Weight2: [2.70882023]\t Bias: [5.92340818]\t Cost: 16.557847078928393\n",
            "Iteration: 691\t Weight1: [7.80396511]\t Weight2: [2.70616561]\t Bias: [5.91223224]\t Cost: 16.550790856793366\n",
            "Iteration: 692\t Weight1: [7.80702542]\t Weight2: [2.70351288]\t Bias: [5.90109558]\t Cost: 16.543781032209864\n",
            "Iteration: 693\t Weight1: [7.81007871]\t Weight2: [2.70086203]\t Bias: [5.88999806]\t Cost: 16.536817287668804\n",
            "Iteration: 694\t Weight1: [7.813125]\t Weight2: [2.6982131]\t Bias: [5.87893954]\t Cost: 16.529899307911034\n",
            "Iteration: 695\t Weight1: [7.8161643]\t Weight2: [2.69556609]\t Bias: [5.86791987]\t Cost: 16.523026779910897\n",
            "Iteration: 696\t Weight1: [7.81919663]\t Weight2: [2.69292102]\t Bias: [5.85693892]\t Cost: 16.516199392860027\n",
            "Iteration: 697\t Weight1: [7.82222199]\t Weight2: [2.6902779]\t Bias: [5.84599655]\t Cost: 16.509416838151097\n",
            "Iteration: 698\t Weight1: [7.82524041]\t Weight2: [2.68763675]\t Bias: [5.83509261]\t Cost: 16.5026788093618\n",
            "Iteration: 699\t Weight1: [7.82825189]\t Weight2: [2.68499758]\t Bias: [5.82422696]\t Cost: 16.495985002239003\n",
            "Iteration: 700\t Weight1: [7.83125646]\t Weight2: [2.68236041]\t Bias: [5.81339947]\t Cost: 16.489335114682884\n",
            "Iteration: 701\t Weight1: [7.83425413]\t Weight2: [2.67972525]\t Bias: [5.80261001]\t Cost: 16.48272884673118\n",
            "Iteration: 702\t Weight1: [7.83724491]\t Weight2: [2.67709211]\t Bias: [5.79185842]\t Cost: 16.476165900543794\n",
            "Iteration: 703\t Weight1: [7.84022881]\t Weight2: [2.67446101]\t Bias: [5.78114458]\t Cost: 16.469645980387188\n",
            "Iteration: 704\t Weight1: [7.84320586]\t Weight2: [2.67183196]\t Bias: [5.77046834]\t Cost: 16.463168792619133\n",
            "Iteration: 705\t Weight1: [7.84617606]\t Weight2: [2.66920497]\t Bias: [5.75982958]\t Cost: 16.456734045673425\n",
            "Iteration: 706\t Weight1: [7.84913943]\t Weight2: [2.66658007]\t Bias: [5.74922815]\t Cost: 16.45034145004487\n",
            "Iteration: 707\t Weight1: [7.85209598]\t Weight2: [2.66395725]\t Bias: [5.73866393]\t Cost: 16.44399071827413\n",
            "Iteration: 708\t Weight1: [7.85504573]\t Weight2: [2.66133654]\t Bias: [5.72813677]\t Cost: 16.437681564933058\n",
            "Iteration: 709\t Weight1: [7.85798869]\t Weight2: [2.65871794]\t Bias: [5.71764654]\t Cost: 16.431413706609707\n",
            "Iteration: 710\t Weight1: [7.86092488]\t Weight2: [2.65610148]\t Bias: [5.70719311]\t Cost: 16.425186861893806\n",
            "Iteration: 711\t Weight1: [7.8638543]\t Weight2: [2.65348716]\t Bias: [5.69677634]\t Cost: 16.419000751362155\n",
            "Iteration: 712\t Weight1: [7.86677698]\t Weight2: [2.65087499]\t Bias: [5.68639611]\t Cost: 16.412855097564176\n",
            "Iteration: 713\t Weight1: [7.86969293]\t Weight2: [2.648265]\t Bias: [5.67605228]\t Cost: 16.406749625007592\n",
            "Iteration: 714\t Weight1: [7.87260216]\t Weight2: [2.64565719]\t Bias: [5.66574472]\t Cost: 16.40068406014417\n",
            "Iteration: 715\t Weight1: [7.87550469]\t Weight2: [2.64305157]\t Bias: [5.6554733]\t Cost: 16.394658131355616\n",
            "Iteration: 716\t Weight1: [7.87840052]\t Weight2: [2.64044815]\t Bias: [5.64523788]\t Cost: 16.388671568939596\n",
            "Iteration: 717\t Weight1: [7.88128969]\t Weight2: [2.63784696]\t Bias: [5.63503834]\t Cost: 16.382724105095686\n",
            "Iteration: 718\t Weight1: [7.88417219]\t Weight2: [2.63524799]\t Bias: [5.62487454]\t Cost: 16.376815473911684\n",
            "Iteration: 719\t Weight1: [7.88704804]\t Weight2: [2.63265127]\t Bias: [5.61474637]\t Cost: 16.370945411349865\n",
            "Iteration: 720\t Weight1: [7.88991726]\t Weight2: [2.63005681]\t Bias: [5.60465368]\t Cost: 16.365113655233323\n",
            "Iteration: 721\t Weight1: [7.89277985]\t Weight2: [2.62746461]\t Bias: [5.59459635]\t Cost: 16.359319945232574\n",
            "Iteration: 722\t Weight1: [7.89563585]\t Weight2: [2.62487468]\t Bias: [5.58457426]\t Cost: 16.353564022851984\n",
            "Iteration: 723\t Weight1: [7.89848525]\t Weight2: [2.62228705]\t Bias: [5.57458727]\t Cost: 16.347845631416643\n",
            "Iteration: 724\t Weight1: [7.90132807]\t Weight2: [2.61970172]\t Bias: [5.56463526]\t Cost: 16.342164516058986\n",
            "Iteration: 725\t Weight1: [7.90416432]\t Weight2: [2.6171187]\t Bias: [5.55471811]\t Cost: 16.336520423705824\n",
            "Iteration: 726\t Weight1: [7.90699403]\t Weight2: [2.61453801]\t Bias: [5.54483568]\t Cost: 16.330913103065217\n",
            "Iteration: 727\t Weight1: [7.9098172]\t Weight2: [2.61195965]\t Bias: [5.53498785]\t Cost: 16.32534230461364\n",
            "Iteration: 728\t Weight1: [7.91263385]\t Weight2: [2.60938364]\t Bias: [5.52517449]\t Cost: 16.31980778058311\n",
            "Iteration: 729\t Weight1: [7.91544398]\t Weight2: [2.60680999]\t Bias: [5.51539549]\t Cost: 16.314309284948486\n",
            "Iteration: 730\t Weight1: [7.91824763]\t Weight2: [2.6042387]\t Bias: [5.50565072]\t Cost: 16.30884657341481\n",
            "Iteration: 731\t Weight1: [7.92104479]\t Weight2: [2.6016698]\t Bias: [5.49594005]\t Cost: 16.303419403404806\n",
            "Iteration: 732\t Weight1: [7.92383548]\t Weight2: [2.59910328]\t Bias: [5.48626336]\t Cost: 16.298027534046415\n",
            "Iteration: 733\t Weight1: [7.92661971]\t Weight2: [2.59653917]\t Bias: [5.47662052]\t Cost: 16.292670726160427\n",
            "Iteration: 734\t Weight1: [7.92939751]\t Weight2: [2.59397747]\t Bias: [5.46701143]\t Cost: 16.28734874224823\n",
            "Iteration: 735\t Weight1: [7.93216888]\t Weight2: [2.59141819]\t Bias: [5.45743594]\t Cost: 16.282061346479654\n",
            "Iteration: 736\t Weight1: [7.93493383]\t Weight2: [2.58886134]\t Bias: [5.44789395]\t Cost: 16.27680830468089\n",
            "Iteration: 737\t Weight1: [7.93769239]\t Weight2: [2.58630694]\t Bias: [5.43838533]\t Cost: 16.271589384322496\n",
            "Iteration: 738\t Weight1: [7.94044455]\t Weight2: [2.58375498]\t Bias: [5.42890997]\t Cost: 16.266404354507447\n",
            "Iteration: 739\t Weight1: [7.94319035]\t Weight2: [2.5812055]\t Bias: [5.41946773]\t Cost: 16.261252985959363\n",
            "Iteration: 740\t Weight1: [7.94592978]\t Weight2: [2.57865848]\t Bias: [5.4100585]\t Cost: 16.25613505101084\n",
            "Iteration: 741\t Weight1: [7.94866287]\t Weight2: [2.57611395]\t Bias: [5.40068217]\t Cost: 16.25105032359173\n",
            "Iteration: 742\t Weight1: [7.95138963]\t Weight2: [2.57357191]\t Bias: [5.39133861]\t Cost: 16.245998579217567\n",
            "Iteration: 743\t Weight1: [7.95411006]\t Weight2: [2.57103237]\t Bias: [5.38202771]\t Cost: 16.2409795949782\n",
            "Iteration: 744\t Weight1: [7.95682419]\t Weight2: [2.56849535]\t Bias: [5.37274935]\t Cost: 16.235993149526337\n",
            "Iteration: 745\t Weight1: [7.95953203]\t Weight2: [2.56596084]\t Bias: [5.3635034]\t Cost: 16.231039023066234\n",
            "Iteration: 746\t Weight1: [7.96223358]\t Weight2: [2.56342887]\t Bias: [5.35428976]\t Cost: 16.226116997342576\n",
            "Iteration: 747\t Weight1: [7.96492888]\t Weight2: [2.56089944]\t Bias: [5.34510831]\t Cost: 16.2212268556292\n",
            "Iteration: 748\t Weight1: [7.96761791]\t Weight2: [2.55837256]\t Bias: [5.33595892]\t Cost: 16.216368382718215\n",
            "Iteration: 749\t Weight1: [7.97030071]\t Weight2: [2.55584824]\t Bias: [5.32684149]\t Cost: 16.211541364908836\n",
            "Iteration: 750\t Weight1: [7.97297729]\t Weight2: [2.55332649]\t Bias: [5.31775591]\t Cost: 16.20674558999673\n",
            "Iteration: 751\t Weight1: [7.97564765]\t Weight2: [2.55080731]\t Bias: [5.30870204]\t Cost: 16.201980847262995\n",
            "Iteration: 752\t Weight1: [7.97831181]\t Weight2: [2.54829073]\t Bias: [5.29967979]\t Cost: 16.197246927463574\n",
            "Iteration: 753\t Weight1: [7.98096978]\t Weight2: [2.54577673]\t Bias: [5.29068904]\t Cost: 16.19254362281854\n",
            "Iteration: 754\t Weight1: [7.98362158]\t Weight2: [2.54326534]\t Bias: [5.28172967]\t Cost: 16.187870727001552\n",
            "Iteration: 755\t Weight1: [7.98626722]\t Weight2: [2.54075657]\t Bias: [5.27280157]\t Cost: 16.183228035129392\n",
            "Iteration: 756\t Weight1: [7.98890671]\t Weight2: [2.53825041]\t Bias: [5.26390462]\t Cost: 16.1786153437515\n",
            "Iteration: 757\t Weight1: [7.99154007]\t Weight2: [2.53574689]\t Bias: [5.25503873]\t Cost: 16.17403245083966\n",
            "Iteration: 758\t Weight1: [7.99416731]\t Weight2: [2.533246]\t Bias: [5.24620376]\t Cost: 16.169479155777747\n",
            "Iteration: 759\t Weight1: [7.99678844]\t Weight2: [2.53074777]\t Bias: [5.23739962]\t Cost: 16.164955259351586\n",
            "Iteration: 760\t Weight1: [7.99940347]\t Weight2: [2.52825218]\t Bias: [5.22862619]\t Cost: 16.160460563738738\n",
            "Iteration: 761\t Weight1: [8.00201243]\t Weight2: [2.52575926]\t Bias: [5.21988336]\t Cost: 16.15599487249856\n",
            "Iteration: 762\t Weight1: [8.00461531]\t Weight2: [2.52326901]\t Bias: [5.21117102]\t Cost: 16.151557990562228\n",
            "Iteration: 763\t Weight1: [8.00721214]\t Weight2: [2.52078144]\t Bias: [5.20248906]\t Cost: 16.147149724222825\n",
            "Iteration: 764\t Weight1: [8.00980292]\t Weight2: [2.51829656]\t Bias: [5.19383737]\t Cost: 16.14276988112557\n",
            "Iteration: 765\t Weight1: [8.01238768]\t Weight2: [2.51581438]\t Bias: [5.18521585]\t Cost: 16.138418270258008\n",
            "Iteration: 766\t Weight1: [8.01496641]\t Weight2: [2.5133349]\t Bias: [5.17662438]\t Cost: 16.134094701940434\n",
            "Iteration: 767\t Weight1: [8.01753915]\t Weight2: [2.51085812]\t Bias: [5.16806285]\t Cost: 16.12979898781622\n",
            "Iteration: 768\t Weight1: [8.02010589]\t Weight2: [2.50838407]\t Bias: [5.15953116]\t Cost: 16.12553094084235\n",
            "Iteration: 769\t Weight1: [8.02266665]\t Weight2: [2.50591275]\t Bias: [5.1510292]\t Cost: 16.121290375279912\n",
            "Iteration: 770\t Weight1: [8.02522145]\t Weight2: [2.50344415]\t Bias: [5.14255687]\t Cost: 16.11707710668475\n",
            "Iteration: 771\t Weight1: [8.02777029]\t Weight2: [2.5009783]\t Bias: [5.13411405]\t Cost: 16.112890951898105\n",
            "Iteration: 772\t Weight1: [8.0303132]\t Weight2: [2.4985152]\t Bias: [5.12570064]\t Cost: 16.108731729037462\n",
            "Iteration: 773\t Weight1: [8.03285017]\t Weight2: [2.49605485]\t Bias: [5.11731654]\t Cost: 16.104599257487227\n",
            "Iteration: 774\t Weight1: [8.03538123]\t Weight2: [2.49359727]\t Bias: [5.10896164]\t Cost: 16.100493357889743\n",
            "Iteration: 775\t Weight1: [8.03790639]\t Weight2: [2.49114246]\t Bias: [5.10063583]\t Cost: 16.0964138521362\n",
            "Iteration: 776\t Weight1: [8.04042566]\t Weight2: [2.48869042]\t Bias: [5.09233901]\t Cost: 16.09236056335763\n",
            "Iteration: 777\t Weight1: [8.04293906]\t Weight2: [2.48624117]\t Bias: [5.08407107]\t Cost: 16.088333315916024\n",
            "Iteration: 778\t Weight1: [8.04544658]\t Weight2: [2.48379471]\t Bias: [5.07583192]\t Cost: 16.08433193539549\n",
            "Iteration: 779\t Weight1: [8.04794826]\t Weight2: [2.48135105]\t Bias: [5.06762144]\t Cost: 16.080356248593464\n",
            "Iteration: 780\t Weight1: [8.0504441]\t Weight2: [2.47891019]\t Bias: [5.05943954]\t Cost: 16.076406083512015\n",
            "Iteration: 781\t Weight1: [8.05293411]\t Weight2: [2.47647214]\t Bias: [5.05128611]\t Cost: 16.072481269349144\n",
            "Iteration: 782\t Weight1: [8.0554183]\t Weight2: [2.47403692]\t Bias: [5.04316106]\t Cost: 16.068581636490233\n",
            "Iteration: 783\t Weight1: [8.0578967]\t Weight2: [2.47160451]\t Bias: [5.03506427]\t Cost: 16.064707016499533\n",
            "Iteration: 784\t Weight1: [8.06036931]\t Weight2: [2.46917494]\t Bias: [5.02699564]\t Cost: 16.06085724211165\n",
            "Iteration: 785\t Weight1: [8.06283614]\t Weight2: [2.46674821]\t Bias: [5.01895508]\t Cost: 16.057032147223204\n",
            "Iteration: 786\t Weight1: [8.0652972]\t Weight2: [2.46432431]\t Bias: [5.01094249]\t Cost: 16.05323156688448\n",
            "Iteration: 787\t Weight1: [8.06775252]\t Weight2: [2.46190327]\t Bias: [5.00295776]\t Cost: 16.049455337291064\n",
            "Iteration: 788\t Weight1: [8.07020209]\t Weight2: [2.45948509]\t Bias: [4.99500079]\t Cost: 16.04570329577582\n",
            "Iteration: 789\t Weight1: [8.07264594]\t Weight2: [2.45706977]\t Bias: [4.98707149]\t Cost: 16.04197528080053\n",
            "Iteration: 790\t Weight1: [8.07508407]\t Weight2: [2.45465731]\t Bias: [4.97916975]\t Cost: 16.03827113194788\n",
            "Iteration: 791\t Weight1: [8.0775165]\t Weight2: [2.45224773]\t Bias: [4.97129547]\t Cost: 16.034590689913497\n",
            "Iteration: 792\t Weight1: [8.07994324]\t Weight2: [2.44984103]\t Bias: [4.96344857]\t Cost: 16.030933796497848\n",
            "Iteration: 793\t Weight1: [8.08236431]\t Weight2: [2.44743722]\t Bias: [4.95562893]\t Cost: 16.027300294598405\n",
            "Iteration: 794\t Weight1: [8.08477971]\t Weight2: [2.4450363]\t Bias: [4.94783646]\t Cost: 16.023690028201756\n",
            "Iteration: 795\t Weight1: [8.08718945]\t Weight2: [2.44263828]\t Bias: [4.94007107]\t Cost: 16.020102842375827\n",
            "Iteration: 796\t Weight1: [8.08959356]\t Weight2: [2.44024315]\t Bias: [4.93233265]\t Cost: 16.016538583262115\n",
            "Iteration: 797\t Weight1: [8.09199203]\t Weight2: [2.43785094]\t Bias: [4.92462111]\t Cost: 16.012997098067977\n",
            "Iteration: 798\t Weight1: [8.09438489]\t Weight2: [2.43546165]\t Bias: [4.91693635]\t Cost: 16.009478235059042\n",
            "Iteration: 799\t Weight1: [8.09677215]\t Weight2: [2.43307527]\t Bias: [4.90927829]\t Cost: 16.00598184355166\n",
            "Iteration: 800\t Weight1: [8.09915381]\t Weight2: [2.43069182]\t Bias: [4.90164681]\t Cost: 16.002507773905297\n",
            "Iteration: 801\t Weight1: [8.10152989]\t Weight2: [2.42831129]\t Bias: [4.89404182]\t Cost: 15.999055877515154\n",
            "Iteration: 802\t Weight1: [8.10390041]\t Weight2: [2.42593371]\t Bias: [4.88646324]\t Cost: 15.995626006804706\n",
            "Iteration: 803\t Weight1: [8.10626536]\t Weight2: [2.42355906]\t Bias: [4.87891096]\t Cost: 15.99221801521839\n",
            "Iteration: 804\t Weight1: [8.10862478]\t Weight2: [2.42118736]\t Bias: [4.8713849]\t Cost: 15.988831757214246\n",
            "Iteration: 805\t Weight1: [8.11097866]\t Weight2: [2.41881861]\t Bias: [4.86388495]\t Cost: 15.985467088256746\n",
            "Iteration: 806\t Weight1: [8.11332703]\t Weight2: [2.41645282]\t Bias: [4.85641102]\t Cost: 15.982123864809523\n",
            "Iteration: 807\t Weight1: [8.11566988]\t Weight2: [2.41408999]\t Bias: [4.84896303]\t Cost: 15.978801944328278\n",
            "Iteration: 808\t Weight1: [8.11800724]\t Weight2: [2.41173013]\t Bias: [4.84154087]\t Cost: 15.975501185253693\n",
            "Iteration: 809\t Weight1: [8.12033912]\t Weight2: [2.40937323]\t Bias: [4.83414446]\t Cost: 15.972221447004399\n",
            "Iteration: 810\t Weight1: [8.12266552]\t Weight2: [2.40701931]\t Bias: [4.8267737]\t Cost: 15.968962589969909\n",
            "Iteration: 811\t Weight1: [8.12498646]\t Weight2: [2.40466837]\t Bias: [4.8194285]\t Cost: 15.965724475503821\n",
            "Iteration: 812\t Weight1: [8.12730196]\t Weight2: [2.40232042]\t Bias: [4.81210877]\t Cost: 15.962506965916837\n",
            "Iteration: 813\t Weight1: [8.12961202]\t Weight2: [2.39997545]\t Bias: [4.80481441]\t Cost: 15.959309924469936\n",
            "Iteration: 814\t Weight1: [8.13191665]\t Weight2: [2.39763348]\t Bias: [4.79754535]\t Cost: 15.956133215367647\n",
            "Iteration: 815\t Weight1: [8.13421587]\t Weight2: [2.39529451]\t Bias: [4.79030147]\t Cost: 15.952976703751272\n",
            "Iteration: 816\t Weight1: [8.13650969]\t Weight2: [2.39295854]\t Bias: [4.78308271]\t Cost: 15.94984025569223\n",
            "Iteration: 817\t Weight1: [8.13879812]\t Weight2: [2.39062557]\t Bias: [4.77588896]\t Cost: 15.946723738185385\n",
            "Iteration: 818\t Weight1: [8.14108118]\t Weight2: [2.38829562]\t Bias: [4.76872014]\t Cost: 15.943627019142472\n",
            "Iteration: 819\t Weight1: [8.14335886]\t Weight2: [2.38596868]\t Bias: [4.76157615]\t Cost: 15.940549967385621\n",
            "Iteration: 820\t Weight1: [8.1456312]\t Weight2: [2.38364476]\t Bias: [4.75445691]\t Cost: 15.937492452640768\n",
            "Iteration: 821\t Weight1: [8.14789819]\t Weight2: [2.38132387]\t Bias: [4.74736233]\t Cost: 15.93445434553131\n",
            "Iteration: 822\t Weight1: [8.15015985]\t Weight2: [2.379006]\t Bias: [4.74029232]\t Cost: 15.93143551757162\n",
            "Iteration: 823\t Weight1: [8.15241619]\t Weight2: [2.37669117]\t Bias: [4.7332468]\t Cost: 15.92843584116076\n",
            "Iteration: 824\t Weight1: [8.15466722]\t Weight2: [2.37437937]\t Bias: [4.72622567]\t Cost: 15.925455189576162\n",
            "Iteration: 825\t Weight1: [8.15691296]\t Weight2: [2.37207061]\t Bias: [4.71922884]\t Cost: 15.922493436967393\n",
            "Iteration: 826\t Weight1: [8.15915341]\t Weight2: [2.36976489]\t Bias: [4.71225624]\t Cost: 15.919550458349923\n",
            "Iteration: 827\t Weight1: [8.1613886]\t Weight2: [2.36746222]\t Bias: [4.70530778]\t Cost: 15.916626129598912\n",
            "Iteration: 828\t Weight1: [8.16361852]\t Weight2: [2.3651626]\t Bias: [4.69838336]\t Cost: 15.913720327443228\n",
            "Iteration: 829\t Weight1: [8.16584319]\t Weight2: [2.36286603]\t Bias: [4.6914829]\t Cost: 15.910832929459191\n",
            "Iteration: 830\t Weight1: [8.16806262]\t Weight2: [2.36057253]\t Bias: [4.68460632]\t Cost: 15.90796381406474\n",
            "Iteration: 831\t Weight1: [8.17027682]\t Weight2: [2.35828208]\t Bias: [4.67775353]\t Cost: 15.905112860513295\n",
            "Iteration: 832\t Weight1: [8.17248581]\t Weight2: [2.3559947]\t Bias: [4.67092444]\t Cost: 15.902279948887866\n",
            "Iteration: 833\t Weight1: [8.1746896]\t Weight2: [2.35371038]\t Bias: [4.66411898]\t Cost: 15.899464960095187\n",
            "Iteration: 834\t Weight1: [8.17688819]\t Weight2: [2.35142914]\t Bias: [4.65733705]\t Cost: 15.896667775859802\n",
            "Iteration: 835\t Weight1: [8.1790816]\t Weight2: [2.34915097]\t Bias: [4.65057858]\t Cost: 15.893888278718292\n",
            "Iteration: 836\t Weight1: [8.18126984]\t Weight2: [2.34687589]\t Bias: [4.64384347]\t Cost: 15.89112635201353\n",
            "Iteration: 837\t Weight1: [8.18345293]\t Weight2: [2.34460388]\t Bias: [4.63713165]\t Cost: 15.888381879888838\n",
            "Iteration: 838\t Weight1: [8.18563086]\t Weight2: [2.34233496]\t Bias: [4.63044303]\t Cost: 15.885654747282455\n",
            "Iteration: 839\t Weight1: [8.18780366]\t Weight2: [2.34006912]\t Bias: [4.62377753]\t Cost: 15.882944839921787\n",
            "Iteration: 840\t Weight1: [8.18997134]\t Weight2: [2.33780637]\t Bias: [4.61713506]\t Cost: 15.880252044317867\n",
            "Iteration: 841\t Weight1: [8.1921339]\t Weight2: [2.33554672]\t Bias: [4.61051555]\t Cost: 15.877576247759693\n",
            "Iteration: 842\t Weight1: [8.19429136]\t Weight2: [2.33329017]\t Bias: [4.60391891]\t Cost: 15.874917338308878\n",
            "Iteration: 843\t Weight1: [8.19644373]\t Weight2: [2.33103671]\t Bias: [4.59734506]\t Cost: 15.87227520479394\n",
            "Iteration: 844\t Weight1: [8.19859102]\t Weight2: [2.32878636]\t Bias: [4.59079392]\t Cost: 15.869649736805105\n",
            "Iteration: 845\t Weight1: [8.20073325]\t Weight2: [2.32653911]\t Bias: [4.5842654]\t Cost: 15.867040824688724\n",
            "Iteration: 846\t Weight1: [8.20287041]\t Weight2: [2.32429497]\t Bias: [4.57775943]\t Cost: 15.864448359541978\n",
            "Iteration: 847\t Weight1: [8.20500253]\t Weight2: [2.32205394]\t Bias: [4.57127593]\t Cost: 15.861872233207556\n",
            "Iteration: 848\t Weight1: [8.20712961]\t Weight2: [2.31981603]\t Bias: [4.56481481]\t Cost: 15.859312338268369\n",
            "Iteration: 849\t Weight1: [8.20925167]\t Weight2: [2.31758123]\t Bias: [4.558376]\t Cost: 15.856768568042312\n",
            "Iteration: 850\t Weight1: [8.21136872]\t Weight2: [2.31534954]\t Bias: [4.55195941]\t Cost: 15.854240816577011\n",
            "Iteration: 851\t Weight1: [8.21348076]\t Weight2: [2.31312098]\t Bias: [4.54556497]\t Cost: 15.851728978644728\n",
            "Iteration: 852\t Weight1: [8.21558781]\t Weight2: [2.31089554]\t Bias: [4.5391926]\t Cost: 15.849232949737155\n",
            "Iteration: 853\t Weight1: [8.21768989]\t Weight2: [2.30867323]\t Bias: [4.53284222]\t Cost: 15.84675262606036\n",
            "Iteration: 854\t Weight1: [8.21978699]\t Weight2: [2.30645405]\t Bias: [4.52651375]\t Cost: 15.844287904529745\n",
            "Iteration: 855\t Weight1: [8.22187914]\t Weight2: [2.30423799]\t Bias: [4.52020711]\t Cost: 15.841838682764976\n",
            "Iteration: 856\t Weight1: [8.22396634]\t Weight2: [2.30202507]\t Bias: [4.51392222]\t Cost: 15.839404859085047\n",
            "Iteration: 857\t Weight1: [8.2260486]\t Weight2: [2.29981528]\t Bias: [4.50765901]\t Cost: 15.836986332503283\n",
            "Iteration: 858\t Weight1: [8.22812594]\t Weight2: [2.29760863]\t Bias: [4.5014174]\t Cost: 15.834583002722507\n",
            "Iteration: 859\t Weight1: [8.23019836]\t Weight2: [2.29540512]\t Bias: [4.49519732]\t Cost: 15.832194770130053\n",
            "Iteration: 860\t Weight1: [8.23226588]\t Weight2: [2.29320475]\t Bias: [4.48899867]\t Cost: 15.829821535793041\n",
            "Iteration: 861\t Weight1: [8.23432851]\t Weight2: [2.29100753]\t Bias: [4.4828214]\t Cost: 15.82746320145349\n",
            "Iteration: 862\t Weight1: [8.23638625]\t Weight2: [2.28881345]\t Bias: [4.47666542]\t Cost: 15.82511966952356\n",
            "Iteration: 863\t Weight1: [8.23843913]\t Weight2: [2.28662251]\t Bias: [4.47053066]\t Cost: 15.822790843080874\n",
            "Iteration: 864\t Weight1: [8.24048714]\t Weight2: [2.28443473]\t Bias: [4.46441703]\t Cost: 15.820476625863744\n",
            "Iteration: 865\t Weight1: [8.24253031]\t Weight2: [2.28225009]\t Bias: [4.45832448]\t Cost: 15.818176922266542\n",
            "Iteration: 866\t Weight1: [8.24456863]\t Weight2: [2.28006861]\t Bias: [4.45225291]\t Cost: 15.815891637335076\n",
            "Iteration: 867\t Weight1: [8.24660213]\t Weight2: [2.27789028]\t Bias: [4.44620226]\t Cost: 15.813620676761946\n",
            "Iteration: 868\t Weight1: [8.24863081]\t Weight2: [2.27571511]\t Bias: [4.44017245]\t Cost: 15.811363946882034\n",
            "Iteration: 869\t Weight1: [8.25065468]\t Weight2: [2.2735431]\t Bias: [4.43416341]\t Cost: 15.809121354667935\n",
            "Iteration: 870\t Weight1: [8.25267376]\t Weight2: [2.27137424]\t Bias: [4.42817506]\t Cost: 15.806892807725443\n",
            "Iteration: 871\t Weight1: [8.25468805]\t Weight2: [2.26920855]\t Bias: [4.42220733]\t Cost: 15.804678214289162\n",
            "Iteration: 872\t Weight1: [8.25669757]\t Weight2: [2.26704602]\t Bias: [4.41626014]\t Cost: 15.802477483217984\n",
            "Iteration: 873\t Weight1: [8.25870232]\t Weight2: [2.26488665]\t Bias: [4.41033343]\t Cost: 15.800290523990716\n",
            "Iteration: 874\t Weight1: [8.26070232]\t Weight2: [2.26273045]\t Bias: [4.40442712]\t Cost: 15.798117246701725\n",
            "Iteration: 875\t Weight1: [8.26269758]\t Weight2: [2.26057742]\t Bias: [4.39854113]\t Cost: 15.795957562056586\n",
            "Iteration: 876\t Weight1: [8.2646881]\t Weight2: [2.25842755]\t Bias: [4.3926754]\t Cost: 15.793811381367771\n",
            "Iteration: 877\t Weight1: [8.2666739]\t Weight2: [2.25628086]\t Bias: [4.38682985]\t Cost: 15.791678616550413\n",
            "Iteration: 878\t Weight1: [8.26865499]\t Weight2: [2.25413733]\t Bias: [4.38100441]\t Cost: 15.789559180117964\n",
            "Iteration: 879\t Weight1: [8.27063138]\t Weight2: [2.25199698]\t Bias: [4.37519901]\t Cost: 15.787452985178119\n",
            "Iteration: 880\t Weight1: [8.27260308]\t Weight2: [2.2498598]\t Bias: [4.36941358]\t Cost: 15.785359945428501\n",
            "Iteration: 881\t Weight1: [8.2745701]\t Weight2: [2.24772579]\t Bias: [4.36364804]\t Cost: 15.783279975152585\n",
            "Iteration: 882\t Weight1: [8.27653244]\t Weight2: [2.24559496]\t Bias: [4.35790233]\t Cost: 15.781212989215568\n",
            "Iteration: 883\t Weight1: [8.27849013]\t Weight2: [2.24346731]\t Bias: [4.35217638]\t Cost: 15.779158903060269\n",
            "Iteration: 884\t Weight1: [8.28044317]\t Weight2: [2.24134283]\t Bias: [4.34647011]\t Cost: 15.777117632703005\n",
            "Iteration: 885\t Weight1: [8.28239157]\t Weight2: [2.23922154]\t Bias: [4.34078345]\t Cost: 15.77508909472969\n",
            "Iteration: 886\t Weight1: [8.28433534]\t Weight2: [2.23710342]\t Bias: [4.33511634]\t Cost: 15.773073206291684\n",
            "Iteration: 887\t Weight1: [8.2862745]\t Weight2: [2.23498848]\t Bias: [4.32946871]\t Cost: 15.771069885101928\n",
            "Iteration: 888\t Weight1: [8.28820904]\t Weight2: [2.23287673]\t Bias: [4.32384048]\t Cost: 15.769079049430951\n",
            "Iteration: 889\t Weight1: [8.29013899]\t Weight2: [2.23076816]\t Bias: [4.31823159]\t Cost: 15.767100618102933\n",
            "Iteration: 890\t Weight1: [8.29206435]\t Weight2: [2.22866277]\t Bias: [4.31264196]\t Cost: 15.765134510491853\n",
            "Iteration: 891\t Weight1: [8.29398514]\t Weight2: [2.22656056]\t Bias: [4.30707154]\t Cost: 15.763180646517633\n",
            "Iteration: 892\t Weight1: [8.29590136]\t Weight2: [2.22446154]\t Bias: [4.30152025]\t Cost: 15.76123894664224\n",
            "Iteration: 893\t Weight1: [8.29781302]\t Weight2: [2.22236571]\t Bias: [4.29598802]\t Cost: 15.759309331865953\n",
            "Iteration: 894\t Weight1: [8.29972013]\t Weight2: [2.22027306]\t Bias: [4.29047478]\t Cost: 15.757391723723536\n",
            "Iteration: 895\t Weight1: [8.30162271]\t Weight2: [2.2181836]\t Bias: [4.28498048]\t Cost: 15.755486044280552\n",
            "Iteration: 896\t Weight1: [8.30352076]\t Weight2: [2.21609733]\t Bias: [4.27950503]\t Cost: 15.753592216129489\n",
            "Iteration: 897\t Weight1: [8.30541429]\t Weight2: [2.21401424]\t Bias: [4.27404838]\t Cost: 15.751710162386294\n",
            "Iteration: 898\t Weight1: [8.30730332]\t Weight2: [2.21193434]\t Bias: [4.26861046]\t Cost: 15.749839806686516\n",
            "Iteration: 899\t Weight1: [8.30918786]\t Weight2: [2.20985763]\t Bias: [4.2631912]\t Cost: 15.747981073181666\n",
            "Iteration: 900\t Weight1: [8.3110679]\t Weight2: [2.20778412]\t Bias: [4.25779053]\t Cost: 15.74613388653576\n",
            "Iteration: 901\t Weight1: [8.31294347]\t Weight2: [2.20571379]\t Bias: [4.25240839]\t Cost: 15.744298171921569\n",
            "Iteration: 902\t Weight1: [8.31481458]\t Weight2: [2.20364665]\t Bias: [4.24704471]\t Cost: 15.742473855017085\n",
            "Iteration: 903\t Weight1: [8.31668123]\t Weight2: [2.2015827]\t Bias: [4.24169943]\t Cost: 15.740660862002045\n",
            "Iteration: 904\t Weight1: [8.31854343]\t Weight2: [2.19952194]\t Bias: [4.23637248]\t Cost: 15.73885911955437\n",
            "Iteration: 905\t Weight1: [8.3204012]\t Weight2: [2.19746437]\t Bias: [4.2310638]\t Cost: 15.73706855484664\n",
            "Iteration: 906\t Weight1: [8.32225454]\t Weight2: [2.19541]\t Bias: [4.22577331]\t Cost: 15.735289095542761\n",
            "Iteration: 907\t Weight1: [8.32410347]\t Weight2: [2.19335882]\t Bias: [4.22050097]\t Cost: 15.733520669794338\n",
            "Iteration: 908\t Weight1: [8.32594799]\t Weight2: [2.19131082]\t Bias: [4.2152467]\t Cost: 15.731763206237403\n",
            "Iteration: 909\t Weight1: [8.32778811]\t Weight2: [2.18926602]\t Bias: [4.21001043]\t Cost: 15.730016633988996\n",
            "Iteration: 910\t Weight1: [8.32962384]\t Weight2: [2.18722442]\t Bias: [4.20479211]\t Cost: 15.728280882643789\n",
            "Iteration: 911\t Weight1: [8.3314552]\t Weight2: [2.185186]\t Bias: [4.19959167]\t Cost: 15.72655588227074\n",
            "Iteration: 912\t Weight1: [8.3332822]\t Weight2: [2.18315078]\t Bias: [4.19440905]\t Cost: 15.72484156340978\n",
            "Iteration: 913\t Weight1: [8.33510483]\t Weight2: [2.18111874]\t Bias: [4.18924418]\t Cost: 15.723137857068497\n",
            "Iteration: 914\t Weight1: [8.33692312]\t Weight2: [2.1790899]\t Bias: [4.184097]\t Cost: 15.721444694718953\n",
            "Iteration: 915\t Weight1: [8.33873707]\t Weight2: [2.17706426]\t Bias: [4.17896745]\t Cost: 15.719762008294346\n",
            "Iteration: 916\t Weight1: [8.34054669]\t Weight2: [2.1750418]\t Bias: [4.17385547]\t Cost: 15.7180897301858\n",
            "Iteration: 917\t Weight1: [8.342352]\t Weight2: [2.17302254]\t Bias: [4.16876099]\t Cost: 15.71642779323923\n",
            "Iteration: 918\t Weight1: [8.34415299]\t Weight2: [2.17100646]\t Bias: [4.16368395]\t Cost: 15.714776130752117\n",
            "Iteration: 919\t Weight1: [8.34594969]\t Weight2: [2.16899358]\t Bias: [4.15862429]\t Cost: 15.713134676470364\n",
            "Iteration: 920\t Weight1: [8.3477421]\t Weight2: [2.16698389]\t Bias: [4.15358195]\t Cost: 15.711503364585145\n",
            "Iteration: 921\t Weight1: [8.34953023]\t Weight2: [2.16497739]\t Bias: [4.14855687]\t Cost: 15.709882129729836\n",
            "Iteration: 922\t Weight1: [8.35131409]\t Weight2: [2.16297409]\t Bias: [4.14354898]\t Cost: 15.708270906976912\n",
            "Iteration: 923\t Weight1: [8.35309368]\t Weight2: [2.16097397]\t Bias: [4.13855822]\t Cost: 15.706669631834902\n",
            "Iteration: 924\t Weight1: [8.35486903]\t Weight2: [2.15897704]\t Bias: [4.13358454]\t Cost: 15.705078240245324\n",
            "Iteration: 925\t Weight1: [8.35664014]\t Weight2: [2.1569833]\t Bias: [4.12862787]\t Cost: 15.70349666857968\n",
            "Iteration: 926\t Weight1: [8.35840702]\t Weight2: [2.15499275]\t Bias: [4.12368816]\t Cost: 15.701924853636399\n",
            "Iteration: 927\t Weight1: [8.36016967]\t Weight2: [2.15300539]\t Bias: [4.11876533]\t Cost: 15.700362732638014\n",
            "Iteration: 928\t Weight1: [8.36192811]\t Weight2: [2.15102122]\t Bias: [4.11385935]\t Cost: 15.698810243228053\n",
            "Iteration: 929\t Weight1: [8.36368235]\t Weight2: [2.14904024]\t Bias: [4.10897013]\t Cost: 15.697267323468155\n",
            "Iteration: 930\t Weight1: [8.36543239]\t Weight2: [2.14706244]\t Bias: [4.10409763]\t Cost: 15.695733911835214\n",
            "Iteration: 931\t Weight1: [8.36717825]\t Weight2: [2.14508783]\t Bias: [4.09924178]\t Cost: 15.694209947218406\n",
            "Iteration: 932\t Weight1: [8.36891994]\t Weight2: [2.14311641]\t Bias: [4.09440253]\t Cost: 15.692695368916368\n",
            "Iteration: 933\t Weight1: [8.37065746]\t Weight2: [2.14114817]\t Bias: [4.08957981]\t Cost: 15.691190116634326\n",
            "Iteration: 934\t Weight1: [8.37239083]\t Weight2: [2.13918311]\t Bias: [4.08477357]\t Cost: 15.689694130481309\n",
            "Iteration: 935\t Weight1: [8.37412005]\t Weight2: [2.13722124]\t Bias: [4.07998376]\t Cost: 15.688207350967248\n",
            "Iteration: 936\t Weight1: [8.37584513]\t Weight2: [2.13526256]\t Bias: [4.0752103]\t Cost: 15.686729719000315\n",
            "Iteration: 937\t Weight1: [8.37756608]\t Weight2: [2.13330706]\t Bias: [4.07045315]\t Cost: 15.685261175884067\n",
            "Iteration: 938\t Weight1: [8.37928292]\t Weight2: [2.13135474]\t Bias: [4.06571224]\t Cost: 15.68380166331467\n",
            "Iteration: 939\t Weight1: [8.38099564]\t Weight2: [2.1294056]\t Bias: [4.06098753]\t Cost: 15.68235112337829\n",
            "Iteration: 940\t Weight1: [8.38270427]\t Weight2: [2.12745964]\t Bias: [4.05627894]\t Cost: 15.680909498548266\n",
            "Iteration: 941\t Weight1: [8.3844088]\t Weight2: [2.12551686]\t Bias: [4.05158643]\t Cost: 15.679476731682476\n",
            "Iteration: 942\t Weight1: [8.38610926]\t Weight2: [2.12357726]\t Bias: [4.04690994]\t Cost: 15.678052766020691\n",
            "Iteration: 943\t Weight1: [8.38780564]\t Weight2: [2.12164084]\t Bias: [4.04224941]\t Cost: 15.676637545181826\n",
            "Iteration: 944\t Weight1: [8.38949796]\t Weight2: [2.11970759]\t Bias: [4.03760478]\t Cost: 15.675231013161435\n",
            "Iteration: 945\t Weight1: [8.39118623]\t Weight2: [2.11777752]\t Bias: [4.032976]\t Cost: 15.673833114328998\n",
            "Iteration: 946\t Weight1: [8.39287045]\t Weight2: [2.11585063]\t Bias: [4.02836302]\t Cost: 15.672443793425362\n",
            "Iteration: 947\t Weight1: [8.39455063]\t Weight2: [2.11392691]\t Bias: [4.02376576]\t Cost: 15.671062995560186\n",
            "Iteration: 948\t Weight1: [8.39622679]\t Weight2: [2.11200636]\t Bias: [4.0191842]\t Cost: 15.66969066620937\n",
            "Iteration: 949\t Weight1: [8.39789894]\t Weight2: [2.11008899]\t Bias: [4.01461825]\t Cost: 15.668326751212474\n",
            "Iteration: 950\t Weight1: [8.39956707]\t Weight2: [2.10817478]\t Bias: [4.01006788]\t Cost: 15.666971196770294\n",
            "Iteration: 951\t Weight1: [8.40123121]\t Weight2: [2.10626375]\t Bias: [4.00553302]\t Cost: 15.665623949442201\n",
            "Iteration: 952\t Weight1: [8.40289135]\t Weight2: [2.10435588]\t Bias: [4.00101362]\t Cost: 15.664284956143845\n",
            "Iteration: 953\t Weight1: [8.40454752]\t Weight2: [2.10245118]\t Bias: [3.99650962]\t Cost: 15.662954164144557\n",
            "Iteration: 954\t Weight1: [8.40619971]\t Weight2: [2.10054965]\t Bias: [3.99202098]\t Cost: 15.66163152106494\n",
            "Iteration: 955\t Weight1: [8.40784794]\t Weight2: [2.09865129]\t Bias: [3.98754764]\t Cost: 15.660316974874428\n",
            "Iteration: 956\t Weight1: [8.40949222]\t Weight2: [2.09675608]\t Bias: [3.98308953]\t Cost: 15.659010473888888\n",
            "Iteration: 957\t Weight1: [8.41113255]\t Weight2: [2.09486404]\t Bias: [3.97864662]\t Cost: 15.657711966768234\n",
            "Iteration: 958\t Weight1: [8.41276894]\t Weight2: [2.09297517]\t Bias: [3.97421884]\t Cost: 15.65642140251397\n",
            "Iteration: 959\t Weight1: [8.41440141]\t Weight2: [2.09108945]\t Bias: [3.96980614]\t Cost: 15.655138730466941\n",
            "Iteration: 960\t Weight1: [8.41602996]\t Weight2: [2.08920689]\t Bias: [3.96540848]\t Cost: 15.653863900304895\n",
            "Iteration: 961\t Weight1: [8.4176546]\t Weight2: [2.08732749]\t Bias: [3.96102578]\t Cost: 15.652596862040204\n",
            "Iteration: 962\t Weight1: [8.41927534]\t Weight2: [2.08545124]\t Bias: [3.95665801]\t Cost: 15.651337566017496\n",
            "Iteration: 963\t Weight1: [8.42089219]\t Weight2: [2.08357815]\t Bias: [3.95230511]\t Cost: 15.650085962911461\n",
            "Iteration: 964\t Weight1: [8.42250516]\t Weight2: [2.08170822]\t Bias: [3.94796703]\t Cost: 15.64884200372445\n",
            "Iteration: 965\t Weight1: [8.42411425]\t Weight2: [2.07984143]\t Bias: [3.94364372]\t Cost: 15.647605639784297\n",
            "Iteration: 966\t Weight1: [8.42571948]\t Weight2: [2.0779778]\t Bias: [3.93933511]\t Cost: 15.646376822742024\n",
            "Iteration: 967\t Weight1: [8.42732086]\t Weight2: [2.07611731]\t Bias: [3.93504117]\t Cost: 15.645155504569665\n",
            "Iteration: 968\t Weight1: [8.42891838]\t Weight2: [2.07425997]\t Bias: [3.93076184]\t Cost: 15.643941637557953\n",
            "Iteration: 969\t Weight1: [8.43051207]\t Weight2: [2.07240578]\t Bias: [3.92649706]\t Cost: 15.642735174314232\n",
            "Iteration: 970\t Weight1: [8.43210192]\t Weight2: [2.07055473]\t Bias: [3.9222468]\t Cost: 15.641536067760223\n",
            "Iteration: 971\t Weight1: [8.43368796]\t Weight2: [2.06870683]\t Bias: [3.91801098]\t Cost: 15.640344271129825\n",
            "Iteration: 972\t Weight1: [8.43527018]\t Weight2: [2.06686206]\t Bias: [3.91378958]\t Cost: 15.639159737966983\n",
            "Iteration: 973\t Weight1: [8.4368486]\t Weight2: [2.06502044]\t Bias: [3.90958252]\t Cost: 15.637982422123601\n",
            "Iteration: 974\t Weight1: [8.43842322]\t Weight2: [2.06318195]\t Bias: [3.90538977]\t Cost: 15.636812277757338\n",
            "Iteration: 975\t Weight1: [8.43999406]\t Weight2: [2.0613466]\t Bias: [3.90121127]\t Cost: 15.63564925932957\n",
            "Iteration: 976\t Weight1: [8.44156112]\t Weight2: [2.05951439]\t Bias: [3.89704698]\t Cost: 15.634493321603275\n",
            "Iteration: 977\t Weight1: [8.44312441]\t Weight2: [2.0576853]\t Bias: [3.89289684]\t Cost: 15.633344419640894\n",
            "Iteration: 978\t Weight1: [8.44468394]\t Weight2: [2.05585935]\t Bias: [3.8887608]\t Cost: 15.632202508802372\n",
            "Iteration: 979\t Weight1: [8.44623972]\t Weight2: [2.05403653]\t Bias: [3.88463881]\t Cost: 15.631067544743063\n",
            "Iteration: 980\t Weight1: [8.44779175]\t Weight2: [2.05221684]\t Bias: [3.88053082]\t Cost: 15.629939483411661\n",
            "Iteration: 981\t Weight1: [8.44934005]\t Weight2: [2.05040027]\t Bias: [3.87643679]\t Cost: 15.62881828104825\n",
            "Iteration: 982\t Weight1: [8.45088462]\t Weight2: [2.04858683]\t Bias: [3.87235667]\t Cost: 15.627703894182229\n",
            "Iteration: 983\t Weight1: [8.45242548]\t Weight2: [2.0467765]\t Bias: [3.8682904]\t Cost: 15.626596279630428\n",
            "Iteration: 984\t Weight1: [8.45396262]\t Weight2: [2.0449693]\t Bias: [3.86423794]\t Cost: 15.625495394494969\n",
            "Iteration: 985\t Weight1: [8.45549607]\t Weight2: [2.04316522]\t Bias: [3.86019923]\t Cost: 15.624401196161466\n",
            "Iteration: 986\t Weight1: [8.45702582]\t Weight2: [2.04136426]\t Bias: [3.85617424]\t Cost: 15.623313642296962\n",
            "Iteration: 987\t Weight1: [8.45855189]\t Weight2: [2.0395664]\t Bias: [3.85216291]\t Cost: 15.622232690848097\n",
            "Iteration: 988\t Weight1: [8.46007428]\t Weight2: [2.03777167]\t Bias: [3.84816519]\t Cost: 15.621158300039072\n",
            "Iteration: 989\t Weight1: [8.461593]\t Weight2: [2.03598004]\t Bias: [3.84418103]\t Cost: 15.620090428369842\n",
            "Iteration: 990\t Weight1: [8.46310807]\t Weight2: [2.03419152]\t Bias: [3.8402104]\t Cost: 15.619029034614167\n",
            "Iteration: 991\t Weight1: [8.46461949]\t Weight2: [2.03240611]\t Bias: [3.83625324]\t Cost: 15.61797407781776\n",
            "Iteration: 992\t Weight1: [8.46612726]\t Weight2: [2.0306238]\t Bias: [3.83230949]\t Cost: 15.616925517296398\n",
            "Iteration: 993\t Weight1: [8.4676314]\t Weight2: [2.0288446]\t Bias: [3.82837913]\t Cost: 15.61588331263407\n",
            "Iteration: 994\t Weight1: [8.46913191]\t Weight2: [2.0270685]\t Bias: [3.82446209]\t Cost: 15.614847423681182\n",
            "Iteration: 995\t Weight1: [8.47062881]\t Weight2: [2.0252955]\t Bias: [3.82055834]\t Cost: 15.613817810552673\n",
            "Iteration: 996\t Weight1: [8.4721221]\t Weight2: [2.02352559]\t Bias: [3.81666782]\t Cost: 15.612794433626219\n",
            "Iteration: 997\t Weight1: [8.47361179]\t Weight2: [2.02175878]\t Bias: [3.81279049]\t Cost: 15.611777253540422\n",
            "Iteration: 998\t Weight1: [8.47509788]\t Weight2: [2.01999506]\t Bias: [3.8089263]\t Cost: 15.610766231193104\n",
            "Iteration: 999\t Weight1: [8.47658039]\t Weight2: [2.01823443]\t Bias: [3.8050752]\t Cost: 15.609761327739369\n",
            "Iteration: 1000\t Weight1: [8.47805933]\t Weight2: [2.01647689]\t Bias: [3.80123716]\t Cost: 15.608762504590013\n",
            "Iteration: 1001\t Weight1: [8.47953469]\t Weight2: [2.01472244]\t Bias: [3.79741212]\t Cost: 15.607769723409671\n",
            "Iteration: 1002\t Weight1: [8.4810065]\t Weight2: [2.01297107]\t Bias: [3.79360004]\t Cost: 15.606782946115056\n",
            "Iteration: 1003\t Weight1: [8.48247476]\t Weight2: [2.01122278]\t Bias: [3.78980087]\t Cost: 15.605802134873384\n",
            "Iteration: 1004\t Weight1: [8.48393947]\t Weight2: [2.00947757]\t Bias: [3.78601457]\t Cost: 15.604827252100463\n",
            "Iteration: 1005\t Weight1: [8.48540065]\t Weight2: [2.00773544]\t Bias: [3.7822411]\t Cost: 15.603858260459104\n",
            "Iteration: 1006\t Weight1: [8.4868583]\t Weight2: [2.00599639]\t Bias: [3.7784804]\t Cost: 15.602895122857444\n",
            "Iteration: 1007\t Weight1: [8.48831243]\t Weight2: [2.0042604]\t Bias: [3.77473243]\t Cost: 15.601937802447239\n",
            "Iteration: 1008\t Weight1: [8.48976305]\t Weight2: [2.00252749]\t Bias: [3.77099715]\t Cost: 15.600986262622152\n",
            "Iteration: 1009\t Weight1: [8.49121017]\t Weight2: [2.00079765]\t Bias: [3.76727451]\t Cost: 15.60004046701621\n",
            "Iteration: 1010\t Weight1: [8.49265379]\t Weight2: [1.99907087]\t Bias: [3.76356447]\t Cost: 15.599100379502053\n",
            "Iteration: 1011\t Weight1: [8.49409393]\t Weight2: [1.99734715]\t Bias: [3.75986698]\t Cost: 15.598165964189338\n",
            "Iteration: 1012\t Weight1: [8.49553058]\t Weight2: [1.9956265]\t Bias: [3.75618201]\t Cost: 15.597237185423177\n",
            "Iteration: 1013\t Weight1: [8.49696377]\t Weight2: [1.99390891]\t Bias: [3.7525095]\t Cost: 15.596314007782436\n",
            "Iteration: 1014\t Weight1: [8.4983935]\t Weight2: [1.99219437]\t Bias: [3.74884942]\t Cost: 15.595396396078225\n",
            "Iteration: 1015\t Weight1: [8.49981976]\t Weight2: [1.99048289]\t Bias: [3.74520171]\t Cost: 15.594484315352243\n",
            "Iteration: 1016\t Weight1: [8.50124259]\t Weight2: [1.98877445]\t Bias: [3.74156634]\t Cost: 15.59357773087527\n",
            "Iteration: 1017\t Weight1: [8.50266197]\t Weight2: [1.98706907]\t Bias: [3.73794326]\t Cost: 15.592676608145533\n",
            "Iteration: 1018\t Weight1: [8.50407792]\t Weight2: [1.98536674]\t Bias: [3.73433243]\t Cost: 15.591780912887206\n",
            "Iteration: 1019\t Weight1: [8.50549045]\t Weight2: [1.98366744]\t Bias: [3.73073381]\t Cost: 15.590890611048872\n",
            "Iteration: 1020\t Weight1: [8.50689957]\t Weight2: [1.9819712]\t Bias: [3.72714735]\t Cost: 15.590005668801957\n",
            "Iteration: 1021\t Weight1: [8.50830527]\t Weight2: [1.98027799]\t Bias: [3.72357301]\t Cost: 15.589126052539253\n",
            "Iteration: 1022\t Weight1: [8.50970758]\t Weight2: [1.97858781]\t Bias: [3.72001075]\t Cost: 15.588251728873367\n",
            "Iteration: 1023\t Weight1: [8.5111065]\t Weight2: [1.97690068]\t Bias: [3.71646052]\t Cost: 15.587382664635268\n",
            "Iteration: 1024\t Weight1: [8.51250203]\t Weight2: [1.97521657]\t Bias: [3.71292229]\t Cost: 15.586518826872723\n",
            "Iteration: 1025\t Weight1: [8.51389419]\t Weight2: [1.97353549]\t Bias: [3.70939601]\t Cost: 15.585660182848967\n",
            "Iteration: 1026\t Weight1: [8.51528297]\t Weight2: [1.97185744]\t Bias: [3.70588164]\t Cost: 15.584806700041085\n",
            "Iteration: 1027\t Weight1: [8.5166684]\t Weight2: [1.97018242]\t Bias: [3.70237914]\t Cost: 15.583958346138607\n",
            "Iteration: 1028\t Weight1: [8.51805048]\t Weight2: [1.96851041]\t Bias: [3.69888846]\t Cost: 15.583115089042124\n",
            "Iteration: 1029\t Weight1: [8.5194292]\t Weight2: [1.96684143]\t Bias: [3.69540957]\t Cost: 15.582276896861744\n",
            "Iteration: 1030\t Weight1: [8.5208046]\t Weight2: [1.96517546]\t Bias: [3.69194242]\t Cost: 15.581443737915768\n",
            "Iteration: 1031\t Weight1: [8.52217666]\t Weight2: [1.9635125]\t Bias: [3.68848698]\t Cost: 15.580615580729232\n",
            "Iteration: 1032\t Weight1: [8.5235454]\t Weight2: [1.96185256]\t Bias: [3.6850432]\t Cost: 15.57979239403247\n",
            "Iteration: 1033\t Weight1: [8.52491083]\t Weight2: [1.96019562]\t Bias: [3.68161103]\t Cost: 15.57897414675979\n",
            "Iteration: 1034\t Weight1: [8.52627294]\t Weight2: [1.95854169]\t Bias: [3.67819045]\t Cost: 15.578160808048\n",
            "Iteration: 1035\t Weight1: [8.52763177]\t Weight2: [1.95689077]\t Bias: [3.67478141]\t Cost: 15.577352347235147\n",
            "Iteration: 1036\t Weight1: [8.52898729]\t Weight2: [1.95524284]\t Bias: [3.67138386]\t Cost: 15.576548733859036\n",
            "Iteration: 1037\t Weight1: [8.53033954]\t Weight2: [1.95359791]\t Bias: [3.66799778]\t Cost: 15.575749937655948\n",
            "Iteration: 1038\t Weight1: [8.53168851]\t Weight2: [1.95195598]\t Bias: [3.66462311]\t Cost: 15.57495592855926\n",
            "Iteration: 1039\t Weight1: [8.53303421]\t Weight2: [1.95031704]\t Bias: [3.66125982]\t Cost: 15.574166676698134\n",
            "Iteration: 1040\t Weight1: [8.53437665]\t Weight2: [1.94868109]\t Bias: [3.65790787]\t Cost: 15.57338215239616\n",
            "Iteration: 1041\t Weight1: [8.53571584]\t Weight2: [1.94704812]\t Bias: [3.65456722]\t Cost: 15.57260232617007\n",
            "Iteration: 1042\t Weight1: [8.53705177]\t Weight2: [1.94541814]\t Bias: [3.65123783]\t Cost: 15.571827168728358\n",
            "Iteration: 1043\t Weight1: [8.53838448]\t Weight2: [1.94379114]\t Bias: [3.64791966]\t Cost: 15.571056650970094\n",
            "Iteration: 1044\t Weight1: [8.53971395]\t Weight2: [1.94216712]\t Bias: [3.64461267]\t Cost: 15.57029074398355\n",
            "Iteration: 1045\t Weight1: [8.54104019]\t Weight2: [1.94054608]\t Bias: [3.64131682]\t Cost: 15.569529419044928\n",
            "Iteration: 1046\t Weight1: [8.54236322]\t Weight2: [1.938928]\t Bias: [3.63803207]\t Cost: 15.568772647617102\n",
            "Iteration: 1047\t Weight1: [8.54368305]\t Weight2: [1.9373129]\t Bias: [3.63475839]\t Cost: 15.568020401348372\n",
            "Iteration: 1048\t Weight1: [8.54499967]\t Weight2: [1.93570077]\t Bias: [3.63149573]\t Cost: 15.567272652071164\n",
            "Iteration: 1049\t Weight1: [8.5463131]\t Weight2: [1.93409159]\t Bias: [3.62824406]\t Cost: 15.566529371800815\n",
            "Iteration: 1050\t Weight1: [8.54762334]\t Weight2: [1.93248538]\t Bias: [3.62500334]\t Cost: 15.565790532734336\n",
            "Iteration: 1051\t Weight1: [8.5489304]\t Weight2: [1.93088213]\t Bias: [3.62177353]\t Cost: 15.565056107249175\n",
            "Iteration: 1052\t Weight1: [8.55023429]\t Weight2: [1.92928184]\t Bias: [3.61855459]\t Cost: 15.564326067901987\n",
            "Iteration: 1053\t Weight1: [8.55153501]\t Weight2: [1.92768449]\t Bias: [3.61534648]\t Cost: 15.563600387427458\n",
            "Iteration: 1054\t Weight1: [8.55283258]\t Weight2: [1.9260901]\t Bias: [3.61214917]\t Cost: 15.562879038737044\n",
            "Iteration: 1055\t Weight1: [8.554127]\t Weight2: [1.92449865]\t Bias: [3.60896262]\t Cost: 15.562161994917831\n",
            "Iteration: 1056\t Weight1: [8.55541828]\t Weight2: [1.92291015]\t Bias: [3.60578679]\t Cost: 15.561449229231336\n",
            "Iteration: 1057\t Weight1: [8.55670642]\t Weight2: [1.92132459]\t Bias: [3.60262165]\t Cost: 15.560740715112319\n",
            "Iteration: 1058\t Weight1: [8.55799144]\t Weight2: [1.91974196]\t Bias: [3.59946714]\t Cost: 15.560036426167581\n",
            "Iteration: 1059\t Weight1: [8.55927333]\t Weight2: [1.91816228]\t Bias: [3.59632325]\t Cost: 15.559336336174903\n",
            "Iteration: 1060\t Weight1: [8.56055211]\t Weight2: [1.91658552]\t Bias: [3.59318993]\t Cost: 15.55864041908174\n",
            "Iteration: 1061\t Weight1: [8.56182779]\t Weight2: [1.91501169]\t Bias: [3.59006714]\t Cost: 15.557948649004269\n",
            "Iteration: 1062\t Weight1: [8.56310036]\t Weight2: [1.91344079]\t Bias: [3.58695486]\t Cost: 15.55726100022603\n",
            "Iteration: 1063\t Weight1: [8.56436984]\t Weight2: [1.91187281]\t Bias: [3.58385303]\t Cost: 15.556577447197022\n",
            "Iteration: 1064\t Weight1: [8.56563624]\t Weight2: [1.91030775]\t Bias: [3.58076163]\t Cost: 15.555897964532388\n",
            "Iteration: 1065\t Weight1: [8.56689957]\t Weight2: [1.90874561]\t Bias: [3.57768062]\t Cost: 15.555222527011423\n",
            "Iteration: 1066\t Weight1: [8.56815982]\t Weight2: [1.90718638]\t Bias: [3.57460995]\t Cost: 15.554551109576453\n",
            "Iteration: 1067\t Weight1: [8.56941701]\t Weight2: [1.90563006]\t Bias: [3.57154961]\t Cost: 15.553883687331652\n",
            "Iteration: 1068\t Weight1: [8.57067114]\t Weight2: [1.90407665]\t Bias: [3.56849954]\t Cost: 15.553220235542089\n",
            "Iteration: 1069\t Weight1: [8.57192223]\t Weight2: [1.90252615]\t Bias: [3.56545972]\t Cost: 15.55256072963252\n",
            "Iteration: 1070\t Weight1: [8.57317027]\t Weight2: [1.90097855]\t Bias: [3.56243011]\t Cost: 15.551905145186348\n",
            "Iteration: 1071\t Weight1: [8.57441528]\t Weight2: [1.89943384]\t Bias: [3.55941067]\t Cost: 15.551253457944656\n",
            "Iteration: 1072\t Weight1: [8.57565726]\t Weight2: [1.89789203]\t Bias: [3.55640137]\t Cost: 15.55060564380496\n",
            "Iteration: 1073\t Weight1: [8.57689622]\t Weight2: [1.89635312]\t Bias: [3.55340217]\t Cost: 15.549961678820344\n",
            "Iteration: 1074\t Weight1: [8.57813216]\t Weight2: [1.89481709]\t Bias: [3.55041304]\t Cost: 15.549321539198274\n",
            "Iteration: 1075\t Weight1: [8.5793651]\t Weight2: [1.89328395]\t Bias: [3.54743394]\t Cost: 15.54868520129963\n",
            "Iteration: 1076\t Weight1: [8.58059504]\t Weight2: [1.89175369]\t Bias: [3.54446483]\t Cost: 15.548052641637666\n",
            "Iteration: 1077\t Weight1: [8.58182199]\t Weight2: [1.89022631]\t Bias: [3.54150569]\t Cost: 15.547423836876987\n",
            "Iteration: 1078\t Weight1: [8.58304596]\t Weight2: [1.88870181]\t Bias: [3.53855647]\t Cost: 15.546798763832506\n",
            "Iteration: 1079\t Weight1: [8.58426694]\t Weight2: [1.88718018]\t Bias: [3.53561715]\t Cost: 15.54617739946849\n",
            "Iteration: 1080\t Weight1: [8.58548495]\t Weight2: [1.88566142]\t Bias: [3.53268769]\t Cost: 15.545559720897469\n",
            "Iteration: 1081\t Weight1: [8.5867]\t Weight2: [1.88414553]\t Bias: [3.52976805]\t Cost: 15.544945705379327\n",
            "Iteration: 1082\t Weight1: [8.58791209]\t Weight2: [1.8826325]\t Bias: [3.5268582]\t Cost: 15.544335330320296\n",
            "Iteration: 1083\t Weight1: [8.58912123]\t Weight2: [1.88112234]\t Bias: [3.5239581]\t Cost: 15.543728573271913\n",
            "Iteration: 1084\t Weight1: [8.59032742]\t Weight2: [1.87961503]\t Bias: [3.52106773]\t Cost: 15.543125411930163\n",
            "Iteration: 1085\t Weight1: [8.59153068]\t Weight2: [1.87811057]\t Bias: [3.51818704]\t Cost: 15.542525824134328\n",
            "Iteration: 1086\t Weight1: [8.59273101]\t Weight2: [1.87660897]\t Bias: [3.51531601]\t Cost: 15.541929787866282\n",
            "Iteration: 1087\t Weight1: [8.59392841]\t Weight2: [1.87511021]\t Bias: [3.51245459]\t Cost: 15.541337281249257\n",
            "Iteration: 1088\t Weight1: [8.5951229]\t Weight2: [1.8736143]\t Bias: [3.50960277]\t Cost: 15.540748282547103\n",
            "Iteration: 1089\t Weight1: [8.59631448]\t Weight2: [1.87212123]\t Bias: [3.5067605]\t Cost: 15.54016277016326\n",
            "Iteration: 1090\t Weight1: [8.59750315]\t Weight2: [1.870631]\t Bias: [3.50392775]\t Cost: 15.539580722639837\n",
            "Iteration: 1091\t Weight1: [8.59868893]\t Weight2: [1.8691436]\t Bias: [3.50110448]\t Cost: 15.539002118656663\n",
            "Iteration: 1092\t Weight1: [8.59987182]\t Weight2: [1.86765904]\t Bias: [3.49829067]\t Cost: 15.538426937030424\n",
            "Iteration: 1093\t Weight1: [8.60105182]\t Weight2: [1.8661773]\t Bias: [3.49548628]\t Cost: 15.537855156713666\n",
            "Iteration: 1094\t Weight1: [8.60222895]\t Weight2: [1.86469839]\t Bias: [3.49269128]\t Cost: 15.537286756793957\n",
            "Iteration: 1095\t Weight1: [8.60340321]\t Weight2: [1.8632223]\t Bias: [3.48990563]\t Cost: 15.536721716492975\n",
            "Iteration: 1096\t Weight1: [8.60457461]\t Weight2: [1.86174902]\t Bias: [3.48712931]\t Cost: 15.536160015165544\n",
            "Iteration: 1097\t Weight1: [8.60574315]\t Weight2: [1.86027857]\t Bias: [3.48436228]\t Cost: 15.535601632298834\n",
            "Iteration: 1098\t Weight1: [8.60690885]\t Weight2: [1.85881092]\t Bias: [3.48160451]\t Cost: 15.535046547511406\n",
            "Iteration: 1099\t Weight1: [8.6080717]\t Weight2: [1.85734608]\t Bias: [3.47885596]\t Cost: 15.534494740552393\n",
            "Iteration: 1100\t Weight1: [8.60923171]\t Weight2: [1.85588405]\t Bias: [3.47611661]\t Cost: 15.53394619130058\n",
            "Iteration: 1101\t Weight1: [8.6103889]\t Weight2: [1.85442482]\t Bias: [3.47338642]\t Cost: 15.533400879763532\n",
            "Iteration: 1102\t Weight1: [8.61154326]\t Weight2: [1.85296839]\t Bias: [3.47066536]\t Cost: 15.532858786076861\n",
            "Iteration: 1103\t Weight1: [8.61269481]\t Weight2: [1.85151475]\t Bias: [3.46795339]\t Cost: 15.532319890503151\n",
            "Iteration: 1104\t Weight1: [8.61384354]\t Weight2: [1.85006391]\t Bias: [3.4652505]\t Cost: 15.531784173431275\n",
            "Iteration: 1105\t Weight1: [8.61498948]\t Weight2: [1.84861585]\t Bias: [3.46255664]\t Cost: 15.531251615375524\n",
            "Iteration: 1106\t Weight1: [8.61613261]\t Weight2: [1.84717058]\t Bias: [3.45987179]\t Cost: 15.530722196974754\n",
            "Iteration: 1107\t Weight1: [8.61727296]\t Weight2: [1.84572809]\t Bias: [3.45719591]\t Cost: 15.53019589899157\n",
            "Iteration: 1108\t Weight1: [8.61841052]\t Weight2: [1.84428838]\t Bias: [3.45452897]\t Cost: 15.529672702311423\n",
            "Iteration: 1109\t Weight1: [8.61954531]\t Weight2: [1.84285144]\t Bias: [3.45187094]\t Cost: 15.529152587941915\n",
            "Iteration: 1110\t Weight1: [8.62067733]\t Weight2: [1.84141727]\t Bias: [3.44922179]\t Cost: 15.528635537011937\n",
            "Iteration: 1111\t Weight1: [8.62180658]\t Weight2: [1.83998588]\t Bias: [3.44658149]\t Cost: 15.528121530770791\n",
            "Iteration: 1112\t Weight1: [8.62293308]\t Weight2: [1.83855724]\t Bias: [3.44395]\t Cost: 15.527610550587495\n",
            "Iteration: 1113\t Weight1: [8.62405682]\t Weight2: [1.83713137]\t Bias: [3.44132731]\t Cost: 15.527102577949957\n",
            "Iteration: 1114\t Weight1: [8.62517783]\t Weight2: [1.83570826]\t Bias: [3.43871337]\t Cost: 15.526597594464109\n",
            "Iteration: 1115\t Weight1: [8.62629609]\t Weight2: [1.8342879]\t Bias: [3.43610816]\t Cost: 15.52609558185322\n",
            "Iteration: 1116\t Weight1: [8.62741162]\t Weight2: [1.83287029]\t Bias: [3.43351164]\t Cost: 15.525596521957075\n",
            "Iteration: 1117\t Weight1: [8.62852443]\t Weight2: [1.83145542]\t Bias: [3.43092379]\t Cost: 15.525100396731178\n",
            "Iteration: 1118\t Weight1: [8.62963451]\t Weight2: [1.83004331]\t Bias: [3.42834458]\t Cost: 15.52460718824604\n",
            "Iteration: 1119\t Weight1: [8.63074189]\t Weight2: [1.82863393]\t Bias: [3.42577398]\t Cost: 15.524116878686359\n",
            "Iteration: 1120\t Weight1: [8.63184656]\t Weight2: [1.82722729]\t Bias: [3.42321195]\t Cost: 15.523629450350262\n",
            "Iteration: 1121\t Weight1: [8.63294853]\t Weight2: [1.82582338]\t Bias: [3.42065846]\t Cost: 15.523144885648643\n",
            "Iteration: 1122\t Weight1: [8.6340478]\t Weight2: [1.82442221]\t Bias: [3.4181135]\t Cost: 15.52266316710427\n",
            "Iteration: 1123\t Weight1: [8.63514439]\t Weight2: [1.82302376]\t Bias: [3.41557702]\t Cost: 15.522184277351156\n",
            "Iteration: 1124\t Weight1: [8.6362383]\t Weight2: [1.82162803]\t Bias: [3.413049]\t Cost: 15.521708199133753\n",
            "Iteration: 1125\t Weight1: [8.63732954]\t Weight2: [1.82023502]\t Bias: [3.4105294]\t Cost: 15.52123491530631\n",
            "Iteration: 1126\t Weight1: [8.6384181]\t Weight2: [1.81884473]\t Bias: [3.40801821]\t Cost: 15.520764408831985\n",
            "Iteration: 1127\t Weight1: [8.63950401]\t Weight2: [1.81745716]\t Bias: [3.40551539]\t Cost: 15.520296662782323\n",
            "Iteration: 1128\t Weight1: [8.64058726]\t Weight2: [1.81607229]\t Bias: [3.40302091]\t Cost: 15.519831660336349\n",
            "Iteration: 1129\t Weight1: [8.64166786]\t Weight2: [1.81469012]\t Bias: [3.40053474]\t Cost: 15.519369384780015\n",
            "Iteration: 1130\t Weight1: [8.64274581]\t Weight2: [1.81331066]\t Bias: [3.39805685]\t Cost: 15.518909819505359\n",
            "Iteration: 1131\t Weight1: [8.64382113]\t Weight2: [1.8119339]\t Bias: [3.39558722]\t Cost: 15.518452948009877\n",
            "Iteration: 1132\t Weight1: [8.64489382]\t Weight2: [1.81055984]\t Bias: [3.39312582]\t Cost: 15.517998753895847\n",
            "Iteration: 1133\t Weight1: [8.64596388]\t Weight2: [1.80918846]\t Bias: [3.39067261]\t Cost: 15.517547220869554\n",
            "Iteration: 1134\t Weight1: [8.64703133]\t Weight2: [1.80781977]\t Bias: [3.38822758]\t Cost: 15.517098332740671\n",
            "Iteration: 1135\t Weight1: [8.64809616]\t Weight2: [1.80645377]\t Bias: [3.38579068]\t Cost: 15.51665207342152\n",
            "Iteration: 1136\t Weight1: [8.64915839]\t Weight2: [1.80509045]\t Bias: [3.3833619]\t Cost: 15.516208426926456\n",
            "Iteration: 1137\t Weight1: [8.65021802]\t Weight2: [1.80372981]\t Bias: [3.3809412]\t Cost: 15.515767377371137\n",
            "Iteration: 1138\t Weight1: [8.65127505]\t Weight2: [1.80237184]\t Bias: [3.37852856]\t Cost: 15.515328908971888\n",
            "Iteration: 1139\t Weight1: [8.6523295]\t Weight2: [1.80101654]\t Bias: [3.37612395]\t Cost: 15.514893006045016\n",
            "Iteration: 1140\t Weight1: [8.65338137]\t Weight2: [1.79966391]\t Bias: [3.37372734]\t Cost: 15.514459653006151\n",
            "Iteration: 1141\t Weight1: [8.65443066]\t Weight2: [1.79831394]\t Bias: [3.37133871]\t Cost: 15.514028834369638\n",
            "Iteration: 1142\t Weight1: [8.65547738]\t Weight2: [1.79696663]\t Bias: [3.36895802]\t Cost: 15.513600534747749\n",
            "Iteration: 1143\t Weight1: [8.65652153]\t Weight2: [1.79562198]\t Bias: [3.36658524]\t Cost: 15.513174738850234\n",
            "Iteration: 1144\t Weight1: [8.65756313]\t Weight2: [1.79427998]\t Bias: [3.36422036]\t Cost: 15.512751431483515\n",
            "Iteration: 1145\t Weight1: [8.65860218]\t Weight2: [1.79294062]\t Bias: [3.36186335]\t Cost: 15.51233059755013\n",
            "Iteration: 1146\t Weight1: [8.65963868]\t Weight2: [1.79160392]\t Bias: [3.35951417]\t Cost: 15.511912222048055\n",
            "Iteration: 1147\t Weight1: [8.66067265]\t Weight2: [1.79026986]\t Bias: [3.3571728]\t Cost: 15.511496290070129\n",
            "Iteration: 1148\t Weight1: [8.66170408]\t Weight2: [1.78893843]\t Bias: [3.35483921]\t Cost: 15.51108278680334\n",
            "Iteration: 1149\t Weight1: [8.66273298]\t Weight2: [1.78760964]\t Bias: [3.35251338]\t Cost: 15.510671697528325\n",
            "Iteration: 1150\t Weight1: [8.66375936]\t Weight2: [1.78628348]\t Bias: [3.35019528]\t Cost: 15.51026300761865\n",
            "Iteration: 1151\t Weight1: [8.66478323]\t Weight2: [1.78495995]\t Bias: [3.34788488]\t Cost: 15.509856702540212\n",
            "Iteration: 1152\t Weight1: [8.66580458]\t Weight2: [1.78363904]\t Bias: [3.34558215]\t Cost: 15.509452767850716\n",
            "Iteration: 1153\t Weight1: [8.66682344]\t Weight2: [1.78232075]\t Bias: [3.34328707]\t Cost: 15.509051189198962\n",
            "Iteration: 1154\t Weight1: [8.66783979]\t Weight2: [1.78100508]\t Bias: [3.34099962]\t Cost: 15.508651952324312\n",
            "Iteration: 1155\t Weight1: [8.66885365]\t Weight2: [1.77969202]\t Bias: [3.33871976]\t Cost: 15.508255043056042\n",
            "Iteration: 1156\t Weight1: [8.66986503]\t Weight2: [1.77838158]\t Bias: [3.33644748]\t Cost: 15.50786044731283\n",
            "Iteration: 1157\t Weight1: [8.67087393]\t Weight2: [1.77707373]\t Bias: [3.33418273]\t Cost: 15.507468151102087\n",
            "Iteration: 1158\t Weight1: [8.67188035]\t Weight2: [1.77576849]\t Bias: [3.33192551]\t Cost: 15.507078140519415\n",
            "Iteration: 1159\t Weight1: [8.67288431]\t Weight2: [1.77446585]\t Bias: [3.32967578]\t Cost: 15.506690401748022\n",
            "Iteration: 1160\t Weight1: [8.6738858]\t Weight2: [1.77316581]\t Bias: [3.32743351]\t Cost: 15.506304921058138\n",
            "Iteration: 1161\t Weight1: [8.67488484]\t Weight2: [1.77186835]\t Bias: [3.32519868]\t Cost: 15.50592168480644\n",
            "Iteration: 1162\t Weight1: [8.67588142]\t Weight2: [1.77057348]\t Bias: [3.32297127]\t Cost: 15.50554067943552\n",
            "Iteration: 1163\t Weight1: [8.67687556]\t Weight2: [1.7692812]\t Bias: [3.32075125]\t Cost: 15.505161891473257\n",
            "Iteration: 1164\t Weight1: [8.67786726]\t Weight2: [1.7679915]\t Bias: [3.31853859]\t Cost: 15.504785307532332\n",
            "Iteration: 1165\t Weight1: [8.67885653]\t Weight2: [1.76670437]\t Bias: [3.31633326]\t Cost: 15.504410914309597\n",
            "Iteration: 1166\t Weight1: [8.67984337]\t Weight2: [1.76541982]\t Bias: [3.31413526]\t Cost: 15.504038698585582\n",
            "Iteration: 1167\t Weight1: [8.68082779]\t Weight2: [1.76413784]\t Bias: [3.31194453]\t Cost: 15.50366864722393\n",
            "Iteration: 1168\t Weight1: [8.68180979]\t Weight2: [1.76285842]\t Bias: [3.30976108]\t Cost: 15.503300747170803\n",
            "Iteration: 1169\t Weight1: [8.68278938]\t Weight2: [1.76158157]\t Bias: [3.30758485]\t Cost: 15.502934985454415\n",
            "Iteration: 1170\t Weight1: [8.68376656]\t Weight2: [1.76030727]\t Bias: [3.30541585]\t Cost: 15.502571349184455\n",
            "Iteration: 1171\t Weight1: [8.68474135]\t Weight2: [1.75903553]\t Bias: [3.30325402]\t Cost: 15.502209825551569\n",
            "Iteration: 1172\t Weight1: [8.68571374]\t Weight2: [1.75776634]\t Bias: [3.30109937]\t Cost: 15.5018504018268\n",
            "Iteration: 1173\t Weight1: [8.68668375]\t Weight2: [1.7564997]\t Bias: [3.29895184]\t Cost: 15.501493065361096\n",
            "Iteration: 1174\t Weight1: [8.68765137]\t Weight2: [1.7552356]\t Bias: [3.29681144]\t Cost: 15.50113780358477\n",
            "Iteration: 1175\t Weight1: [8.68861662]\t Weight2: [1.75397405]\t Bias: [3.29467812]\t Cost: 15.500784604006984\n",
            "Iteration: 1176\t Weight1: [8.68957949]\t Weight2: [1.75271503]\t Bias: [3.29255187]\t Cost: 15.500433454215248\n",
            "Iteration: 1177\t Weight1: [8.69054]\t Weight2: [1.75145854]\t Bias: [3.29043265]\t Cost: 15.500084341874842\n",
            "Iteration: 1178\t Weight1: [8.69149815]\t Weight2: [1.75020458]\t Bias: [3.28832046]\t Cost: 15.499737254728407\n",
            "Iteration: 1179\t Weight1: [8.69245395]\t Weight2: [1.74895315]\t Bias: [3.28621525]\t Cost: 15.49939218059536\n",
            "Iteration: 1180\t Weight1: [8.6934074]\t Weight2: [1.74770424]\t Bias: [3.28411702]\t Cost: 15.499049107371446\n",
            "Iteration: 1181\t Weight1: [8.6943585]\t Weight2: [1.74645785]\t Bias: [3.28202572]\t Cost: 15.498708023028204\n",
            "Iteration: 1182\t Weight1: [8.69530727]\t Weight2: [1.74521397]\t Bias: [3.27994135]\t Cost: 15.498368915612465\n",
            "Iteration: 1183\t Weight1: [8.69625371]\t Weight2: [1.74397261]\t Bias: [3.27786387]\t Cost: 15.498031773245915\n",
            "Iteration: 1184\t Weight1: [8.69719782]\t Weight2: [1.74273375]\t Bias: [3.27579327]\t Cost: 15.497696584124506\n",
            "Iteration: 1185\t Weight1: [8.6981396]\t Weight2: [1.74149739]\t Bias: [3.27372951]\t Cost: 15.497363336518102\n",
            "Iteration: 1186\t Weight1: [8.69907908]\t Weight2: [1.74026354]\t Bias: [3.27167258]\t Cost: 15.497032018769916\n",
            "Iteration: 1187\t Weight1: [8.70001624]\t Weight2: [1.73903218]\t Bias: [3.26962245]\t Cost: 15.49670261929599\n",
            "Iteration: 1188\t Weight1: [8.7009511]\t Weight2: [1.73780331]\t Bias: [3.2675791]\t Cost: 15.496375126584839\n",
            "Iteration: 1189\t Weight1: [8.70188366]\t Weight2: [1.73657693]\t Bias: [3.2655425]\t Cost: 15.49604952919689\n",
            "Iteration: 1190\t Weight1: [8.70281393]\t Weight2: [1.73535304]\t Bias: [3.26351263]\t Cost: 15.495725815764015\n",
            "Iteration: 1191\t Weight1: [8.70374191]\t Weight2: [1.73413163]\t Bias: [3.26148948]\t Cost: 15.495403974989117\n",
            "Iteration: 1192\t Weight1: [8.7046676]\t Weight2: [1.7329127]\t Bias: [3.25947301]\t Cost: 15.495083995645608\n",
            "Iteration: 1193\t Weight1: [8.70559102]\t Weight2: [1.73169624]\t Bias: [3.2574632]\t Cost: 15.494765866577039\n",
            "Iteration: 1194\t Weight1: [8.70651217]\t Weight2: [1.73048225]\t Bias: [3.25546003]\t Cost: 15.494449576696502\n",
            "Iteration: 1195\t Weight1: [8.70743105]\t Weight2: [1.72927073]\t Bias: [3.25346347]\t Cost: 15.49413511498631\n",
            "Iteration: 1196\t Weight1: [8.70834767]\t Weight2: [1.72806167]\t Bias: [3.25147352]\t Cost: 15.493822470497484\n",
            "Iteration: 1197\t Weight1: [8.70926203]\t Weight2: [1.72685508]\t Bias: [3.24949013]\t Cost: 15.493511632349321\n",
            "Iteration: 1198\t Weight1: [8.71017415]\t Weight2: [1.72565093]\t Bias: [3.24751329]\t Cost: 15.493202589728924\n",
            "Iteration: 1199\t Weight1: [8.71108402]\t Weight2: [1.72444924]\t Bias: [3.24554298]\t Cost: 15.492895331890814\n",
            "Iteration: 1200\t Weight1: [8.71199165]\t Weight2: [1.72325]\t Bias: [3.24357917]\t Cost: 15.492589848156431\n",
            "Iteration: 1201\t Weight1: [8.71289704]\t Weight2: [1.7220532]\t Bias: [3.24162184]\t Cost: 15.492286127913772\n",
            "Iteration: 1202\t Weight1: [8.71380021]\t Weight2: [1.72085884]\t Bias: [3.23967097]\t Cost: 15.491984160616846\n",
            "Iteration: 1203\t Weight1: [8.71470115]\t Weight2: [1.71966692]\t Bias: [3.23772654]\t Cost: 15.491683935785376\n",
            "Iteration: 1204\t Weight1: [8.71559988]\t Weight2: [1.71847744]\t Bias: [3.23578853]\t Cost: 15.491385443004305\n",
            "Iteration: 1205\t Weight1: [8.71649639]\t Weight2: [1.71729038]\t Bias: [3.23385691]\t Cost: 15.491088671923361\n",
            "Iteration: 1206\t Weight1: [8.71739069]\t Weight2: [1.71610575]\t Bias: [3.23193165]\t Cost: 15.490793612256628\n",
            "Iteration: 1207\t Weight1: [8.71828279]\t Weight2: [1.71492354]\t Bias: [3.23001275]\t Cost: 15.490500253782196\n",
            "Iteration: 1208\t Weight1: [8.7191727]\t Weight2: [1.71374375]\t Bias: [3.22810017]\t Cost: 15.490208586341678\n",
            "Iteration: 1209\t Weight1: [8.72006041]\t Weight2: [1.71256638]\t Bias: [3.2261939]\t Cost: 15.489918599839868\n",
            "Iteration: 1210\t Weight1: [8.72094593]\t Weight2: [1.71139141]\t Bias: [3.22429392]\t Cost: 15.489630284244216\n",
            "Iteration: 1211\t Weight1: [8.72182928]\t Weight2: [1.71021886]\t Bias: [3.2224002]\t Cost: 15.489343629584546\n",
            "Iteration: 1212\t Weight1: [8.72271045]\t Weight2: [1.7090487]\t Bias: [3.22051271]\t Cost: 15.489058625952584\n",
            "Iteration: 1213\t Weight1: [8.72358944]\t Weight2: [1.70788095]\t Bias: [3.21863145]\t Cost: 15.4887752635016\n",
            "Iteration: 1214\t Weight1: [8.72446627]\t Weight2: [1.7067156]\t Bias: [3.21675638]\t Cost: 15.48849353244591\n",
            "Iteration: 1215\t Weight1: [8.72534094]\t Weight2: [1.70555263]\t Bias: [3.2148875]\t Cost: 15.488213423060614\n",
            "Iteration: 1216\t Weight1: [8.72621345]\t Weight2: [1.70439206]\t Bias: [3.21302476]\t Cost: 15.48793492568113\n",
            "Iteration: 1217\t Weight1: [8.72708382]\t Weight2: [1.70323387]\t Bias: [3.21116817]\t Cost: 15.48765803070278\n",
            "Iteration: 1218\t Weight1: [8.72795203]\t Weight2: [1.70207806]\t Bias: [3.20931768]\t Cost: 15.487382728580508\n",
            "Iteration: 1219\t Weight1: [8.72881811]\t Weight2: [1.70092464]\t Bias: [3.20747329]\t Cost: 15.487109009828355\n",
            "Iteration: 1220\t Weight1: [8.72968205]\t Weight2: [1.69977358]\t Bias: [3.20563497]\t Cost: 15.486836865019148\n",
            "Iteration: 1221\t Weight1: [8.73054386]\t Weight2: [1.6986249]\t Bias: [3.2038027]\t Cost: 15.486566284784164\n",
            "Iteration: 1222\t Weight1: [8.73140355]\t Weight2: [1.69747858]\t Bias: [3.20197646]\t Cost: 15.486297259812694\n",
            "Iteration: 1223\t Weight1: [8.73226112]\t Weight2: [1.69633462]\t Bias: [3.20015623]\t Cost: 15.486029780851634\n",
            "Iteration: 1224\t Weight1: [8.73311657]\t Weight2: [1.69519303]\t Bias: [3.19834199]\t Cost: 15.485763838705196\n",
            "Iteration: 1225\t Weight1: [8.73396991]\t Weight2: [1.69405379]\t Bias: [3.19653372]\t Cost: 15.4854994242345\n",
            "Iteration: 1226\t Weight1: [8.73482114]\t Weight2: [1.6929169]\t Bias: [3.1947314]\t Cost: 15.485236528357202\n",
            "Iteration: 1227\t Weight1: [8.73567028]\t Weight2: [1.69178236]\t Bias: [3.192935]\t Cost: 15.484975142047134\n",
            "Iteration: 1228\t Weight1: [8.73651732]\t Weight2: [1.69065016]\t Bias: [3.19114451]\t Cost: 15.484715256333935\n",
            "Iteration: 1229\t Weight1: [8.73736227]\t Weight2: [1.68952031]\t Bias: [3.18935991]\t Cost: 15.484456862302702\n",
            "Iteration: 1230\t Weight1: [8.73820514]\t Weight2: [1.68839279]\t Bias: [3.18758118]\t Cost: 15.484199951093633\n",
            "Iteration: 1231\t Weight1: [8.73904593]\t Weight2: [1.68726761]\t Bias: [3.18580829]\t Cost: 15.48394451390168\n",
            "Iteration: 1232\t Weight1: [8.73988464]\t Weight2: [1.68614475]\t Bias: [3.18404123]\t Cost: 15.48369054197614\n",
            "Iteration: 1233\t Weight1: [8.74072128]\t Weight2: [1.68502422]\t Bias: [3.18227998]\t Cost: 15.4834380266204\n",
            "Iteration: 1234\t Weight1: [8.74155586]\t Weight2: [1.68390602]\t Bias: [3.18052451]\t Cost: 15.483186959191498\n",
            "Iteration: 1235\t Weight1: [8.74238837]\t Weight2: [1.68279013]\t Bias: [3.17877481]\t Cost: 15.482937331099835\n",
            "Iteration: 1236\t Weight1: [8.74321884]\t Weight2: [1.68167656]\t Bias: [3.17703086]\t Cost: 15.482689133808796\n",
            "Iteration: 1237\t Weight1: [8.74404725]\t Weight2: [1.6805653]\t Bias: [3.17529263]\t Cost: 15.482442358834463\n",
            "Iteration: 1238\t Weight1: [8.74487361]\t Weight2: [1.67945634]\t Bias: [3.17356012]\t Cost: 15.48219699774519\n",
            "Iteration: 1239\t Weight1: [8.74569794]\t Weight2: [1.67834969]\t Bias: [3.17183329]\t Cost: 15.481953042161361\n",
            "Iteration: 1240\t Weight1: [8.74652023]\t Weight2: [1.67724534]\t Bias: [3.17011214]\t Cost: 15.481710483754956\n",
            "Iteration: 1241\t Weight1: [8.74734049]\t Weight2: [1.67614328]\t Bias: [3.16839663]\t Cost: 15.481469314249331\n",
            "Iteration: 1242\t Weight1: [8.74815872]\t Weight2: [1.67504352]\t Bias: [3.16668675]\t Cost: 15.481229525418794\n",
            "Iteration: 1243\t Weight1: [8.74897493]\t Weight2: [1.67394605]\t Bias: [3.16498249]\t Cost: 15.480991109088322\n",
            "Iteration: 1244\t Weight1: [8.74978913]\t Weight2: [1.67285086]\t Bias: [3.16328381]\t Cost: 15.480754057133245\n",
            "Iteration: 1245\t Weight1: [8.75060131]\t Weight2: [1.67175795]\t Bias: [3.16159072]\t Cost: 15.480518361478866\n",
            "Iteration: 1246\t Weight1: [8.75141149]\t Weight2: [1.67066733]\t Bias: [3.15990317]\t Cost: 15.48028401410022\n",
            "Iteration: 1247\t Weight1: [8.75221967]\t Weight2: [1.66957897]\t Bias: [3.15822116]\t Cost: 15.48005100702167\n",
            "Iteration: 1248\t Weight1: [8.75302585]\t Weight2: [1.66849289]\t Bias: [3.15654467]\t Cost: 15.479819332316676\n",
            "Iteration: 1249\t Weight1: [8.75383003]\t Weight2: [1.66740907]\t Bias: [3.15487367]\t Cost: 15.479588982107432\n",
            "Iteration: 1250\t Weight1: [8.75463223]\t Weight2: [1.66632751]\t Bias: [3.15320815]\t Cost: 15.479359948564516\n",
            "Iteration: 1251\t Weight1: [8.75543245]\t Weight2: [1.66524822]\t Bias: [3.15154809]\t Cost: 15.4791322239067\n",
            "Iteration: 1252\t Weight1: [8.75623069]\t Weight2: [1.66417118]\t Bias: [3.14989348]\t Cost: 15.478905800400494\n",
            "Iteration: 1253\t Weight1: [8.75702695]\t Weight2: [1.66309639]\t Bias: [3.14824428]\t Cost: 15.478680670359953\n",
            "Iteration: 1254\t Weight1: [8.75782125]\t Weight2: [1.66202385]\t Bias: [3.14660049]\t Cost: 15.478456826146292\n",
            "Iteration: 1255\t Weight1: [8.75861358]\t Weight2: [1.66095356]\t Bias: [3.14496209]\t Cost: 15.478234260167664\n",
            "Iteration: 1256\t Weight1: [8.75940396]\t Weight2: [1.6598855]\t Bias: [3.14332905]\t Cost: 15.478012964878804\n",
            "Iteration: 1257\t Weight1: [8.76019238]\t Weight2: [1.65881968]\t Bias: [3.14170136]\t Cost: 15.477792932780734\n",
            "Iteration: 1258\t Weight1: [8.76097885]\t Weight2: [1.6577561]\t Bias: [3.14007901]\t Cost: 15.477574156420491\n",
            "Iteration: 1259\t Weight1: [8.76176337]\t Weight2: [1.65669475]\t Bias: [3.13846196]\t Cost: 15.477356628390801\n",
            "Iteration: 1260\t Weight1: [8.76254596]\t Weight2: [1.65563562]\t Bias: [3.13685021]\t Cost: 15.477140341329822\n",
            "Iteration: 1261\t Weight1: [8.76332661]\t Weight2: [1.65457871]\t Bias: [3.13524374]\t Cost: 15.476925287920826\n",
            "Iteration: 1262\t Weight1: [8.76410533]\t Weight2: [1.65352403]\t Bias: [3.13364253]\t Cost: 15.47671146089192\n",
            "Iteration: 1263\t Weight1: [8.76488212]\t Weight2: [1.65247155]\t Bias: [3.13204655]\t Cost: 15.476498853015796\n",
            "Iteration: 1264\t Weight1: [8.76565699]\t Weight2: [1.65142129]\t Bias: [3.1304558]\t Cost: 15.476287457109345\n",
            "Iteration: 1265\t Weight1: [8.76642994]\t Weight2: [1.65037324]\t Bias: [3.12887026]\t Cost: 15.476077266033517\n",
            "Iteration: 1266\t Weight1: [8.76720098]\t Weight2: [1.64932739]\t Bias: [3.1272899]\t Cost: 15.475868272692876\n",
            "Iteration: 1267\t Weight1: [8.76797011]\t Weight2: [1.64828374]\t Bias: [3.12571471]\t Cost: 15.475660470035482\n",
            "Iteration: 1268\t Weight1: [8.76873734]\t Weight2: [1.64724229]\t Bias: [3.12414467]\t Cost: 15.475453851052526\n",
            "Iteration: 1269\t Weight1: [8.76950267]\t Weight2: [1.64620303]\t Bias: [3.12257977]\t Cost: 15.475248408778027\n",
            "Iteration: 1270\t Weight1: [8.77026611]\t Weight2: [1.64516596]\t Bias: [3.12101998]\t Cost: 15.475044136288652\n",
            "Iteration: 1271\t Weight1: [8.77102765]\t Weight2: [1.64413108]\t Bias: [3.11946529]\t Cost: 15.474841026703361\n",
            "Iteration: 1272\t Weight1: [8.77178731]\t Weight2: [1.64309837]\t Bias: [3.11791569]\t Cost: 15.474639073183194\n",
            "Iteration: 1273\t Weight1: [8.77254509]\t Weight2: [1.64206785]\t Bias: [3.11637115]\t Cost: 15.474438268930944\n",
            "Iteration: 1274\t Weight1: [8.773301]\t Weight2: [1.6410395]\t Bias: [3.11483166]\t Cost: 15.474238607190971\n",
            "Iteration: 1275\t Weight1: [8.77405503]\t Weight2: [1.64001332]\t Bias: [3.11329719]\t Cost: 15.474040081248866\n",
            "Iteration: 1276\t Weight1: [8.7748072]\t Weight2: [1.63898931]\t Bias: [3.11176774]\t Cost: 15.473842684431192\n",
            "Iteration: 1277\t Weight1: [8.7755575]\t Weight2: [1.63796746]\t Bias: [3.11024329]\t Cost: 15.47364641010529\n",
            "Iteration: 1278\t Weight1: [8.77630594]\t Weight2: [1.63694778]\t Bias: [3.10872382]\t Cost: 15.47345125167894\n",
            "Iteration: 1279\t Weight1: [8.77705253]\t Weight2: [1.63593024]\t Bias: [3.10720931]\t Cost: 15.473257202600157\n",
            "Iteration: 1280\t Weight1: [8.77779727]\t Weight2: [1.63491487]\t Bias: [3.10569974]\t Cost: 15.473064256356912\n",
            "Iteration: 1281\t Weight1: [8.77854017]\t Weight2: [1.63390164]\t Bias: [3.1041951]\t Cost: 15.472872406476878\n",
            "Iteration: 1282\t Weight1: [8.77928122]\t Weight2: [1.63289055]\t Bias: [3.10269538]\t Cost: 15.4726816465272\n",
            "Iteration: 1283\t Weight1: [8.78002044]\t Weight2: [1.63188161]\t Bias: [3.10120055]\t Cost: 15.4724919701142\n",
            "Iteration: 1284\t Weight1: [8.78075783]\t Weight2: [1.6308748]\t Bias: [3.09971059]\t Cost: 15.472303370883177\n",
            "Iteration: 1285\t Weight1: [8.78149339]\t Weight2: [1.62987013]\t Bias: [3.0982255]\t Cost: 15.472115842518113\n",
            "Iteration: 1286\t Weight1: [8.78222713]\t Weight2: [1.62886759]\t Bias: [3.09674526]\t Cost: 15.471929378741477\n",
            "Iteration: 1287\t Weight1: [8.78295905]\t Weight2: [1.62786718]\t Bias: [3.09526984]\t Cost: 15.471743973313933\n",
            "Iteration: 1288\t Weight1: [8.78368916]\t Weight2: [1.62686889]\t Bias: [3.09379924]\t Cost: 15.47155962003414\n",
            "Iteration: 1289\t Weight1: [8.78441745]\t Weight2: [1.62587272]\t Bias: [3.09233343]\t Cost: 15.471376312738487\n",
            "Iteration: 1290\t Weight1: [8.78514394]\t Weight2: [1.62487867]\t Bias: [3.0908724]\t Cost: 15.471194045300827\n",
            "Iteration: 1291\t Weight1: [8.78586863]\t Weight2: [1.62388673]\t Bias: [3.08941614]\t Cost: 15.47101281163232\n",
            "Iteration: 1292\t Weight1: [8.78659153]\t Weight2: [1.6228969]\t Bias: [3.08796462]\t Cost: 15.470832605681112\n",
            "Iteration: 1293\t Weight1: [8.78731263]\t Weight2: [1.62190917]\t Bias: [3.08651784]\t Cost: 15.470653421432143\n",
            "Iteration: 1294\t Weight1: [8.78803194]\t Weight2: [1.62092355]\t Bias: [3.08507577]\t Cost: 15.47047525290689\n",
            "Iteration: 1295\t Weight1: [8.78874947]\t Weight2: [1.61994002]\t Bias: [3.08363839]\t Cost: 15.470298094163178\n",
            "Iteration: 1296\t Weight1: [8.78946522]\t Weight2: [1.61895859]\t Bias: [3.08220571]\t Cost: 15.470121939294916\n",
            "Iteration: 1297\t Weight1: [8.7901792]\t Weight2: [1.61797925]\t Bias: [3.08077768]\t Cost: 15.469946782431863\n",
            "Iteration: 1298\t Weight1: [8.7908914]\t Weight2: [1.61700199]\t Bias: [3.07935432]\t Cost: 15.469772617739435\n",
            "Iteration: 1299\t Weight1: [8.79160184]\t Weight2: [1.61602682]\t Bias: [3.07793558]\t Cost: 15.469599439418431\n",
            "Iteration: 1300\t Weight1: [8.79231051]\t Weight2: [1.61505373]\t Bias: [3.07652147]\t Cost: 15.46942724170485\n",
            "Iteration: 1301\t Weight1: [8.79301743]\t Weight2: [1.61408272]\t Bias: [3.07511196]\t Cost: 15.469256018869666\n",
            "Iteration: 1302\t Weight1: [8.79372259]\t Weight2: [1.61311378]\t Bias: [3.07370704]\t Cost: 15.469085765218585\n",
            "Iteration: 1303\t Weight1: [8.79442601]\t Weight2: [1.6121469]\t Bias: [3.07230669]\t Cost: 15.468916475091836\n",
            "Iteration: 1304\t Weight1: [8.79512767]\t Weight2: [1.6111821]\t Bias: [3.0709109]\t Cost: 15.468748142863939\n",
            "Iteration: 1305\t Weight1: [8.7958276]\t Weight2: [1.61021935]\t Bias: [3.06951965]\t Cost: 15.468580762943539\n",
            "Iteration: 1306\t Weight1: [8.79652579]\t Weight2: [1.60925867]\t Bias: [3.06813293]\t Cost: 15.468414329773111\n",
            "Iteration: 1307\t Weight1: [8.79722225]\t Weight2: [1.60830003]\t Bias: [3.06675072]\t Cost: 15.468248837828826\n",
            "Iteration: 1308\t Weight1: [8.79791698]\t Weight2: [1.60734345]\t Bias: [3.06537301]\t Cost: 15.468084281620268\n",
            "Iteration: 1309\t Weight1: [8.79860998]\t Weight2: [1.60638892]\t Bias: [3.06399978]\t Cost: 15.467920655690296\n",
            "Iteration: 1310\t Weight1: [8.79930127]\t Weight2: [1.60543643]\t Bias: [3.06263101]\t Cost: 15.467757954614754\n",
            "Iteration: 1311\t Weight1: [8.79999083]\t Weight2: [1.60448598]\t Bias: [3.06126669]\t Cost: 15.467596173002345\n",
            "Iteration: 1312\t Weight1: [8.80067869]\t Weight2: [1.60353757]\t Bias: [3.05990681]\t Cost: 15.46743530549434\n",
            "Iteration: 1313\t Weight1: [8.80136484]\t Weight2: [1.60259119]\t Bias: [3.05855135]\t Cost: 15.467275346764449\n",
            "Iteration: 1314\t Weight1: [8.80204928]\t Weight2: [1.60164684]\t Bias: [3.0572003]\t Cost: 15.467116291518561\n",
            "Iteration: 1315\t Weight1: [8.80273203]\t Weight2: [1.60070452]\t Bias: [3.05585363]\t Cost: 15.46695813449459\n",
            "Iteration: 1316\t Weight1: [8.80341308]\t Weight2: [1.59976422]\t Bias: [3.05451134]\t Cost: 15.46680087046221\n",
            "Iteration: 1317\t Weight1: [8.80409243]\t Weight2: [1.59882594]\t Bias: [3.05317342]\t Cost: 15.466644494222738\n",
            "Iteration: 1318\t Weight1: [8.8047701]\t Weight2: [1.59788967]\t Bias: [3.05183983]\t Cost: 15.466489000608847\n",
            "Iteration: 1319\t Weight1: [8.80544609]\t Weight2: [1.59695541]\t Bias: [3.05051058]\t Cost: 15.466334384484416\n",
            "Iteration: 1320\t Weight1: [8.8061204]\t Weight2: [1.59602317]\t Bias: [3.04918565]\t Cost: 15.466180640744355\n",
            "Iteration: 1321\t Weight1: [8.80679303]\t Weight2: [1.59509292]\t Bias: [3.04786502]\t Cost: 15.466027764314356\n",
            "Iteration: 1322\t Weight1: [8.80746399]\t Weight2: [1.59416468]\t Bias: [3.04654868]\t Cost: 15.465875750150738\n",
            "Iteration: 1323\t Weight1: [8.80813329]\t Weight2: [1.59323844]\t Bias: [3.04523661]\t Cost: 15.465724593240253\n",
            "Iteration: 1324\t Weight1: [8.80880092]\t Weight2: [1.59231419]\t Bias: [3.04392879]\t Cost: 15.465574288599852\n",
            "Iteration: 1325\t Weight1: [8.80946689]\t Weight2: [1.59139193]\t Bias: [3.04262523]\t Cost: 15.465424831276561\n",
            "Iteration: 1326\t Weight1: [8.81013121]\t Weight2: [1.59047166]\t Bias: [3.04132589]\t Cost: 15.465276216347249\n",
            "Iteration: 1327\t Weight1: [8.81079388]\t Weight2: [1.58955337]\t Bias: [3.04003077]\t Cost: 15.465128438918438\n",
            "Iteration: 1328\t Weight1: [8.8114549]\t Weight2: [1.58863706]\t Bias: [3.03873984]\t Cost: 15.464981494126135\n",
            "Iteration: 1329\t Weight1: [8.81211427]\t Weight2: [1.58772273]\t Bias: [3.03745311]\t Cost: 15.46483537713567\n",
            "Iteration: 1330\t Weight1: [8.81277201]\t Weight2: [1.58681037]\t Bias: [3.03617055]\t Cost: 15.464690083141436\n",
            "Iteration: 1331\t Weight1: [8.81342811]\t Weight2: [1.58589997]\t Bias: [3.03489215]\t Cost: 15.464545607366793\n",
            "Iteration: 1332\t Weight1: [8.81408258]\t Weight2: [1.58499155]\t Bias: [3.03361789]\t Cost: 15.464401945063825\n",
            "Iteration: 1333\t Weight1: [8.81473543]\t Weight2: [1.58408509]\t Bias: [3.03234776]\t Cost: 15.46425909151319\n",
            "Iteration: 1334\t Weight1: [8.81538665]\t Weight2: [1.58318058]\t Bias: [3.03108175]\t Cost: 15.464117042023926\n",
            "Iteration: 1335\t Weight1: [8.81603625]\t Weight2: [1.58227803]\t Bias: [3.02981985]\t Cost: 15.4639757919333\n",
            "Iteration: 1336\t Weight1: [8.81668423]\t Weight2: [1.58137743]\t Bias: [3.02856203]\t Cost: 15.463835336606595\n",
            "Iteration: 1337\t Weight1: [8.81733061]\t Weight2: [1.58047878]\t Bias: [3.02730829]\t Cost: 15.463695671436964\n",
            "Iteration: 1338\t Weight1: [8.81797538]\t Weight2: [1.57958207]\t Bias: [3.02605861]\t Cost: 15.463556791845221\n",
            "Iteration: 1339\t Weight1: [8.81861854]\t Weight2: [1.57868731]\t Bias: [3.02481297]\t Cost: 15.463418693279705\n",
            "Iteration: 1340\t Weight1: [8.8192601]\t Weight2: [1.57779448]\t Bias: [3.02357137]\t Cost: 15.463281371216105\n",
            "Iteration: 1341\t Weight1: [8.81990007]\t Weight2: [1.57690359]\t Bias: [3.0223338]\t Cost: 15.46314482115724\n",
            "Iteration: 1342\t Weight1: [8.82053844]\t Weight2: [1.57601463]\t Bias: [3.02110022]\t Cost: 15.46300903863297\n",
            "Iteration: 1343\t Weight1: [8.82117523]\t Weight2: [1.57512759]\t Bias: [3.01987065]\t Cost: 15.46287401919997\n",
            "Iteration: 1344\t Weight1: [8.82181043]\t Weight2: [1.57424248]\t Bias: [3.01864505]\t Cost: 15.46273975844153\n",
            "Iteration: 1345\t Weight1: [8.82244405]\t Weight2: [1.57335928]\t Bias: [3.01742342]\t Cost: 15.462606251967511\n",
            "Iteration: 1346\t Weight1: [8.8230761]\t Weight2: [1.57247801]\t Bias: [3.01620574]\t Cost: 15.462473495414047\n",
            "Iteration: 1347\t Weight1: [8.82370657]\t Weight2: [1.57159864]\t Bias: [3.014992]\t Cost: 15.462341484443439\n",
            "Iteration: 1348\t Weight1: [8.82433548]\t Weight2: [1.57072119]\t Bias: [3.01378219]\t Cost: 15.462210214744\n",
            "Iteration: 1349\t Weight1: [8.82496281]\t Weight2: [1.56984564]\t Bias: [3.01257629]\t Cost: 15.46207968202992\n",
            "Iteration: 1350\t Weight1: [8.82558859]\t Weight2: [1.568972]\t Bias: [3.01137429]\t Cost: 15.461949882040987\n",
            "Iteration: 1351\t Weight1: [8.82621281]\t Weight2: [1.56810025]\t Bias: [3.01017618]\t Cost: 15.461820810542562\n",
            "Iteration: 1352\t Weight1: [8.82683547]\t Weight2: [1.5672304]\t Bias: [3.00898194]\t Cost: 15.461692463325354\n",
            "Iteration: 1353\t Weight1: [8.82745659]\t Weight2: [1.56636244]\t Bias: [3.00779156]\t Cost: 15.461564836205262\n",
            "Iteration: 1354\t Weight1: [8.82807616]\t Weight2: [1.56549637]\t Bias: [3.00660503]\t Cost: 15.461437925023224\n",
            "Iteration: 1355\t Weight1: [8.82869418]\t Weight2: [1.56463219]\t Bias: [3.00542234]\t Cost: 15.461311725645063\n",
            "Iteration: 1356\t Weight1: [8.82931067]\t Weight2: [1.56376989]\t Bias: [3.00424346]\t Cost: 15.461186233961383\n",
            "Iteration: 1357\t Weight1: [8.82992562]\t Weight2: [1.56290946]\t Bias: [3.0030684]\t Cost: 15.46106144588729\n",
            "Iteration: 1358\t Weight1: [8.83053904]\t Weight2: [1.56205091]\t Bias: [3.00189713]\t Cost: 15.460937357362361\n",
            "Iteration: 1359\t Weight1: [8.83115093]\t Weight2: [1.56119424]\t Bias: [3.00072965]\t Cost: 15.46081396435045\n",
            "Iteration: 1360\t Weight1: [8.8317613]\t Weight2: [1.56033943]\t Bias: [2.99956594]\t Cost: 15.460691262839477\n",
            "Iteration: 1361\t Weight1: [8.83237015]\t Weight2: [1.55948648]\t Bias: [2.99840598]\t Cost: 15.460569248841418\n",
            "Iteration: 1362\t Weight1: [8.83297748]\t Weight2: [1.5586354]\t Bias: [2.99724977]\t Cost: 15.460447918391996\n",
            "Iteration: 1363\t Weight1: [8.83358329]\t Weight2: [1.55778617]\t Bias: [2.99609729]\t Cost: 15.46032726755065\n",
            "Iteration: 1364\t Weight1: [8.8341876]\t Weight2: [1.5569388]\t Bias: [2.99494854]\t Cost: 15.46020729240034\n",
            "Iteration: 1365\t Weight1: [8.83479041]\t Weight2: [1.55609328]\t Bias: [2.99380349]\t Cost: 15.460087989047386\n",
            "Iteration: 1366\t Weight1: [8.83539171]\t Weight2: [1.5552496]\t Bias: [2.99266213]\t Cost: 15.45996935362136\n",
            "Iteration: 1367\t Weight1: [8.83599151]\t Weight2: [1.55440777]\t Bias: [2.99152446]\t Cost: 15.459851382274952\n",
            "Iteration: 1368\t Weight1: [8.83658982]\t Weight2: [1.55356778]\t Bias: [2.99039046]\t Cost: 15.45973407118375\n",
            "Iteration: 1369\t Weight1: [8.83718663]\t Weight2: [1.55272963]\t Bias: [2.98926011]\t Cost: 15.459617416546168\n",
            "Iteration: 1370\t Weight1: [8.83778196]\t Weight2: [1.55189331]\t Bias: [2.98813342]\t Cost: 15.459501414583285\n",
            "Iteration: 1371\t Weight1: [8.83837581]\t Weight2: [1.55105883]\t Bias: [2.98701035]\t Cost: 15.459386061538705\n",
            "Iteration: 1372\t Weight1: [8.83896817]\t Weight2: [1.55022616]\t Bias: [2.98589091]\t Cost: 15.459271353678426\n",
            "Iteration: 1373\t Weight1: [8.83955906]\t Weight2: [1.54939533]\t Bias: [2.98477508]\t Cost: 15.45915728729066\n",
            "Iteration: 1374\t Weight1: [8.84014848]\t Weight2: [1.54856631]\t Bias: [2.98366284]\t Cost: 15.459043858685758\n",
            "Iteration: 1375\t Weight1: [8.84073642]\t Weight2: [1.54773911]\t Bias: [2.98255419]\t Cost: 15.45893106419603\n",
            "Iteration: 1376\t Weight1: [8.8413229]\t Weight2: [1.54691372]\t Bias: [2.98144911]\t Cost: 15.458818900175608\n",
            "Iteration: 1377\t Weight1: [8.84190792]\t Weight2: [1.54609014]\t Bias: [2.98034759]\t Cost: 15.458707363000327\n",
            "Iteration: 1378\t Weight1: [8.84249148]\t Weight2: [1.54526837]\t Bias: [2.97924962]\t Cost: 15.458596449067606\n",
            "Iteration: 1379\t Weight1: [8.84307358]\t Weight2: [1.54444841]\t Bias: [2.97815518]\t Cost: 15.45848615479627\n",
            "Iteration: 1380\t Weight1: [8.84365423]\t Weight2: [1.54363024]\t Bias: [2.97706428]\t Cost: 15.458376476626459\n",
            "Iteration: 1381\t Weight1: [8.84423344]\t Weight2: [1.54281387]\t Bias: [2.97597688]\t Cost: 15.458267411019465\n",
            "Iteration: 1382\t Weight1: [8.8448112]\t Weight2: [1.54199929]\t Bias: [2.97489299]\t Cost: 15.458158954457621\n",
            "Iteration: 1383\t Weight1: [8.84538752]\t Weight2: [1.5411865]\t Bias: [2.97381259]\t Cost: 15.458051103444177\n",
            "Iteration: 1384\t Weight1: [8.8459624]\t Weight2: [1.5403755]\t Bias: [2.97273566]\t Cost: 15.457943854503139\n",
            "Iteration: 1385\t Weight1: [8.84653584]\t Weight2: [1.53956628]\t Bias: [2.9716622]\t Cost: 15.457837204179171\n",
            "Iteration: 1386\t Weight1: [8.84710786]\t Weight2: [1.53875884]\t Bias: [2.97059219]\t Cost: 15.457731149037452\n",
            "Iteration: 1387\t Weight1: [8.84767844]\t Weight2: [1.53795318]\t Bias: [2.96952563]\t Cost: 15.457625685663576\n",
            "Iteration: 1388\t Weight1: [8.84824761]\t Weight2: [1.53714929]\t Bias: [2.9684625]\t Cost: 15.457520810663347\n",
            "Iteration: 1389\t Weight1: [8.84881535]\t Weight2: [1.53634717]\t Bias: [2.96740279]\t Cost: 15.45741652066278\n",
            "Iteration: 1390\t Weight1: [8.84938168]\t Weight2: [1.53554681]\t Bias: [2.96634649]\t Cost: 15.457312812307876\n",
            "Iteration: 1391\t Weight1: [8.8499466]\t Weight2: [1.53474822]\t Bias: [2.96529359]\t Cost: 15.45720968226454\n",
            "Iteration: 1392\t Weight1: [8.8505101]\t Weight2: [1.53395139]\t Bias: [2.96424407]\t Cost: 15.45710712721841\n",
            "Iteration: 1393\t Weight1: [8.8510722]\t Weight2: [1.53315632]\t Bias: [2.96319792]\t Cost: 15.457005143874834\n",
            "Iteration: 1394\t Weight1: [8.85163289]\t Weight2: [1.532363]\t Bias: [2.96215514]\t Cost: 15.456903728958654\n",
            "Iteration: 1395\t Weight1: [8.85219219]\t Weight2: [1.53157142]\t Bias: [2.96111571]\t Cost: 15.456802879214113\n",
            "Iteration: 1396\t Weight1: [8.85275009]\t Weight2: [1.5307816]\t Bias: [2.96007962]\t Cost: 15.45670259140475\n",
            "Iteration: 1397\t Weight1: [8.85330659]\t Weight2: [1.52999351]\t Bias: [2.95904686]\t Cost: 15.4566028623133\n",
            "Iteration: 1398\t Weight1: [8.85386171]\t Weight2: [1.52920717]\t Bias: [2.95801742]\t Cost: 15.45650368874151\n",
            "Iteration: 1399\t Weight1: [8.85441544]\t Weight2: [1.52842256]\t Bias: [2.95699128]\t Cost: 15.456405067510083\n",
            "Iteration: 1400\t Weight1: [8.85496779]\t Weight2: [1.52763969]\t Bias: [2.95596844]\t Cost: 15.456306995458533\n",
            "Iteration: 1401\t Weight1: [8.85551876]\t Weight2: [1.52685855]\t Bias: [2.95494889]\t Cost: 15.456209469445067\n",
            "Iteration: 1402\t Weight1: [8.85606835]\t Weight2: [1.52607913]\t Bias: [2.95393261]\t Cost: 15.456112486346516\n",
            "Iteration: 1403\t Weight1: [8.85661657]\t Weight2: [1.52530144]\t Bias: [2.95291959]\t Cost: 15.456016043058131\n",
            "Iteration: 1404\t Weight1: [8.85716342]\t Weight2: [1.52452546]\t Bias: [2.95190983]\t Cost: 15.455920136493566\n",
            "Iteration: 1405\t Weight1: [8.85770891]\t Weight2: [1.52375121]\t Bias: [2.9509033]\t Cost: 15.45582476358469\n",
            "Iteration: 1406\t Weight1: [8.85825303]\t Weight2: [1.52297866]\t Bias: [2.94990001]\t Cost: 15.455729921281518\n",
            "Iteration: 1407\t Weight1: [8.85879579]\t Weight2: [1.52220783]\t Bias: [2.94889993]\t Cost: 15.455635606552098\n",
            "Iteration: 1408\t Weight1: [8.8593372]\t Weight2: [1.5214387]\t Bias: [2.94790307]\t Cost: 15.455541816382372\n",
            "Iteration: 1409\t Weight1: [8.85987725]\t Weight2: [1.52067128]\t Bias: [2.9469094]\t Cost: 15.455448547776083\n",
            "Iteration: 1410\t Weight1: [8.86041596]\t Weight2: [1.51990556]\t Bias: [2.94591892]\t Cost: 15.455355797754693\n",
            "Iteration: 1411\t Weight1: [8.86095332]\t Weight2: [1.51914153]\t Bias: [2.94493162]\t Cost: 15.455263563357217\n",
            "Iteration: 1412\t Weight1: [8.86148933]\t Weight2: [1.5183792]\t Bias: [2.94394748]\t Cost: 15.455171841640148\n",
            "Iteration: 1413\t Weight1: [8.86202401]\t Weight2: [1.51761856]\t Bias: [2.9429665]\t Cost: 15.455080629677397\n",
            "Iteration: 1414\t Weight1: [8.86255735]\t Weight2: [1.5168596]\t Bias: [2.94198866]\t Cost: 15.454989924560042\n",
            "Iteration: 1415\t Weight1: [8.86308936]\t Weight2: [1.51610234]\t Bias: [2.94101395]\t Cost: 15.454899723396396\n",
            "Iteration: 1416\t Weight1: [8.86362004]\t Weight2: [1.51534675]\t Bias: [2.94004238]\t Cost: 15.454810023311824\n",
            "Iteration: 1417\t Weight1: [8.86414939]\t Weight2: [1.51459284]\t Bias: [2.93907391]\t Cost: 15.454720821448577\n",
            "Iteration: 1418\t Weight1: [8.86467742]\t Weight2: [1.5138406]\t Bias: [2.93810855]\t Cost: 15.454632114965808\n",
            "Iteration: 1419\t Weight1: [8.86520413]\t Weight2: [1.51309003]\t Bias: [2.93714628]\t Cost: 15.454543901039372\n",
            "Iteration: 1420\t Weight1: [8.86572952]\t Weight2: [1.51234114]\t Bias: [2.93618709]\t Cost: 15.454456176861791\n",
            "Iteration: 1421\t Weight1: [8.8662536]\t Weight2: [1.5115939]\t Bias: [2.93523097]\t Cost: 15.454368939642077\n",
            "Iteration: 1422\t Weight1: [8.86677637]\t Weight2: [1.51084833]\t Bias: [2.93427792]\t Cost: 15.454282186605749\n",
            "Iteration: 1423\t Weight1: [8.86729783]\t Weight2: [1.51010442]\t Bias: [2.93332792]\t Cost: 15.454195914994578\n",
            "Iteration: 1424\t Weight1: [8.86781798]\t Weight2: [1.50936216]\t Bias: [2.93238096]\t Cost: 15.454110122066634\n",
            "Iteration: 1425\t Weight1: [8.86833684]\t Weight2: [1.50862155]\t Bias: [2.93143703]\t Cost: 15.454024805096068\n",
            "Iteration: 1426\t Weight1: [8.8688544]\t Weight2: [1.5078826]\t Bias: [2.93049612]\t Cost: 15.45393996137313\n",
            "Iteration: 1427\t Weight1: [8.86937066]\t Weight2: [1.50714529]\t Bias: [2.92955822]\t Cost: 15.453855588203924\n",
            "Iteration: 1428\t Weight1: [8.86988564]\t Weight2: [1.50640962]\t Bias: [2.92862332]\t Cost: 15.453771682910487\n",
            "Iteration: 1429\t Weight1: [8.87039932]\t Weight2: [1.50567559]\t Bias: [2.92769142]\t Cost: 15.453688242830511\n",
            "Iteration: 1430\t Weight1: [8.87091172]\t Weight2: [1.50494319]\t Bias: [2.92676249]\t Cost: 15.453605265317403\n",
            "Iteration: 1431\t Weight1: [8.87142284]\t Weight2: [1.50421243]\t Bias: [2.92583654]\t Cost: 15.45352274774008\n",
            "Iteration: 1432\t Weight1: [8.87193268]\t Weight2: [1.5034833]\t Bias: [2.92491355]\t Cost: 15.453440687482953\n",
            "Iteration: 1433\t Weight1: [8.87244124]\t Weight2: [1.50275579]\t Bias: [2.9239935]\t Cost: 15.453359081945749\n",
            "Iteration: 1434\t Weight1: [8.87294853]\t Weight2: [1.50202991]\t Bias: [2.9230764]\t Cost: 15.453277928543503\n",
            "Iteration: 1435\t Weight1: [8.87345455]\t Weight2: [1.50130565]\t Bias: [2.92216224]\t Cost: 15.453197224706422\n",
            "Iteration: 1436\t Weight1: [8.87395931]\t Weight2: [1.500583]\t Bias: [2.92125099]\t Cost: 15.453116967879767\n",
            "Iteration: 1437\t Weight1: [8.8744628]\t Weight2: [1.49986197]\t Bias: [2.92034265]\t Cost: 15.453037155523797\n",
            "Iteration: 1438\t Weight1: [8.87496504]\t Weight2: [1.49914255]\t Bias: [2.91943722]\t Cost: 15.452957785113716\n",
            "Iteration: 1439\t Weight1: [8.87546601]\t Weight2: [1.49842474]\t Bias: [2.91853468]\t Cost: 15.452878854139488\n",
            "Iteration: 1440\t Weight1: [8.87596573]\t Weight2: [1.49770853]\t Bias: [2.91763503]\t Cost: 15.452800360105805\n",
            "Iteration: 1441\t Weight1: [8.8764642]\t Weight2: [1.49699392]\t Bias: [2.91673824]\t Cost: 15.452722300531995\n",
            "Iteration: 1442\t Weight1: [8.87696143]\t Weight2: [1.49628091]\t Bias: [2.91584432]\t Cost: 15.452644672951932\n",
            "Iteration: 1443\t Weight1: [8.87745741]\t Weight2: [1.4955695]\t Bias: [2.91495326]\t Cost: 15.452567474913929\n",
            "Iteration: 1444\t Weight1: [8.87795214]\t Weight2: [1.49485967]\t Bias: [2.91406504]\t Cost: 15.452490703980665\n",
            "Iteration: 1445\t Weight1: [8.87844564]\t Weight2: [1.49415144]\t Bias: [2.91317965]\t Cost: 15.452414357729117\n",
            "Iteration: 1446\t Weight1: [8.8789379]\t Weight2: [1.49344479]\t Bias: [2.91229709]\t Cost: 15.452338433750423\n",
            "Iteration: 1447\t Weight1: [8.87942893]\t Weight2: [1.49273972]\t Bias: [2.91141735]\t Cost: 15.452262929649814\n",
            "Iteration: 1448\t Weight1: [8.87991873]\t Weight2: [1.49203624]\t Bias: [2.91054042]\t Cost: 15.452187843046584\n",
            "Iteration: 1449\t Weight1: [8.88040731]\t Weight2: [1.49133433]\t Bias: [2.90966628]\t Cost: 15.452113171573927\n",
            "Iteration: 1450\t Weight1: [8.88089466]\t Weight2: [1.49063399]\t Bias: [2.90879493]\t Cost: 15.452038912878878\n",
            "Iteration: 1451\t Weight1: [8.88138079]\t Weight2: [1.48993522]\t Bias: [2.90792636]\t Cost: 15.451965064622263\n",
            "Iteration: 1452\t Weight1: [8.8818657]\t Weight2: [1.48923802]\t Bias: [2.90706056]\t Cost: 15.451891624478568\n",
            "Iteration: 1453\t Weight1: [8.8823494]\t Weight2: [1.48854238]\t Bias: [2.90619752]\t Cost: 15.451818590135876\n",
            "Iteration: 1454\t Weight1: [8.88283189]\t Weight2: [1.48784831]\t Bias: [2.90533724]\t Cost: 15.451745959295803\n",
            "Iteration: 1455\t Weight1: [8.88331316]\t Weight2: [1.48715579]\t Bias: [2.90447969]\t Cost: 15.45167372967337\n",
            "Iteration: 1456\t Weight1: [8.88379324]\t Weight2: [1.48646483]\t Bias: [2.90362488]\t Cost: 15.451601898996955\n",
            "Iteration: 1457\t Weight1: [8.88427211]\t Weight2: [1.48577542]\t Bias: [2.90277279]\t Cost: 15.451530465008236\n",
            "Iteration: 1458\t Weight1: [8.88474978]\t Weight2: [1.48508755]\t Bias: [2.90192342]\t Cost: 15.45145942546204\n",
            "Iteration: 1459\t Weight1: [8.88522625]\t Weight2: [1.48440123]\t Bias: [2.90107675]\t Cost: 15.451388778126322\n",
            "Iteration: 1460\t Weight1: [8.88570153]\t Weight2: [1.48371646]\t Bias: [2.90023278]\t Cost: 15.451318520782069\n",
            "Iteration: 1461\t Weight1: [8.88617561]\t Weight2: [1.48303322]\t Bias: [2.8993915]\t Cost: 15.451248651223224\n",
            "Iteration: 1462\t Weight1: [8.88664851]\t Weight2: [1.48235152]\t Bias: [2.8985529]\t Cost: 15.45117916725658\n",
            "Iteration: 1463\t Weight1: [8.88712023]\t Weight2: [1.48167136]\t Bias: [2.89771697]\t Cost: 15.451110066701737\n",
            "Iteration: 1464\t Weight1: [8.88759076]\t Weight2: [1.48099272]\t Bias: [2.8968837]\t Cost: 15.451041347391019\n",
            "Iteration: 1465\t Weight1: [8.88806012]\t Weight2: [1.48031561]\t Bias: [2.89605308]\t Cost: 15.450973007169392\n",
            "Iteration: 1466\t Weight1: [8.88852829]\t Weight2: [1.47964002]\t Bias: [2.89522511]\t Cost: 15.450905043894373\n",
            "Iteration: 1467\t Weight1: [8.8889953]\t Weight2: [1.47896596]\t Bias: [2.89439977]\t Cost: 15.450837455435966\n",
            "Iteration: 1468\t Weight1: [8.88946113]\t Weight2: [1.47829341]\t Bias: [2.89357706]\t Cost: 15.450770239676586\n",
            "Iteration: 1469\t Weight1: [8.88992579]\t Weight2: [1.47762238]\t Bias: [2.89275697]\t Cost: 15.45070339451101\n",
            "Iteration: 1470\t Weight1: [8.89038929]\t Weight2: [1.47695286]\t Bias: [2.89193948]\t Cost: 15.450636917846259\n",
            "Iteration: 1471\t Weight1: [8.89085163]\t Weight2: [1.47628485]\t Bias: [2.8911246]\t Cost: 15.450570807601526\n",
            "Iteration: 1472\t Weight1: [8.89131281]\t Weight2: [1.47561835]\t Bias: [2.8903123]\t Cost: 15.450505061708148\n",
            "Iteration: 1473\t Weight1: [8.89177283]\t Weight2: [1.47495335]\t Bias: [2.88950259]\t Cost: 15.450439678109502\n",
            "Iteration: 1474\t Weight1: [8.8922317]\t Weight2: [1.47428985]\t Bias: [2.88869545]\t Cost: 15.450374654760896\n",
            "Iteration: 1475\t Weight1: [8.89268942]\t Weight2: [1.47362784]\t Bias: [2.88789088]\t Cost: 15.450309989629584\n",
            "Iteration: 1476\t Weight1: [8.89314599]\t Weight2: [1.47296733]\t Bias: [2.88708887]\t Cost: 15.450245680694605\n",
            "Iteration: 1477\t Weight1: [8.89360141]\t Weight2: [1.47230831]\t Bias: [2.88628941]\t Cost: 15.450181725946798\n",
            "Iteration: 1478\t Weight1: [8.89405569]\t Weight2: [1.47165078]\t Bias: [2.88549248]\t Cost: 15.450118123388624\n",
            "Iteration: 1479\t Weight1: [8.89450884]\t Weight2: [1.47099473]\t Bias: [2.88469809]\t Cost: 15.450054871034197\n",
            "Iteration: 1480\t Weight1: [8.89496084]\t Weight2: [1.47034017]\t Bias: [2.88390623]\t Cost: 15.449991966909161\n",
            "Iteration: 1481\t Weight1: [8.89541172]\t Weight2: [1.46968708]\t Bias: [2.88311687]\t Cost: 15.44992940905067\n",
            "Iteration: 1482\t Weight1: [8.89586146]\t Weight2: [1.46903548]\t Bias: [2.88233003]\t Cost: 15.449867195507194\n",
            "Iteration: 1483\t Weight1: [8.89631007]\t Weight2: [1.46838534]\t Bias: [2.88154568]\t Cost: 15.449805324338616\n",
            "Iteration: 1484\t Weight1: [8.89675756]\t Weight2: [1.46773667]\t Bias: [2.88076382]\t Cost: 15.449743793616076\n",
            "Iteration: 1485\t Weight1: [8.89720392]\t Weight2: [1.46708948]\t Bias: [2.87998445]\t Cost: 15.449682601421864\n",
            "Iteration: 1486\t Weight1: [8.89764917]\t Weight2: [1.46644374]\t Bias: [2.87920755]\t Cost: 15.44962174584945\n",
            "Iteration: 1487\t Weight1: [8.8980933]\t Weight2: [1.46579947]\t Bias: [2.87843311]\t Cost: 15.449561225003356\n",
            "Iteration: 1488\t Weight1: [8.89853631]\t Weight2: [1.46515665]\t Bias: [2.87766114]\t Cost: 15.44950103699908\n",
            "Iteration: 1489\t Weight1: [8.89897821]\t Weight2: [1.46451529]\t Bias: [2.87689161]\t Cost: 15.449441179963094\n",
            "Iteration: 1490\t Weight1: [8.899419]\t Weight2: [1.46387539]\t Bias: [2.87612452]\t Cost: 15.44938165203267\n",
            "Iteration: 1491\t Weight1: [8.89985869]\t Weight2: [1.46323693]\t Bias: [2.87535987]\t Cost: 15.449322451355979\n",
            "Iteration: 1492\t Weight1: [8.90029727]\t Weight2: [1.46259992]\t Bias: [2.87459764]\t Cost: 15.4492635760918\n",
            "Iteration: 1493\t Weight1: [8.90073475]\t Weight2: [1.46196436]\t Bias: [2.87383783]\t Cost: 15.449205024409729\n",
            "Iteration: 1494\t Weight1: [8.90117114]\t Weight2: [1.46133023]\t Bias: [2.87308043]\t Cost: 15.44914679448982\n",
            "Iteration: 1495\t Weight1: [8.90160642]\t Weight2: [1.46069754]\t Bias: [2.87232543]\t Cost: 15.44908888452278\n",
            "Iteration: 1496\t Weight1: [8.90204062]\t Weight2: [1.46006629]\t Bias: [2.87157282]\t Cost: 15.449031292709744\n",
            "Iteration: 1497\t Weight1: [8.90247372]\t Weight2: [1.45943647]\t Bias: [2.8708226]\t Cost: 15.448974017262298\n",
            "Iteration: 1498\t Weight1: [8.90290574]\t Weight2: [1.45880808]\t Bias: [2.87007476]\t Cost: 15.448917056402353\n",
            "Iteration: 1499\t Weight1: [8.90333667]\t Weight2: [1.45818111]\t Bias: [2.86932928]\t Cost: 15.4488604083621\n",
            "Iteration: 1500\t Weight1: [8.90376652]\t Weight2: [1.45755557]\t Bias: [2.86858617]\t Cost: 15.448804071383993\n",
            "Iteration: 1501\t Weight1: [8.90419529]\t Weight2: [1.45693145]\t Bias: [2.86784541]\t Cost: 15.448748043720649\n",
            "Iteration: 1502\t Weight1: [8.90462299]\t Weight2: [1.45630875]\t Bias: [2.867107]\t Cost: 15.44869232363479\n",
            "Iteration: 1503\t Weight1: [8.90504961]\t Weight2: [1.45568746]\t Bias: [2.86637092]\t Cost: 15.44863690939916\n",
            "Iteration: 1504\t Weight1: [8.90547516]\t Weight2: [1.45506758]\t Bias: [2.86563718]\t Cost: 15.44858179929654\n",
            "Iteration: 1505\t Weight1: [8.90589964]\t Weight2: [1.45444912]\t Bias: [2.86490576]\t Cost: 15.448526991619616\n",
            "Iteration: 1506\t Weight1: [8.90632305]\t Weight2: [1.45383206]\t Bias: [2.86417665]\t Cost: 15.448472484670903\n",
            "Iteration: 1507\t Weight1: [8.9067454]\t Weight2: [1.4532164]\t Bias: [2.86344985]\t Cost: 15.448418276762787\n",
            "Iteration: 1508\t Weight1: [8.90716669]\t Weight2: [1.45260214]\t Bias: [2.86272536]\t Cost: 15.44836436621737\n",
            "Iteration: 1509\t Weight1: [8.90758692]\t Weight2: [1.45198928]\t Bias: [2.86200315]\t Cost: 15.448310751366447\n",
            "Iteration: 1510\t Weight1: [8.9080061]\t Weight2: [1.45137782]\t Bias: [2.86128323]\t Cost: 15.448257430551454\n",
            "Iteration: 1511\t Weight1: [8.90842422]\t Weight2: [1.45076774]\t Bias: [2.86056559]\t Cost: 15.44820440212342\n",
            "Iteration: 1512\t Weight1: [8.90884129]\t Weight2: [1.45015906]\t Bias: [2.85985021]\t Cost: 15.448151664442843\n",
            "Iteration: 1513\t Weight1: [8.90925731]\t Weight2: [1.44955176]\t Bias: [2.8591371]\t Cost: 15.448099215879736\n",
            "Iteration: 1514\t Weight1: [8.90967229]\t Weight2: [1.44894585]\t Bias: [2.85842625]\t Cost: 15.448047054813495\n",
            "Iteration: 1515\t Weight1: [8.91008623]\t Weight2: [1.44834131]\t Bias: [2.85771764]\t Cost: 15.44799517963285\n",
            "Iteration: 1516\t Weight1: [8.91049912]\t Weight2: [1.44773816]\t Bias: [2.85701127]\t Cost: 15.447943588735855\n",
            "Iteration: 1517\t Weight1: [8.91091098]\t Weight2: [1.44713638]\t Bias: [2.85630713]\t Cost: 15.447892280529778\n",
            "Iteration: 1518\t Weight1: [8.9113218]\t Weight2: [1.44653597]\t Bias: [2.85560522]\t Cost: 15.447841253431088\n",
            "Iteration: 1519\t Weight1: [8.91173159]\t Weight2: [1.44593693]\t Bias: [2.85490553]\t Cost: 15.44779050586536\n",
            "Iteration: 1520\t Weight1: [8.91214035]\t Weight2: [1.44533926]\t Bias: [2.85420805]\t Cost: 15.447740036267266\n",
            "Iteration: 1521\t Weight1: [8.91254808]\t Weight2: [1.44474295]\t Bias: [2.85351277]\t Cost: 15.44768984308047\n",
            "Iteration: 1522\t Weight1: [8.91295479]\t Weight2: [1.444148]\t Bias: [2.85281969]\t Cost: 15.447639924757642\n",
            "Iteration: 1523\t Weight1: [8.91336047]\t Weight2: [1.44355441]\t Bias: [2.85212879]\t Cost: 15.44759027976031\n",
            "Iteration: 1524\t Weight1: [8.91376513]\t Weight2: [1.44296218]\t Bias: [2.85144008]\t Cost: 15.447540906558912\n",
            "Iteration: 1525\t Weight1: [8.91416878]\t Weight2: [1.44237129]\t Bias: [2.85075354]\t Cost: 15.447491803632664\n",
            "Iteration: 1526\t Weight1: [8.91457141]\t Weight2: [1.44178176]\t Bias: [2.85006917]\t Cost: 15.447442969469538\n",
            "Iteration: 1527\t Weight1: [8.91497303]\t Weight2: [1.44119358]\t Bias: [2.84938696]\t Cost: 15.447394402566198\n",
            "Iteration: 1528\t Weight1: [8.91537364]\t Weight2: [1.44060674]\t Bias: [2.84870691]\t Cost: 15.447346101427984\n",
            "Iteration: 1529\t Weight1: [8.91577325]\t Weight2: [1.44002124]\t Bias: [2.848029]\t Cost: 15.447298064568828\n",
            "Iteration: 1530\t Weight1: [8.91617184]\t Weight2: [1.43943708]\t Bias: [2.84735322]\t Cost: 15.447250290511182\n",
            "Iteration: 1531\t Weight1: [8.91656944]\t Weight2: [1.43885425]\t Bias: [2.84667958]\t Cost: 15.447202777786012\n",
            "Iteration: 1532\t Weight1: [8.91696603]\t Weight2: [1.43827276]\t Bias: [2.84600807]\t Cost: 15.447155524932747\n",
            "Iteration: 1533\t Weight1: [8.91736163]\t Weight2: [1.4376926]\t Bias: [2.84533867]\t Cost: 15.44710853049918\n",
            "Iteration: 1534\t Weight1: [8.91775623]\t Weight2: [1.43711377]\t Bias: [2.84467138]\t Cost: 15.447061793041463\n",
            "Iteration: 1535\t Weight1: [8.91814984]\t Weight2: [1.43653626]\t Bias: [2.8440062]\t Cost: 15.447015311124037\n",
            "Iteration: 1536\t Weight1: [8.91854246]\t Weight2: [1.43596007]\t Bias: [2.84334311]\t Cost: 15.44696908331961\n",
            "Iteration: 1537\t Weight1: [8.91893409]\t Weight2: [1.43538521]\t Bias: [2.84268212]\t Cost: 15.446923108209058\n",
            "Iteration: 1538\t Weight1: [8.91932474]\t Weight2: [1.43481166]\t Bias: [2.8420232]\t Cost: 15.44687738438143\n",
            "Iteration: 1539\t Weight1: [8.9197144]\t Weight2: [1.43423942]\t Bias: [2.84136637]\t Cost: 15.446831910433849\n",
            "Iteration: 1540\t Weight1: [8.92010309]\t Weight2: [1.4336685]\t Bias: [2.8407116]\t Cost: 15.446786684971505\n",
            "Iteration: 1541\t Weight1: [8.92049079]\t Weight2: [1.43309888]\t Bias: [2.8400589]\t Cost: 15.446741706607586\n",
            "Iteration: 1542\t Weight1: [8.92087752]\t Weight2: [1.43253057]\t Bias: [2.83940825]\t Cost: 15.44669697396328\n",
            "Iteration: 1543\t Weight1: [8.92126328]\t Weight2: [1.43196357]\t Bias: [2.83875965]\t Cost: 15.446652485667627\n",
            "Iteration: 1544\t Weight1: [8.92164806]\t Weight2: [1.43139786]\t Bias: [2.83811309]\t Cost: 15.446608240357524\n",
            "Iteration: 1545\t Weight1: [8.92203188]\t Weight2: [1.43083346]\t Bias: [2.83746857]\t Cost: 15.44656423667772\n",
            "Iteration: 1546\t Weight1: [8.92241473]\t Weight2: [1.43027034]\t Bias: [2.83682608]\t Cost: 15.446520473280728\n",
            "Iteration: 1547\t Weight1: [8.92279662]\t Weight2: [1.42970852]\t Bias: [2.83618561]\t Cost: 15.44647694882678\n",
            "Iteration: 1548\t Weight1: [8.92317755]\t Weight2: [1.42914799]\t Bias: [2.83554716]\t Cost: 15.446433661983793\n",
            "Iteration: 1549\t Weight1: [8.92355752]\t Weight2: [1.42858875]\t Bias: [2.83491072]\t Cost: 15.446390611427272\n",
            "Iteration: 1550\t Weight1: [8.92393653]\t Weight2: [1.42803079]\t Bias: [2.83427628]\t Cost: 15.44634779584036\n",
            "Iteration: 1551\t Weight1: [8.92431458]\t Weight2: [1.42747411]\t Bias: [2.83364383]\t Cost: 15.446305213913737\n",
            "Iteration: 1552\t Weight1: [8.92469169]\t Weight2: [1.42691872]\t Bias: [2.83301337]\t Cost: 15.44626286434555\n",
            "Iteration: 1553\t Weight1: [8.92506784]\t Weight2: [1.42636459]\t Bias: [2.8323849]\t Cost: 15.44622074584143\n",
            "Iteration: 1554\t Weight1: [8.92544305]\t Weight2: [1.42581175]\t Bias: [2.8317584]\t Cost: 15.446178857114383\n",
            "Iteration: 1555\t Weight1: [8.92581732]\t Weight2: [1.42526017]\t Bias: [2.83113388]\t Cost: 15.446137196884806\n",
            "Iteration: 1556\t Weight1: [8.92619064]\t Weight2: [1.42470986]\t Bias: [2.83051131]\t Cost: 15.446095763880411\n",
            "Iteration: 1557\t Weight1: [8.92656302]\t Weight2: [1.42416082]\t Bias: [2.82989071]\t Cost: 15.446054556836206\n",
            "Iteration: 1558\t Weight1: [8.92693446]\t Weight2: [1.42361304]\t Bias: [2.82927205]\t Cost: 15.446013574494373\n",
            "Iteration: 1559\t Weight1: [8.92730497]\t Weight2: [1.42306652]\t Bias: [2.82865534]\t Cost: 15.44597281560436\n",
            "Iteration: 1560\t Weight1: [8.92767455]\t Weight2: [1.42252126]\t Bias: [2.82804057]\t Cost: 15.445932278922719\n",
            "Iteration: 1561\t Weight1: [8.92804319]\t Weight2: [1.42197726]\t Bias: [2.82742772]\t Cost: 15.445891963213121\n",
            "Iteration: 1562\t Weight1: [8.92841091]\t Weight2: [1.42143451]\t Bias: [2.82681681]\t Cost: 15.445851867246297\n",
            "Iteration: 1563\t Weight1: [8.9287777]\t Weight2: [1.420893]\t Bias: [2.82620781]\t Cost: 15.445811989800038\n",
            "Iteration: 1564\t Weight1: [8.92914356]\t Weight2: [1.42035275]\t Bias: [2.82560072]\t Cost: 15.44577232965905\n",
            "Iteration: 1565\t Weight1: [8.92950851]\t Weight2: [1.41981374]\t Bias: [2.82499554]\t Cost: 15.445732885615037\n",
            "Iteration: 1566\t Weight1: [8.92987253]\t Weight2: [1.41927597]\t Bias: [2.82439226]\t Cost: 15.445693656466574\n",
            "Iteration: 1567\t Weight1: [8.93023564]\t Weight2: [1.41873944]\t Bias: [2.82379088]\t Cost: 15.445654641019088\n",
            "Iteration: 1568\t Weight1: [8.93059783]\t Weight2: [1.41820415]\t Bias: [2.82319138]\t Cost: 15.44561583808487\n",
            "Iteration: 1569\t Weight1: [8.93095911]\t Weight2: [1.41767009]\t Bias: [2.82259376]\t Cost: 15.445577246482927\n",
            "Iteration: 1570\t Weight1: [8.93131948]\t Weight2: [1.41713727]\t Bias: [2.82199802]\t Cost: 15.445538865039053\n",
            "Iteration: 1571\t Weight1: [8.93167894]\t Weight2: [1.41660567]\t Bias: [2.82140415]\t Cost: 15.445500692585714\n",
            "Iteration: 1572\t Weight1: [8.9320375]\t Weight2: [1.4160753]\t Bias: [2.82081214]\t Cost: 15.445462727962063\n",
            "Iteration: 1573\t Weight1: [8.93239515]\t Weight2: [1.41554616]\t Bias: [2.82022199]\t Cost: 15.445424970013834\n",
            "Iteration: 1574\t Weight1: [8.9327519]\t Weight2: [1.41501824]\t Bias: [2.81963369]\t Cost: 15.445387417593361\n",
            "Iteration: 1575\t Weight1: [8.93310775]\t Weight2: [1.41449153]\t Bias: [2.81904723]\t Cost: 15.445350069559519\n",
            "Iteration: 1576\t Weight1: [8.93346271]\t Weight2: [1.41396604]\t Bias: [2.81846261]\t Cost: 15.445312924777712\n",
            "Iteration: 1577\t Weight1: [8.93381677]\t Weight2: [1.41344177]\t Bias: [2.81787982]\t Cost: 15.445275982119774\n",
            "Iteration: 1578\t Weight1: [8.93416994]\t Weight2: [1.41291871]\t Bias: [2.81729887]\t Cost: 15.445239240463952\n",
            "Iteration: 1579\t Weight1: [8.93452222]\t Weight2: [1.41239685]\t Bias: [2.81671973]\t Cost: 15.445202698694924\n",
            "Iteration: 1580\t Weight1: [8.93487361]\t Weight2: [1.4118762]\t Bias: [2.81614241]\t Cost: 15.44516635570373\n",
            "Iteration: 1581\t Weight1: [8.93522411]\t Weight2: [1.41135676]\t Bias: [2.81556689]\t Cost: 15.445130210387662\n",
            "Iteration: 1582\t Weight1: [8.93557373]\t Weight2: [1.41083852]\t Bias: [2.81499318]\t Cost: 15.445094261650338\n",
            "Iteration: 1583\t Weight1: [8.93592247]\t Weight2: [1.41032147]\t Bias: [2.81442127]\t Cost: 15.445058508401601\n",
            "Iteration: 1584\t Weight1: [8.93627033]\t Weight2: [1.40980562]\t Bias: [2.81385114]\t Cost: 15.44502294955749\n",
            "Iteration: 1585\t Weight1: [8.93661731]\t Weight2: [1.40929097]\t Bias: [2.8132828]\t Cost: 15.444987584040247\n",
            "Iteration: 1586\t Weight1: [8.93696342]\t Weight2: [1.4087775]\t Bias: [2.81271625]\t Cost: 15.444952410778209\n",
            "Iteration: 1587\t Weight1: [8.93730865]\t Weight2: [1.40826523]\t Bias: [2.81215146]\t Cost: 15.444917428705804\n",
            "Iteration: 1588\t Weight1: [8.93765302]\t Weight2: [1.40775414]\t Bias: [2.81158845]\t Cost: 15.444882636763532\n",
            "Iteration: 1589\t Weight1: [8.93799651]\t Weight2: [1.40724423]\t Bias: [2.81102719]\t Cost: 15.444848033897925\n",
            "Iteration: 1590\t Weight1: [8.93833914]\t Weight2: [1.40673551]\t Bias: [2.81046769]\t Cost: 15.444813619061506\n",
            "Iteration: 1591\t Weight1: [8.93868091]\t Weight2: [1.40622796]\t Bias: [2.80990995]\t Cost: 15.444779391212716\n",
            "Iteration: 1592\t Weight1: [8.93902181]\t Weight2: [1.40572159]\t Bias: [2.80935394]\t Cost: 15.444745349315966\n",
            "Iteration: 1593\t Weight1: [8.93936185]\t Weight2: [1.40521639]\t Bias: [2.80879968]\t Cost: 15.444711492341492\n",
            "Iteration: 1594\t Weight1: [8.93970104]\t Weight2: [1.40471237]\t Bias: [2.80824715]\t Cost: 15.444677819265438\n",
            "Iteration: 1595\t Weight1: [8.94003937]\t Weight2: [1.40420951]\t Bias: [2.80769635]\t Cost: 15.444644329069716\n",
            "Iteration: 1596\t Weight1: [8.94037685]\t Weight2: [1.40370782]\t Bias: [2.80714727]\t Cost: 15.444611020742048\n",
            "Iteration: 1597\t Weight1: [8.94071347]\t Weight2: [1.40320729]\t Bias: [2.80659991]\t Cost: 15.44457789327587\n",
            "Iteration: 1598\t Weight1: [8.94104925]\t Weight2: [1.40270792]\t Bias: [2.80605425]\t Cost: 15.444544945670367\n",
            "Iteration: 1599\t Weight1: [8.94138418]\t Weight2: [1.40220971]\t Bias: [2.80551031]\t Cost: 15.444512176930386\n",
            "Iteration: 1600\t Weight1: [8.94171826]\t Weight2: [1.40171266]\t Bias: [2.80496806]\t Cost: 15.444479586066404\n",
            "Iteration: 1601\t Weight1: [8.9420515]\t Weight2: [1.40121676]\t Bias: [2.80442751]\t Cost: 15.444447172094574\n",
            "Iteration: 1602\t Weight1: [8.9423839]\t Weight2: [1.40072202]\t Bias: [2.80388864]\t Cost: 15.444414934036537\n",
            "Iteration: 1603\t Weight1: [8.94271546]\t Weight2: [1.40022842]\t Bias: [2.80335146]\t Cost: 15.444382870919561\n",
            "Iteration: 1604\t Weight1: [8.94304618]\t Weight2: [1.39973597]\t Bias: [2.80281596]\t Cost: 15.444350981776372\n",
            "Iteration: 1605\t Weight1: [8.94337607]\t Weight2: [1.39924466]\t Bias: [2.80228213]\t Cost: 15.444319265645216\n",
            "Iteration: 1606\t Weight1: [8.94370513]\t Weight2: [1.39875449]\t Bias: [2.80174997]\t Cost: 15.444287721569765\n",
            "Iteration: 1607\t Weight1: [8.94403336]\t Weight2: [1.39826546]\t Bias: [2.80121947]\t Cost: 15.444256348599149\n",
            "Iteration: 1608\t Weight1: [8.94436076]\t Weight2: [1.39777757]\t Bias: [2.80069062]\t Cost: 15.444225145787838\n",
            "Iteration: 1609\t Weight1: [8.94468733]\t Weight2: [1.39729082]\t Bias: [2.80016343]\t Cost: 15.444194112195659\n",
            "Iteration: 1610\t Weight1: [8.94501308]\t Weight2: [1.39680519]\t Bias: [2.79963788]\t Cost: 15.44416324688782\n",
            "Iteration: 1611\t Weight1: [8.945338]\t Weight2: [1.3963207]\t Bias: [2.79911397]\t Cost: 15.444132548934759\n",
            "Iteration: 1612\t Weight1: [8.94566211]\t Weight2: [1.39583733]\t Bias: [2.79859169]\t Cost: 15.444102017412215\n",
            "Iteration: 1613\t Weight1: [8.94598539]\t Weight2: [1.39535508]\t Bias: [2.79807105]\t Cost: 15.444071651401138\n",
            "Iteration: 1614\t Weight1: [8.94630786]\t Weight2: [1.39487396]\t Bias: [2.79755203]\t Cost: 15.444041449987676\n",
            "Iteration: 1615\t Weight1: [8.94662952]\t Weight2: [1.39439396]\t Bias: [2.79703462]\t Cost: 15.444011412263178\n",
            "Iteration: 1616\t Weight1: [8.94695036]\t Weight2: [1.39391507]\t Bias: [2.79651883]\t Cost: 15.443981537324095\n",
            "Iteration: 1617\t Weight1: [8.9472704]\t Weight2: [1.39343731]\t Bias: [2.79600465]\t Cost: 15.44395182427202\n",
            "Iteration: 1618\t Weight1: [8.94758962]\t Weight2: [1.39296065]\t Bias: [2.79549207]\t Cost: 15.443922272213605\n",
            "Iteration: 1619\t Weight1: [8.94790804]\t Weight2: [1.3924851]\t Bias: [2.79498109]\t Cost: 15.443892880260568\n",
            "Iteration: 1620\t Weight1: [8.94822566]\t Weight2: [1.39201066]\t Bias: [2.7944717]\t Cost: 15.443863647529632\n",
            "Iteration: 1621\t Weight1: [8.94854247]\t Weight2: [1.39153733]\t Bias: [2.7939639]\t Cost: 15.44383457314252\n",
            "Iteration: 1622\t Weight1: [8.94885849]\t Weight2: [1.3910651]\t Bias: [2.79345768]\t Cost: 15.443805656225948\n",
            "Iteration: 1623\t Weight1: [8.9491737]\t Weight2: [1.39059397]\t Bias: [2.79295304]\t Cost: 15.443776895911492\n",
            "Iteration: 1624\t Weight1: [8.94948812]\t Weight2: [1.39012394]\t Bias: [2.79244997]\t Cost: 15.443748291335714\n",
            "Iteration: 1625\t Weight1: [8.94980175]\t Weight2: [1.389655]\t Bias: [2.79194847]\t Cost: 15.443719841640014\n",
            "Iteration: 1626\t Weight1: [8.95011458]\t Weight2: [1.38918716]\t Bias: [2.79144853]\t Cost: 15.443691545970632\n",
            "Iteration: 1627\t Weight1: [8.95042662]\t Weight2: [1.38872041]\t Bias: [2.79095015]\t Cost: 15.443663403478668\n",
            "Iteration: 1628\t Weight1: [8.95073787]\t Weight2: [1.38825475]\t Bias: [2.79045331]\t Cost: 15.443635413319956\n",
            "Iteration: 1629\t Weight1: [8.95104834]\t Weight2: [1.38779017]\t Bias: [2.78995803]\t Cost: 15.443607574655125\n",
            "Iteration: 1630\t Weight1: [8.95135803]\t Weight2: [1.38732668]\t Bias: [2.78946428]\t Cost: 15.44357988664958\n",
            "Iteration: 1631\t Weight1: [8.95166693]\t Weight2: [1.38686427]\t Bias: [2.78897207]\t Cost: 15.443552348473368\n",
            "Iteration: 1632\t Weight1: [8.95197505]\t Weight2: [1.38640294]\t Bias: [2.7884814]\t Cost: 15.443524959301245\n",
            "Iteration: 1633\t Weight1: [8.95228239]\t Weight2: [1.38594269]\t Bias: [2.78799225]\t Cost: 15.443497718312646\n",
            "Iteration: 1634\t Weight1: [8.95258896]\t Weight2: [1.38548351]\t Bias: [2.78750462]\t Cost: 15.44347062469157\n",
            "Iteration: 1635\t Weight1: [8.95289475]\t Weight2: [1.38502541]\t Bias: [2.78701851]\t Cost: 15.443443677626702\n",
            "Iteration: 1636\t Weight1: [8.95319976]\t Weight2: [1.38456838]\t Bias: [2.78653391]\t Cost: 15.443416876311217\n",
            "Iteration: 1637\t Weight1: [8.95350401]\t Weight2: [1.38411241]\t Bias: [2.78605081]\t Cost: 15.443390219942907\n",
            "Iteration: 1638\t Weight1: [8.95380749]\t Weight2: [1.38365751]\t Bias: [2.78556922]\t Cost: 15.443363707724034\n",
            "Iteration: 1639\t Weight1: [8.9541102]\t Weight2: [1.38320367]\t Bias: [2.78508913]\t Cost: 15.443337338861376\n",
            "Iteration: 1640\t Weight1: [8.95441215]\t Weight2: [1.3827509]\t Bias: [2.78461053]\t Cost: 15.443311112566183\n",
            "Iteration: 1641\t Weight1: [8.95471333]\t Weight2: [1.38229918]\t Bias: [2.78413341]\t Cost: 15.44328502805415\n",
            "Iteration: 1642\t Weight1: [8.95501375]\t Weight2: [1.38184852]\t Bias: [2.78365778]\t Cost: 15.443259084545355\n",
            "Iteration: 1643\t Weight1: [8.95531342]\t Weight2: [1.38139892]\t Bias: [2.78318363]\t Cost: 15.443233281264325\n",
            "Iteration: 1644\t Weight1: [8.95561232]\t Weight2: [1.38095036]\t Bias: [2.78271095]\t Cost: 15.443207617439878\n",
            "Iteration: 1645\t Weight1: [8.95591047]\t Weight2: [1.38050286]\t Bias: [2.78223973]\t Cost: 15.443182092305255\n",
            "Iteration: 1646\t Weight1: [8.95620787]\t Weight2: [1.3800564]\t Bias: [2.78176998]\t Cost: 15.443156705097945\n",
            "Iteration: 1647\t Weight1: [8.95650451]\t Weight2: [1.37961099]\t Bias: [2.78130169]\t Cost: 15.443131455059774\n",
            "Iteration: 1648\t Weight1: [8.9568004]\t Weight2: [1.37916663]\t Bias: [2.78083486]\t Cost: 15.443106341436799\n",
            "Iteration: 1649\t Weight1: [8.95709555]\t Weight2: [1.3787233]\t Bias: [2.78036947]\t Cost: 15.443081363479346\n",
            "Iteration: 1650\t Weight1: [8.95738995]\t Weight2: [1.37828101]\t Bias: [2.77990552]\t Cost: 15.443056520441925\n",
            "Iteration: 1651\t Weight1: [8.9576836]\t Weight2: [1.37783976]\t Bias: [2.77944302]\t Cost: 15.443031811583268\n",
            "Iteration: 1652\t Weight1: [8.95797652]\t Weight2: [1.37739954]\t Bias: [2.77898195]\t Cost: 15.443007236166236\n",
            "Iteration: 1653\t Weight1: [8.95826869]\t Weight2: [1.37696035]\t Bias: [2.77852232]\t Cost: 15.442982793457892\n",
            "Iteration: 1654\t Weight1: [8.95856012]\t Weight2: [1.37652219]\t Bias: [2.77806411]\t Cost: 15.44295848272937\n",
            "Iteration: 1655\t Weight1: [8.95885082]\t Weight2: [1.37608506]\t Bias: [2.77760732]\t Cost: 15.44293430325591\n",
            "Iteration: 1656\t Weight1: [8.95914078]\t Weight2: [1.37564896]\t Bias: [2.77715194]\t Cost: 15.442910254316827\n",
            "Iteration: 1657\t Weight1: [8.95943]\t Weight2: [1.37521387]\t Bias: [2.77669798]\t Cost: 15.442886335195492\n",
            "Iteration: 1658\t Weight1: [8.9597185]\t Weight2: [1.37477981]\t Bias: [2.77624543]\t Cost: 15.44286254517928\n",
            "Iteration: 1659\t Weight1: [8.96000626]\t Weight2: [1.37434677]\t Bias: [2.77579428]\t Cost: 15.4428388835596\n",
            "Iteration: 1660\t Weight1: [8.9602933]\t Weight2: [1.37391474]\t Bias: [2.77534453]\t Cost: 15.442815349631799\n",
            "Iteration: 1661\t Weight1: [8.96057961]\t Weight2: [1.37348373]\t Bias: [2.77489617]\t Cost: 15.442791942695212\n",
            "Iteration: 1662\t Weight1: [8.9608652]\t Weight2: [1.37305373]\t Bias: [2.7744492]\t Cost: 15.442768662053082\n",
            "Iteration: 1663\t Weight1: [8.96115007]\t Weight2: [1.37262473]\t Bias: [2.77400362]\t Cost: 15.442745507012596\n",
            "Iteration: 1664\t Weight1: [8.96143421]\t Weight2: [1.37219675]\t Bias: [2.77355941]\t Cost: 15.442722476884777\n",
            "Iteration: 1665\t Weight1: [8.96171764]\t Weight2: [1.37176977]\t Bias: [2.77311659]\t Cost: 15.442699570984566\n",
            "Iteration: 1666\t Weight1: [8.96200035]\t Weight2: [1.37134379]\t Bias: [2.77267513]\t Cost: 15.442676788630711\n",
            "Iteration: 1667\t Weight1: [8.96228234]\t Weight2: [1.37091882]\t Bias: [2.77223504]\t Cost: 15.442654129145781\n",
            "Iteration: 1668\t Weight1: [8.96256362]\t Weight2: [1.37049484]\t Bias: [2.77179632]\t Cost: 15.442631591856173\n",
            "Iteration: 1669\t Weight1: [8.96284419]\t Weight2: [1.37007186]\t Bias: [2.77135895]\t Cost: 15.44260917609202\n",
            "Iteration: 1670\t Weight1: [8.96312404]\t Weight2: [1.36964987]\t Bias: [2.77092294]\t Cost: 15.442586881187239\n",
            "Iteration: 1671\t Weight1: [8.96340319]\t Weight2: [1.36922888]\t Bias: [2.77048827]\t Cost: 15.44256470647947\n",
            "Iteration: 1672\t Weight1: [8.96368164]\t Weight2: [1.36880887]\t Bias: [2.77005496]\t Cost: 15.442542651310077\n",
            "Iteration: 1673\t Weight1: [8.96395937]\t Weight2: [1.36838985]\t Bias: [2.76962298]\t Cost: 15.442520715024083\n",
            "Iteration: 1674\t Weight1: [8.96423641]\t Weight2: [1.36797182]\t Bias: [2.76919234]\t Cost: 15.442498896970196\n",
            "Iteration: 1675\t Weight1: [8.96451274]\t Weight2: [1.36755477]\t Bias: [2.76876303]\t Cost: 15.442477196500787\n",
            "Iteration: 1676\t Weight1: [8.96478838]\t Weight2: [1.36713871]\t Bias: [2.76833505]\t Cost: 15.442455612971806\n",
            "Iteration: 1677\t Weight1: [8.96506332]\t Weight2: [1.36672362]\t Bias: [2.76790839]\t Cost: 15.442434145742888\n",
            "Iteration: 1678\t Weight1: [8.96533756]\t Weight2: [1.36630951]\t Bias: [2.76748305]\t Cost: 15.442412794177187\n",
            "Iteration: 1679\t Weight1: [8.9656111]\t Weight2: [1.36589637]\t Bias: [2.76705903]\t Cost: 15.442391557641429\n",
            "Iteration: 1680\t Weight1: [8.96588396]\t Weight2: [1.36548421]\t Bias: [2.76663632]\t Cost: 15.442370435505904\n",
            "Iteration: 1681\t Weight1: [8.96615612]\t Weight2: [1.36507302]\t Bias: [2.76621491]\t Cost: 15.442349427144425\n",
            "Iteration: 1682\t Weight1: [8.9664276]\t Weight2: [1.36466279]\t Bias: [2.76579481]\t Cost: 15.442328531934269\n",
            "Iteration: 1683\t Weight1: [8.96669838]\t Weight2: [1.36425353]\t Bias: [2.76537601]\t Cost: 15.442307749256258\n",
            "Iteration: 1684\t Weight1: [8.96696849]\t Weight2: [1.36384524]\t Bias: [2.7649585]\t Cost: 15.442287078494635\n",
            "Iteration: 1685\t Weight1: [8.9672379]\t Weight2: [1.36343791]\t Bias: [2.76454228]\t Cost: 15.442266519037076\n",
            "Iteration: 1686\t Weight1: [8.96750664]\t Weight2: [1.36303154]\t Bias: [2.76412734]\t Cost: 15.442246070274733\n",
            "Iteration: 1687\t Weight1: [8.96777469]\t Weight2: [1.36262612]\t Bias: [2.76371369]\t Cost: 15.442225731602097\n",
            "Iteration: 1688\t Weight1: [8.96804207]\t Weight2: [1.36222167]\t Bias: [2.76330131]\t Cost: 15.442205502417096\n",
            "Iteration: 1689\t Weight1: [8.96830877]\t Weight2: [1.36181816]\t Bias: [2.76289021]\t Cost: 15.44218538212097\n",
            "Iteration: 1690\t Weight1: [8.96857479]\t Weight2: [1.36141561]\t Bias: [2.76248038]\t Cost: 15.442165370118353\n",
            "Iteration: 1691\t Weight1: [8.96884014]\t Weight2: [1.36101401]\t Bias: [2.76207181]\t Cost: 15.442145465817187\n",
            "Iteration: 1692\t Weight1: [8.96910482]\t Weight2: [1.36061335]\t Bias: [2.7616645]\t Cost: 15.442125668628718\n",
            "Iteration: 1693\t Weight1: [8.96936883]\t Weight2: [1.36021364]\t Bias: [2.76125845]\t Cost: 15.442105977967472\n",
            "Iteration: 1694\t Weight1: [8.96963217]\t Weight2: [1.35981488]\t Bias: [2.76085366]\t Cost: 15.442086393251254\n",
            "Iteration: 1695\t Weight1: [8.96989484]\t Weight2: [1.35941705]\t Bias: [2.76045011]\t Cost: 15.442066913901115\n",
            "Iteration: 1696\t Weight1: [8.97015685]\t Weight2: [1.35902016]\t Bias: [2.76004781]\t Cost: 15.442047539341331\n",
            "Iteration: 1697\t Weight1: [8.97041819]\t Weight2: [1.35862421]\t Bias: [2.75964675]\t Cost: 15.442028268999419\n",
            "Iteration: 1698\t Weight1: [8.97067887]\t Weight2: [1.3582292]\t Bias: [2.75924692]\t Cost: 15.442009102306057\n",
            "Iteration: 1699\t Weight1: [8.97093889]\t Weight2: [1.35783512]\t Bias: [2.75884833]\t Cost: 15.441990038695122\n",
            "Iteration: 1700\t Weight1: [8.97119825]\t Weight2: [1.35744197]\t Bias: [2.75845097]\t Cost: 15.44197107760363\n",
            "Iteration: 1701\t Weight1: [8.97145695]\t Weight2: [1.35704975]\t Bias: [2.75805483]\t Cost: 15.441952218471751\n",
            "Iteration: 1702\t Weight1: [8.971715]\t Weight2: [1.35665845]\t Bias: [2.75765991]\t Cost: 15.44193346074275\n",
            "Iteration: 1703\t Weight1: [8.9719724]\t Weight2: [1.35626808]\t Bias: [2.75726621]\t Cost: 15.441914803863042\n",
            "Iteration: 1704\t Weight1: [8.97222914]\t Weight2: [1.35587864]\t Bias: [2.75687372]\t Cost: 15.441896247282113\n",
            "Iteration: 1705\t Weight1: [8.97248523]\t Weight2: [1.35549011]\t Bias: [2.75648245]\t Cost: 15.441877790452487\n",
            "Iteration: 1706\t Weight1: [8.97274068]\t Weight2: [1.3551025]\t Bias: [2.75609237]\t Cost: 15.441859432829759\n",
            "Iteration: 1707\t Weight1: [8.97299547]\t Weight2: [1.35471581]\t Bias: [2.7557035]\t Cost: 15.441841173872554\n",
            "Iteration: 1708\t Weight1: [8.97324962]\t Weight2: [1.35433003]\t Bias: [2.75531583]\t Cost: 15.441823013042542\n",
            "Iteration: 1709\t Weight1: [8.97350313]\t Weight2: [1.35394517]\t Bias: [2.75492935]\t Cost: 15.441804949804348\n",
            "Iteration: 1710\t Weight1: [8.97375599]\t Weight2: [1.35356122]\t Bias: [2.75454406]\t Cost: 15.441786983625576\n",
            "Iteration: 1711\t Weight1: [8.97400822]\t Weight2: [1.35317817]\t Bias: [2.75415996]\t Cost: 15.441769113976875\n",
            "Iteration: 1712\t Weight1: [8.9742598]\t Weight2: [1.35279603]\t Bias: [2.75377704]\t Cost: 15.441751340331738\n",
            "Iteration: 1713\t Weight1: [8.97451074]\t Weight2: [1.3524148]\t Bias: [2.7533953]\t Cost: 15.441733662166605\n",
            "Iteration: 1714\t Weight1: [8.97476105]\t Weight2: [1.35203447]\t Bias: [2.75301474]\t Cost: 15.441716078960935\n",
            "Iteration: 1715\t Weight1: [8.97501073]\t Weight2: [1.35165504]\t Bias: [2.75263534]\t Cost: 15.44169859019694\n",
            "Iteration: 1716\t Weight1: [8.97525977]\t Weight2: [1.3512765]\t Bias: [2.75225711]\t Cost: 15.44168119535981\n",
            "Iteration: 1717\t Weight1: [8.97550818]\t Weight2: [1.35089887]\t Bias: [2.75188005]\t Cost: 15.441663893937573\n",
            "Iteration: 1718\t Weight1: [8.97575596]\t Weight2: [1.35052213]\t Bias: [2.75150414]\t Cost: 15.441646685421096\n",
            "Iteration: 1719\t Weight1: [8.97600312]\t Weight2: [1.35014628]\t Bias: [2.75112939]\t Cost: 15.44162956930406\n",
            "Iteration: 1720\t Weight1: [8.97624964]\t Weight2: [1.34977132]\t Bias: [2.7507558]\t Cost: 15.441612545082993\n",
            "Iteration: 1721\t Weight1: [8.97649554]\t Weight2: [1.34939725]\t Bias: [2.75038335]\t Cost: 15.441595612257245\n",
            "Iteration: 1722\t Weight1: [8.97674082]\t Weight2: [1.34902407]\t Bias: [2.75001205]\t Cost: 15.441578770328885\n",
            "Iteration: 1723\t Weight1: [8.97698548]\t Weight2: [1.34865177]\t Bias: [2.74964189]\t Cost: 15.441562018802786\n",
            "Iteration: 1724\t Weight1: [8.97722951]\t Weight2: [1.34828036]\t Bias: [2.74927286]\t Cost: 15.441545357186579\n",
            "Iteration: 1725\t Weight1: [8.97747293]\t Weight2: [1.34790982]\t Bias: [2.74890497]\t Cost: 15.441528784990624\n",
            "Iteration: 1726\t Weight1: [8.97771573]\t Weight2: [1.34754017]\t Bias: [2.74853821]\t Cost: 15.44151230172797\n",
            "Iteration: 1727\t Weight1: [8.97795791]\t Weight2: [1.34717139]\t Bias: [2.74817258]\t Cost: 15.441495906914417\n",
            "Iteration: 1728\t Weight1: [8.97819948]\t Weight2: [1.34680348]\t Bias: [2.74780807]\t Cost: 15.441479600068439\n",
            "Iteration: 1729\t Weight1: [8.97844044]\t Weight2: [1.34643645]\t Bias: [2.74744468]\t Cost: 15.441463380711184\n",
            "Iteration: 1730\t Weight1: [8.97868078]\t Weight2: [1.34607029]\t Bias: [2.74708241]\t Cost: 15.441447248366442\n",
            "Iteration: 1731\t Weight1: [8.97892052]\t Weight2: [1.345705]\t Bias: [2.74672125]\t Cost: 15.44143120256068\n",
            "Iteration: 1732\t Weight1: [8.97915964]\t Weight2: [1.34534058]\t Bias: [2.7463612]\t Cost: 15.44141524282295\n",
            "Iteration: 1733\t Weight1: [8.97939817]\t Weight2: [1.34497702]\t Bias: [2.74600225]\t Cost: 15.441399368684957\n",
            "Iteration: 1734\t Weight1: [8.97963608]\t Weight2: [1.34461433]\t Bias: [2.7456444]\t Cost: 15.441383579680988\n",
            "Iteration: 1735\t Weight1: [8.97987339]\t Weight2: [1.3442525]\t Bias: [2.74528766]\t Cost: 15.441367875347918\n",
            "Iteration: 1736\t Weight1: [8.9801101]\t Weight2: [1.34389152]\t Bias: [2.74493201]\t Cost: 15.441352255225192\n",
            "Iteration: 1737\t Weight1: [8.98034621]\t Weight2: [1.34353141]\t Bias: [2.74457744]\t Cost: 15.44133671885479\n",
            "Iteration: 1738\t Weight1: [8.98058173]\t Weight2: [1.34317214]\t Bias: [2.74422397]\t Cost: 15.441321265781266\n",
            "Iteration: 1739\t Weight1: [8.98081664]\t Weight2: [1.34281374]\t Bias: [2.74387158]\t Cost: 15.441305895551668\n",
            "Iteration: 1740\t Weight1: [8.98105096]\t Weight2: [1.34245618]\t Bias: [2.74352027]\t Cost: 15.44129060771558\n",
            "Iteration: 1741\t Weight1: [8.98128468]\t Weight2: [1.34209948]\t Bias: [2.74317004]\t Cost: 15.441275401825076\n",
            "Iteration: 1742\t Weight1: [8.98151781]\t Weight2: [1.34174362]\t Bias: [2.74282089]\t Cost: 15.44126027743469\n",
            "Iteration: 1743\t Weight1: [8.98175035]\t Weight2: [1.34138861]\t Bias: [2.7424728]\t Cost: 15.441245234101466\n",
            "Iteration: 1744\t Weight1: [8.98198229]\t Weight2: [1.34103444]\t Bias: [2.74212578]\t Cost: 15.441230271384866\n",
            "Iteration: 1745\t Weight1: [8.98221365]\t Weight2: [1.34068112]\t Bias: [2.74177982]\t Cost: 15.44121538884681\n",
            "Iteration: 1746\t Weight1: [8.98244443]\t Weight2: [1.34032864]\t Bias: [2.74143493]\t Cost: 15.44120058605165\n",
            "Iteration: 1747\t Weight1: [8.98267461]\t Weight2: [1.33997699]\t Bias: [2.74109109]\t Cost: 15.441185862566126\n",
            "Iteration: 1748\t Weight1: [8.98290422]\t Weight2: [1.33962618]\t Bias: [2.7407483]\t Cost: 15.441171217959404\n",
            "Iteration: 1749\t Weight1: [8.98313324]\t Weight2: [1.33927621]\t Bias: [2.74040657]\t Cost: 15.441156651803034\n",
            "Iteration: 1750\t Weight1: [8.98336167]\t Weight2: [1.33892707]\t Bias: [2.74006588]\t Cost: 15.44114216367091\n",
            "Iteration: 1751\t Weight1: [8.98358953]\t Weight2: [1.33857876]\t Bias: [2.73972623]\t Cost: 15.441127753139327\n",
            "Iteration: 1752\t Weight1: [8.98381681]\t Weight2: [1.33823128]\t Bias: [2.73938763]\t Cost: 15.441113419786904\n",
            "Iteration: 1753\t Weight1: [8.98404352]\t Weight2: [1.33788463]\t Bias: [2.73905006]\t Cost: 15.441099163194549\n",
            "Iteration: 1754\t Weight1: [8.98426964]\t Weight2: [1.3375388]\t Bias: [2.73871352]\t Cost: 15.44108498294558\n",
            "Iteration: 1755\t Weight1: [8.9844952]\t Weight2: [1.3371938]\t Bias: [2.73837802]\t Cost: 15.441070878625556\n",
            "Iteration: 1756\t Weight1: [8.98472018]\t Weight2: [1.33684962]\t Bias: [2.73804354]\t Cost: 15.441056849822308\n",
            "Iteration: 1757\t Weight1: [8.98494459]\t Weight2: [1.33650626]\t Bias: [2.73771009]\t Cost: 15.441042896126039\n",
            "Iteration: 1758\t Weight1: [8.98516843]\t Weight2: [1.33616372]\t Bias: [2.73737765]\t Cost: 15.44102901712912\n",
            "Iteration: 1759\t Weight1: [8.9853917]\t Weight2: [1.33582199]\t Bias: [2.73704623]\t Cost: 15.441015212426235\n",
            "Iteration: 1760\t Weight1: [8.98561441]\t Weight2: [1.33548108]\t Bias: [2.73671583]\t Cost: 15.44100148161429\n",
            "Iteration: 1761\t Weight1: [8.98583654]\t Weight2: [1.33514098]\t Bias: [2.73638644]\t Cost: 15.440987824292423\n",
            "Iteration: 1762\t Weight1: [8.98605812]\t Weight2: [1.33480169]\t Bias: [2.73605805]\t Cost: 15.440974240061966\n",
            "Iteration: 1763\t Weight1: [8.98627913]\t Weight2: [1.33446322]\t Bias: [2.73573067]\t Cost: 15.44096072852651\n",
            "Iteration: 1764\t Weight1: [8.98649958]\t Weight2: [1.33412554]\t Bias: [2.73540429]\t Cost: 15.440947289291737\n",
            "Iteration: 1765\t Weight1: [8.98671948]\t Weight2: [1.33378868]\t Bias: [2.73507891]\t Cost: 15.440933921965629\n",
            "Iteration: 1766\t Weight1: [8.98693881]\t Weight2: [1.33345262]\t Bias: [2.73475452]\t Cost: 15.440920626158254\n",
            "Iteration: 1767\t Weight1: [8.98715759]\t Weight2: [1.33311736]\t Bias: [2.73443112]\t Cost: 15.440907401481853\n",
            "Iteration: 1768\t Weight1: [8.98737581]\t Weight2: [1.3327829]\t Bias: [2.73410871]\t Cost: 15.440894247550803\n",
            "Iteration: 1769\t Weight1: [8.98759347]\t Weight2: [1.33244923]\t Bias: [2.73378729]\t Cost: 15.440881163981615\n",
            "Iteration: 1770\t Weight1: [8.98781059]\t Weight2: [1.33211637]\t Bias: [2.73346685]\t Cost: 15.440868150392937\n",
            "Iteration: 1771\t Weight1: [8.98802715]\t Weight2: [1.3317843]\t Bias: [2.73314738]\t Cost: 15.440855206405494\n",
            "Iteration: 1772\t Weight1: [8.98824316]\t Weight2: [1.33145302]\t Bias: [2.73282889]\t Cost: 15.4408423316421\n",
            "Iteration: 1773\t Weight1: [8.98845862]\t Weight2: [1.33112253]\t Bias: [2.73251138]\t Cost: 15.440829525727677\n",
            "Iteration: 1774\t Weight1: [8.98867354]\t Weight2: [1.33079284]\t Bias: [2.73219483]\t Cost: 15.440816788289215\n",
            "Iteration: 1775\t Weight1: [8.98888791]\t Weight2: [1.33046393]\t Bias: [2.73187926]\t Cost: 15.440804118955725\n",
            "Iteration: 1776\t Weight1: [8.98910173]\t Weight2: [1.3301358]\t Bias: [2.73156464]\t Cost: 15.440791517358312\n",
            "Iteration: 1777\t Weight1: [8.98931502]\t Weight2: [1.32980846]\t Bias: [2.73125098]\t Cost: 15.440778983130093\n",
            "Iteration: 1778\t Weight1: [8.98952776]\t Weight2: [1.3294819]\t Bias: [2.73093829]\t Cost: 15.440766515906212\n",
            "Iteration: 1779\t Weight1: [8.98973996]\t Weight2: [1.32915613]\t Bias: [2.73062654]\t Cost: 15.440754115323795\n",
            "Iteration: 1780\t Weight1: [8.98995162]\t Weight2: [1.32883113]\t Bias: [2.73031575]\t Cost: 15.440741781022036\n",
            "Iteration: 1781\t Weight1: [8.99016274]\t Weight2: [1.32850691]\t Bias: [2.7300059]\t Cost: 15.440729512642044\n",
            "Iteration: 1782\t Weight1: [8.99037333]\t Weight2: [1.32818346]\t Bias: [2.729697]\t Cost: 15.440717309826955\n",
            "Iteration: 1783\t Weight1: [8.99058338]\t Weight2: [1.32786079]\t Bias: [2.72938905]\t Cost: 15.440705172221861\n",
            "Iteration: 1784\t Weight1: [8.9907929]\t Weight2: [1.32753889]\t Bias: [2.72908203]\t Cost: 15.440693099473789\n",
            "Iteration: 1785\t Weight1: [8.99100188]\t Weight2: [1.32721776]\t Bias: [2.72877595]\t Cost: 15.440681091231744\n",
            "Iteration: 1786\t Weight1: [8.99121033]\t Weight2: [1.32689739]\t Bias: [2.7284708]\t Cost: 15.440669147146652\n",
            "Iteration: 1787\t Weight1: [8.99141826]\t Weight2: [1.3265778]\t Bias: [2.72816658]\t Cost: 15.440657266871343\n",
            "Iteration: 1788\t Weight1: [8.99162565]\t Weight2: [1.32625897]\t Bias: [2.72786328]\t Cost: 15.440645450060575\n",
            "Iteration: 1789\t Weight1: [8.99183252]\t Weight2: [1.3259409]\t Bias: [2.72756092]\t Cost: 15.44063369637101\n",
            "Iteration: 1790\t Weight1: [8.99203887]\t Weight2: [1.32562359]\t Bias: [2.72725947]\t Cost: 15.440622005461204\n",
            "Iteration: 1791\t Weight1: [8.99224468]\t Weight2: [1.32530704]\t Bias: [2.72695894]\t Cost: 15.440610376991577\n",
            "Iteration: 1792\t Weight1: [8.99244998]\t Weight2: [1.32499125]\t Bias: [2.72665933]\t Cost: 15.440598810624424\n",
            "Iteration: 1793\t Weight1: [8.99265475]\t Weight2: [1.32467622]\t Bias: [2.72636063]\t Cost: 15.440587306023914\n",
            "Iteration: 1794\t Weight1: [8.99285901]\t Weight2: [1.32436194]\t Bias: [2.72606284]\t Cost: 15.44057586285602\n",
            "Iteration: 1795\t Weight1: [8.99306274]\t Weight2: [1.32404841]\t Bias: [2.72576595]\t Cost: 15.440564480788627\n",
            "Iteration: 1796\t Weight1: [8.99326596]\t Weight2: [1.32373564]\t Bias: [2.72546997]\t Cost: 15.440553159491365\n",
            "Iteration: 1797\t Weight1: [8.99346866]\t Weight2: [1.32342361]\t Bias: [2.7251749]\t Cost: 15.440541898635743\n",
            "Iteration: 1798\t Weight1: [8.99367084]\t Weight2: [1.32311234]\t Bias: [2.72488071]\t Cost: 15.440530697895063\n",
            "Iteration: 1799\t Weight1: [8.99387251]\t Weight2: [1.3228018]\t Bias: [2.72458743]\t Cost: 15.44051955694439\n",
            "Iteration: 1800\t Weight1: [8.99407367]\t Weight2: [1.32249202]\t Bias: [2.72429504]\t Cost: 15.440508475460614\n",
            "Iteration: 1801\t Weight1: [8.99427431]\t Weight2: [1.32218297]\t Bias: [2.72400353]\t Cost: 15.440497453122383\n",
            "Iteration: 1802\t Weight1: [8.99447445]\t Weight2: [1.32187467]\t Bias: [2.72371292]\t Cost: 15.440486489610116\n",
            "Iteration: 1803\t Weight1: [8.99467407]\t Weight2: [1.3215671]\t Bias: [2.72342318]\t Cost: 15.440475584605998\n",
            "Iteration: 1804\t Weight1: [8.99487319]\t Weight2: [1.32126027]\t Bias: [2.72313433]\t Cost: 15.440464737793949\n",
            "Iteration: 1805\t Weight1: [8.9950718]\t Weight2: [1.32095418]\t Bias: [2.72284636]\t Cost: 15.440453948859627\n",
            "Iteration: 1806\t Weight1: [8.99526991]\t Weight2: [1.32064883]\t Bias: [2.72255926]\t Cost: 15.440443217490419\n",
            "Iteration: 1807\t Weight1: [8.99546752]\t Weight2: [1.3203442]\t Bias: [2.72227304]\t Cost: 15.440432543375444\n",
            "Iteration: 1808\t Weight1: [8.99566462]\t Weight2: [1.32004031]\t Bias: [2.72198768]\t Cost: 15.440421926205456\n",
            "Iteration: 1809\t Weight1: [8.99586122]\t Weight2: [1.31973714]\t Bias: [2.7217032]\t Cost: 15.44041136567305\n",
            "Iteration: 1810\t Weight1: [8.99605732]\t Weight2: [1.31943471]\t Bias: [2.72141957]\t Cost: 15.440400861472373\n",
            "Iteration: 1811\t Weight1: [8.99625292]\t Weight2: [1.319133]\t Bias: [2.72113681]\t Cost: 15.440390413299312\n",
            "Iteration: 1812\t Weight1: [8.99644802]\t Weight2: [1.31883201]\t Bias: [2.72085491]\t Cost: 15.440380020851428\n",
            "Iteration: 1813\t Weight1: [8.99664263]\t Weight2: [1.31853174]\t Bias: [2.72057387]\t Cost: 15.440369683827912\n",
            "Iteration: 1814\t Weight1: [8.99683674]\t Weight2: [1.3182322]\t Bias: [2.72029368]\t Cost: 15.44035940192964\n",
            "Iteration: 1815\t Weight1: [8.99703036]\t Weight2: [1.31793338]\t Bias: [2.72001434]\t Cost: 15.440349174859097\n",
            "Iteration: 1816\t Weight1: [8.99722349]\t Weight2: [1.31763527]\t Bias: [2.71973584]\t Cost: 15.44033900232043\n",
            "Iteration: 1817\t Weight1: [8.99741612]\t Weight2: [1.31733788]\t Bias: [2.7194582]\t Cost: 15.44032888401938\n",
            "Iteration: 1818\t Weight1: [8.99760827]\t Weight2: [1.31704121]\t Bias: [2.71918139]\t Cost: 15.440318819663343\n",
            "Iteration: 1819\t Weight1: [8.99779992]\t Weight2: [1.31674524]\t Bias: [2.71890543]\t Cost: 15.44030880896125\n",
            "Iteration: 1820\t Weight1: [8.99799109]\t Weight2: [1.31644999]\t Bias: [2.7186303]\t Cost: 15.440298851623734\n",
            "Iteration: 1821\t Weight1: [8.99818177]\t Weight2: [1.31615545]\t Bias: [2.71835601]\t Cost: 15.440288947362923\n",
            "Iteration: 1822\t Weight1: [8.99837197]\t Weight2: [1.31586162]\t Bias: [2.71808256]\t Cost: 15.440279095892553\n",
            "Iteration: 1823\t Weight1: [8.99856168]\t Weight2: [1.31556849]\t Bias: [2.71780993]\t Cost: 15.440269296927934\n",
            "Iteration: 1824\t Weight1: [8.99875091]\t Weight2: [1.31527607]\t Bias: [2.71753812]\t Cost: 15.44025955018595\n",
            "Iteration: 1825\t Weight1: [8.99893966]\t Weight2: [1.31498435]\t Bias: [2.71726715]\t Cost: 15.440249855385\n",
            "Iteration: 1826\t Weight1: [8.99912793]\t Weight2: [1.31469333]\t Bias: [2.71699699]\t Cost: 15.440240212245056\n",
            "Iteration: 1827\t Weight1: [8.99931572]\t Weight2: [1.31440301]\t Bias: [2.71672766]\t Cost: 15.440230620487618\n",
            "Iteration: 1828\t Weight1: [8.99950303]\t Weight2: [1.31411339]\t Bias: [2.71645914]\t Cost: 15.4402210798357\n",
            "Iteration: 1829\t Weight1: [8.99968987]\t Weight2: [1.31382447]\t Bias: [2.71619143]\t Cost: 15.440211590013863\n",
            "Iteration: 1830\t Weight1: [8.99987622]\t Weight2: [1.31353624]\t Bias: [2.71592454]\t Cost: 15.440202150748139\n",
            "Iteration: 1831\t Weight1: [9.00006211]\t Weight2: [1.31324871]\t Bias: [2.71565845]\t Cost: 15.440192761766092\n",
            "Iteration: 1832\t Weight1: [9.00024752]\t Weight2: [1.31296187]\t Bias: [2.71539317]\t Cost: 15.440183422796766\n",
            "Iteration: 1833\t Weight1: [9.00043246]\t Weight2: [1.31267571]\t Bias: [2.7151287]\t Cost: 15.440174133570698\n",
            "Iteration: 1834\t Weight1: [9.00061693]\t Weight2: [1.31239025]\t Bias: [2.71486502]\t Cost: 15.44016489381985\n",
            "Iteration: 1835\t Weight1: [9.00080093]\t Weight2: [1.31210548]\t Bias: [2.71460215]\t Cost: 15.44015570327773\n",
            "Iteration: 1836\t Weight1: [9.00098446]\t Weight2: [1.31182139]\t Bias: [2.71434007]\t Cost: 15.440146561679237\n",
            "Iteration: 1837\t Weight1: [9.00116753]\t Weight2: [1.31153798]\t Bias: [2.71407878]\t Cost: 15.440137468760799\n",
            "Iteration: 1838\t Weight1: [9.00135013]\t Weight2: [1.31125526]\t Bias: [2.71381829]\t Cost: 15.440128424260193\n",
            "Iteration: 1839\t Weight1: [9.00153226]\t Weight2: [1.31097322]\t Bias: [2.71355859]\t Cost: 15.440119427916681\n",
            "Iteration: 1840\t Weight1: [9.00171393]\t Weight2: [1.31069185]\t Bias: [2.71329967]\t Cost: 15.44011047947096\n",
            "Iteration: 1841\t Weight1: [9.00189514]\t Weight2: [1.31041117]\t Bias: [2.71304153]\t Cost: 15.440101578665136\n",
            "Iteration: 1842\t Weight1: [9.00207588]\t Weight2: [1.31013116]\t Bias: [2.71278418]\t Cost: 15.440092725242703\n",
            "Iteration: 1843\t Weight1: [9.00225617]\t Weight2: [1.30985183]\t Bias: [2.7125276]\t Cost: 15.440083918948597\n",
            "Iteration: 1844\t Weight1: [9.00243599]\t Weight2: [1.30957317]\t Bias: [2.7122718]\t Cost: 15.440075159529119\n",
            "Iteration: 1845\t Weight1: [9.00261536]\t Weight2: [1.30929518]\t Bias: [2.71201678]\t Cost: 15.440066446731961\n",
            "Iteration: 1846\t Weight1: [9.00279428]\t Weight2: [1.30901786]\t Bias: [2.71176253]\t Cost: 15.44005778030621\n",
            "Iteration: 1847\t Weight1: [9.00297273]\t Weight2: [1.30874121]\t Bias: [2.71150904]\t Cost: 15.44004916000231\n",
            "Iteration: 1848\t Weight1: [9.00315073]\t Weight2: [1.30846523]\t Bias: [2.71125632]\t Cost: 15.440040585572072\n",
            "Iteration: 1849\t Weight1: [9.00332828]\t Weight2: [1.30818991]\t Bias: [2.71100437]\t Cost: 15.440032056768692\n",
            "Iteration: 1850\t Weight1: [9.00350538]\t Weight2: [1.30791526]\t Bias: [2.71075318]\t Cost: 15.44002357334664\n",
            "Iteration: 1851\t Weight1: [9.00368203]\t Weight2: [1.30764127]\t Bias: [2.71050275]\t Cost: 15.440015135061806\n",
            "Iteration: 1852\t Weight1: [9.00385822]\t Weight2: [1.30736794]\t Bias: [2.71025307]\t Cost: 15.440006741671386\n",
            "Iteration: 1853\t Weight1: [9.00403397]\t Weight2: [1.30709527]\t Bias: [2.71000415]\t Cost: 15.439998392933903\n",
            "Iteration: 1854\t Weight1: [9.00420927]\t Weight2: [1.30682326]\t Bias: [2.70975598]\t Cost: 15.439990088609171\n",
            "Iteration: 1855\t Weight1: [9.00438412]\t Weight2: [1.3065519]\t Bias: [2.70950856]\t Cost: 15.439981828458372\n",
            "Iteration: 1856\t Weight1: [9.00455853]\t Weight2: [1.3062812]\t Bias: [2.70926189]\t Cost: 15.439973612243936\n",
            "Iteration: 1857\t Weight1: [9.00473249]\t Weight2: [1.30601115]\t Bias: [2.70901597]\t Cost: 15.439965439729628\n",
            "Iteration: 1858\t Weight1: [9.00490601]\t Weight2: [1.30574176]\t Bias: [2.70877078]\t Cost: 15.43995731068049\n",
            "Iteration: 1859\t Weight1: [9.00507909]\t Weight2: [1.30547302]\t Bias: [2.70852634]\t Cost: 15.439949224862847\n",
            "Iteration: 1860\t Weight1: [9.00525173]\t Weight2: [1.30520492]\t Bias: [2.70828264]\t Cost: 15.439941182044299\n",
            "Iteration: 1861\t Weight1: [9.00542393]\t Weight2: [1.30493747]\t Bias: [2.70803967]\t Cost: 15.439933181993712\n",
            "Iteration: 1862\t Weight1: [9.00559569]\t Weight2: [1.30467067]\t Bias: [2.70779743]\t Cost: 15.439925224481204\n",
            "Iteration: 1863\t Weight1: [9.00576701]\t Weight2: [1.30440451]\t Bias: [2.70755593]\t Cost: 15.439917309278183\n",
            "Iteration: 1864\t Weight1: [9.0059379]\t Weight2: [1.304139]\t Bias: [2.70731515]\t Cost: 15.439909436157281\n",
            "Iteration: 1865\t Weight1: [9.00610834]\t Weight2: [1.30387413]\t Bias: [2.70707511]\t Cost: 15.439901604892343\n",
            "Iteration: 1866\t Weight1: [9.00627836]\t Weight2: [1.30360989]\t Bias: [2.70683578]\t Cost: 15.4398938152585\n",
            "Iteration: 1867\t Weight1: [9.00644794]\t Weight2: [1.3033463]\t Bias: [2.70659718]\t Cost: 15.43988606703207\n",
            "Iteration: 1868\t Weight1: [9.00661709]\t Weight2: [1.30308334]\t Bias: [2.7063593]\t Cost: 15.439878359990615\n",
            "Iteration: 1869\t Weight1: [9.00678581]\t Weight2: [1.30282102]\t Bias: [2.70612213]\t Cost: 15.439870693912907\n",
            "Iteration: 1870\t Weight1: [9.0069541]\t Weight2: [1.30255933]\t Bias: [2.70588568]\t Cost: 15.439863068578894\n",
            "Iteration: 1871\t Weight1: [9.00712196]\t Weight2: [1.30229828]\t Bias: [2.70564995]\t Cost: 15.439855483769751\n",
            "Iteration: 1872\t Weight1: [9.0072894]\t Weight2: [1.30203786]\t Bias: [2.70541492]\t Cost: 15.439847939267866\n",
            "Iteration: 1873\t Weight1: [9.0074564]\t Weight2: [1.30177806]\t Bias: [2.7051806]\t Cost: 15.439840434856762\n",
            "Iteration: 1874\t Weight1: [9.00762298]\t Weight2: [1.3015189]\t Bias: [2.70494699]\t Cost: 15.439832970321188\n",
            "Iteration: 1875\t Weight1: [9.00778914]\t Weight2: [1.30126036]\t Bias: [2.70471409]\t Cost: 15.439825545447025\n",
            "Iteration: 1876\t Weight1: [9.00795487]\t Weight2: [1.30100245]\t Bias: [2.70448188]\t Cost: 15.439818160021357\n",
            "Iteration: 1877\t Weight1: [9.00812018]\t Weight2: [1.30074516]\t Bias: [2.70425038]\t Cost: 15.43981081383242\n",
            "Iteration: 1878\t Weight1: [9.00828507]\t Weight2: [1.3004885]\t Bias: [2.70401957]\t Cost: 15.439803506669588\n",
            "Iteration: 1879\t Weight1: [9.00844954]\t Weight2: [1.30023245]\t Bias: [2.70378946]\t Cost: 15.439796238323375\n",
            "Iteration: 1880\t Weight1: [9.00861359]\t Weight2: [1.29997703]\t Bias: [2.70356004]\t Cost: 15.439789008585475\n",
            "Iteration: 1881\t Weight1: [9.00877722]\t Weight2: [1.29972222]\t Bias: [2.70333131]\t Cost: 15.439781817248686\n",
            "Iteration: 1882\t Weight1: [9.00894044]\t Weight2: [1.29946803]\t Bias: [2.70310327]\t Cost: 15.439774664106936\n",
            "Iteration: 1883\t Weight1: [9.00910324]\t Weight2: [1.29921446]\t Bias: [2.70287591]\t Cost: 15.439767548955295\n",
            "Iteration: 1884\t Weight1: [9.00926562]\t Weight2: [1.2989615]\t Bias: [2.70264925]\t Cost: 15.439760471589906\n",
            "Iteration: 1885\t Weight1: [9.00942759]\t Weight2: [1.29870915]\t Bias: [2.70242326]\t Cost: 15.439753431808086\n",
            "Iteration: 1886\t Weight1: [9.00958914]\t Weight2: [1.29845741]\t Bias: [2.70219795]\t Cost: 15.439746429408185\n",
            "Iteration: 1887\t Weight1: [9.00975029]\t Weight2: [1.29820629]\t Bias: [2.70197333]\t Cost: 15.439739464189701\n",
            "Iteration: 1888\t Weight1: [9.00991102]\t Weight2: [1.29795577]\t Bias: [2.70174937]\t Cost: 15.439732535953198\n",
            "Iteration: 1889\t Weight1: [9.01007135]\t Weight2: [1.29770586]\t Bias: [2.7015261]\t Cost: 15.439725644500346\n",
            "Iteration: 1890\t Weight1: [9.01023126]\t Weight2: [1.29745655]\t Bias: [2.70130349]\t Cost: 15.439718789633872\n",
            "Iteration: 1891\t Weight1: [9.01039077]\t Weight2: [1.29720785]\t Bias: [2.70108155]\t Cost: 15.439711971157587\n",
            "Iteration: 1892\t Weight1: [9.01054987]\t Weight2: [1.29695975]\t Bias: [2.70086028]\t Cost: 15.439705188876365\n",
            "Iteration: 1893\t Weight1: [9.01070857]\t Weight2: [1.29671226]\t Bias: [2.70063968]\t Cost: 15.439698442596143\n",
            "Iteration: 1894\t Weight1: [9.01086686]\t Weight2: [1.29646536]\t Bias: [2.70041974]\t Cost: 15.439691732123935\n",
            "Iteration: 1895\t Weight1: [9.01102475]\t Weight2: [1.29621906]\t Bias: [2.70020046]\t Cost: 15.439685057267738\n",
            "Iteration: 1896\t Weight1: [9.01118223]\t Weight2: [1.29597336]\t Bias: [2.69998184]\t Cost: 15.439678417836662\n",
            "Iteration: 1897\t Weight1: [9.01133931]\t Weight2: [1.29572826]\t Bias: [2.69976387]\t Cost: 15.439671813640839\n",
            "Iteration: 1898\t Weight1: [9.01149599]\t Weight2: [1.29548375]\t Bias: [2.69954656]\t Cost: 15.43966524449143\n",
            "Iteration: 1899\t Weight1: [9.01165228]\t Weight2: [1.29523983]\t Bias: [2.69932991]\t Cost: 15.439658710200595\n",
            "Iteration: 1900\t Weight1: [9.01180816]\t Weight2: [1.2949965]\t Bias: [2.6991139]\t Cost: 15.439652210581542\n",
            "Iteration: 1901\t Weight1: [9.01196365]\t Weight2: [1.29475377]\t Bias: [2.69889855]\t Cost: 15.439645745448495\n",
            "Iteration: 1902\t Weight1: [9.01211874]\t Weight2: [1.29451162]\t Bias: [2.69868384]\t Cost: 15.439639314616684\n",
            "Iteration: 1903\t Weight1: [9.01227343]\t Weight2: [1.29427006]\t Bias: [2.69846978]\t Cost: 15.439632917902328\n",
            "Iteration: 1904\t Weight1: [9.01242773]\t Weight2: [1.29402909]\t Bias: [2.69825636]\t Cost: 15.439626555122668\n",
            "Iteration: 1905\t Weight1: [9.01258164]\t Weight2: [1.2937887]\t Bias: [2.69804358]\t Cost: 15.439620226095913\n",
            "Iteration: 1906\t Weight1: [9.01273515]\t Weight2: [1.2935489]\t Bias: [2.69783143]\t Cost: 15.439613930641297\n",
            "Iteration: 1907\t Weight1: [9.01288828]\t Weight2: [1.29330968]\t Bias: [2.69761993]\t Cost: 15.43960766857898\n",
            "Iteration: 1908\t Weight1: [9.01304101]\t Weight2: [1.29307104]\t Bias: [2.69740906]\t Cost: 15.439601439730145\n",
            "Iteration: 1909\t Weight1: [9.01319335]\t Weight2: [1.29283297]\t Bias: [2.69719882]\t Cost: 15.43959524391693\n",
            "Iteration: 1910\t Weight1: [9.0133453]\t Weight2: [1.29259549]\t Bias: [2.69698922]\t Cost: 15.439589080962433\n",
            "Iteration: 1911\t Weight1: [9.01349687]\t Weight2: [1.29235858]\t Bias: [2.69678024]\t Cost: 15.439582950690724\n",
            "Iteration: 1912\t Weight1: [9.01364805]\t Weight2: [1.29212225]\t Bias: [2.69657189]\t Cost: 15.439576852926827\n",
            "Iteration: 1913\t Weight1: [9.01379884]\t Weight2: [1.2918865]\t Bias: [2.69636416]\t Cost: 15.439570787496692\n",
            "Iteration: 1914\t Weight1: [9.01394925]\t Weight2: [1.29165131]\t Bias: [2.69615706]\t Cost: 15.439564754227245\n",
            "Iteration: 1915\t Weight1: [9.01409928]\t Weight2: [1.2914167]\t Bias: [2.69595058]\t Cost: 15.439558752946338\n",
            "Iteration: 1916\t Weight1: [9.01424892]\t Weight2: [1.29118266]\t Bias: [2.69574472]\t Cost: 15.439552783482746\n",
            "Iteration: 1917\t Weight1: [9.01439818]\t Weight2: [1.29094918]\t Bias: [2.69553947]\t Cost: 15.43954684566622\n",
            "Iteration: 1918\t Weight1: [9.01454706]\t Weight2: [1.29071628]\t Bias: [2.69533484]\t Cost: 15.439540939327333\n",
            "Iteration: 1919\t Weight1: [9.01469556]\t Weight2: [1.29048394]\t Bias: [2.69513083]\t Cost: 15.439535064297695\n",
            "Iteration: 1920\t Weight1: [9.01484368]\t Weight2: [1.29025216]\t Bias: [2.69492742]\t Cost: 15.439529220409755\n",
            "Iteration: 1921\t Weight1: [9.01499142]\t Weight2: [1.29002095]\t Bias: [2.69472463]\t Cost: 15.439523407496905\n",
            "Iteration: 1922\t Weight1: [9.01513879]\t Weight2: [1.2897903]\t Bias: [2.69452244]\t Cost: 15.439517625393432\n",
            "Iteration: 1923\t Weight1: [9.01528578]\t Weight2: [1.28956021]\t Bias: [2.69432086]\t Cost: 15.439511873934494\n",
            "Iteration: 1924\t Weight1: [9.01543239]\t Weight2: [1.28933068]\t Bias: [2.69411988]\t Cost: 15.439506152956174\n",
            "Iteration: 1925\t Weight1: [9.01557863]\t Weight2: [1.28910171]\t Bias: [2.69391951]\t Cost: 15.439500462295426\n",
            "Iteration: 1926\t Weight1: [9.0157245]\t Weight2: [1.2888733]\t Bias: [2.69371973]\t Cost: 15.439494801790122\n",
            "Iteration: 1927\t Weight1: [9.01587]\t Weight2: [1.28864544]\t Bias: [2.69352055]\t Cost: 15.439489171278966\n",
            "Iteration: 1928\t Weight1: [9.01601512]\t Weight2: [1.28841814]\t Bias: [2.69332197]\t Cost: 15.43948357060156\n",
            "Iteration: 1929\t Weight1: [9.01615987]\t Weight2: [1.28819139]\t Bias: [2.69312398]\t Cost: 15.439477999598367\n",
            "Iteration: 1930\t Weight1: [9.01630426]\t Weight2: [1.28796519]\t Bias: [2.69292659]\t Cost: 15.439472458110743\n",
            "Iteration: 1931\t Weight1: [9.01644827]\t Weight2: [1.28773954]\t Bias: [2.69272979]\t Cost: 15.439466945980856\n",
            "Iteration: 1932\t Weight1: [9.01659192]\t Weight2: [1.28751444]\t Bias: [2.69253357]\t Cost: 15.43946146305176\n",
            "Iteration: 1933\t Weight1: [9.0167352]\t Weight2: [1.28728989]\t Bias: [2.69233795]\t Cost: 15.439456009167353\n",
            "Iteration: 1934\t Weight1: [9.01687812]\t Weight2: [1.28706589]\t Bias: [2.6921429]\t Cost: 15.43945058417237\n",
            "Iteration: 1935\t Weight1: [9.01702067]\t Weight2: [1.28684243]\t Bias: [2.69194844]\t Cost: 15.439445187912405\n",
            "Iteration: 1936\t Weight1: [9.01716286]\t Weight2: [1.28661951]\t Bias: [2.69175457]\t Cost: 15.439439820233867\n",
            "Iteration: 1937\t Weight1: [9.01730468]\t Weight2: [1.28639714]\t Bias: [2.69156127]\t Cost: 15.439434480984026\n",
            "Iteration: 1938\t Weight1: [9.01744614]\t Weight2: [1.28617531]\t Bias: [2.69136855]\t Cost: 15.439429170010932\n",
            "Iteration: 1939\t Weight1: [9.01758724]\t Weight2: [1.28595402]\t Bias: [2.69117641]\t Cost: 15.439423887163498\n",
            "Iteration: 1940\t Weight1: [9.01772798]\t Weight2: [1.28573327]\t Bias: [2.69098484]\t Cost: 15.439418632291446\n",
            "Iteration: 1941\t Weight1: [9.01786836]\t Weight2: [1.28551306]\t Bias: [2.69079385]\t Cost: 15.439413405245284\n",
            "Iteration: 1942\t Weight1: [9.01800839]\t Weight2: [1.28529338]\t Bias: [2.69060342]\t Cost: 15.439408205876392\n",
            "Iteration: 1943\t Weight1: [9.01814805]\t Weight2: [1.28507424]\t Bias: [2.69041356]\t Cost: 15.439403034036875\n",
            "Iteration: 1944\t Weight1: [9.01828736]\t Weight2: [1.28485564]\t Bias: [2.69022428]\t Cost: 15.439397889579682\n",
            "Iteration: 1945\t Weight1: [9.01842631]\t Weight2: [1.28463756]\t Bias: [2.69003555]\t Cost: 15.439392772358584\n",
            "Iteration: 1946\t Weight1: [9.01856491]\t Weight2: [1.28442002]\t Bias: [2.68984739]\t Cost: 15.439387682228077\n",
            "Iteration: 1947\t Weight1: [9.01870315]\t Weight2: [1.28420301]\t Bias: [2.6896598]\t Cost: 15.439382619043498\n",
            "Iteration: 1948\t Weight1: [9.01884104]\t Weight2: [1.28398653]\t Bias: [2.68947276]\t Cost: 15.43937758266092\n",
            "Iteration: 1949\t Weight1: [9.01897858]\t Weight2: [1.28377057]\t Bias: [2.68928628]\t Cost: 15.439372572937273\n",
            "Iteration: 1950\t Weight1: [9.01911577]\t Weight2: [1.28355514]\t Bias: [2.68910036]\t Cost: 15.439367589730145\n",
            "Iteration: 1951\t Weight1: [9.01925261]\t Weight2: [1.28334024]\t Bias: [2.688915]\t Cost: 15.439362632898002\n",
            "Iteration: 1952\t Weight1: [9.0193891]\t Weight2: [1.28312586]\t Bias: [2.68873018]\t Cost: 15.439357702300011\n",
            "Iteration: 1953\t Weight1: [9.01952524]\t Weight2: [1.28291201]\t Bias: [2.68854592]\t Cost: 15.439352797796124\n",
            "Iteration: 1954\t Weight1: [9.01966103]\t Weight2: [1.28269867]\t Bias: [2.68836221]\t Cost: 15.439347919247048\n",
            "Iteration: 1955\t Weight1: [9.01979647]\t Weight2: [1.28248586]\t Bias: [2.68817905]\t Cost: 15.439343066514247\n",
            "Iteration: 1956\t Weight1: [9.01993157]\t Weight2: [1.28227357]\t Bias: [2.68799643]\t Cost: 15.43933823945992\n",
            "Iteration: 1957\t Weight1: [9.02006632]\t Weight2: [1.28206179]\t Bias: [2.68781436]\t Cost: 15.439333437946999\n",
            "Iteration: 1958\t Weight1: [9.02020073]\t Weight2: [1.28185053]\t Bias: [2.68763283]\t Cost: 15.439328661839218\n",
            "Iteration: 1959\t Weight1: [9.0203348]\t Weight2: [1.28163979]\t Bias: [2.68745184]\t Cost: 15.439323911000978\n",
            "Iteration: 1960\t Weight1: [9.02046852]\t Weight2: [1.28142956]\t Bias: [2.6872714]\t Cost: 15.439319185297432\n",
            "Iteration: 1961\t Weight1: [9.02060191]\t Weight2: [1.28121985]\t Bias: [2.68709149]\t Cost: 15.43931448459449\n",
            "Iteration: 1962\t Weight1: [9.02073495]\t Weight2: [1.28101064]\t Bias: [2.68691211]\t Cost: 15.439309808758763\n",
            "Iteration: 1963\t Weight1: [9.02086765]\t Weight2: [1.28080195]\t Bias: [2.68673328]\t Cost: 15.439305157657545\n",
            "Iteration: 1964\t Weight1: [9.02100001]\t Weight2: [1.28059377]\t Bias: [2.68655497]\t Cost: 15.439300531158938\n",
            "Iteration: 1965\t Weight1: [9.02113204]\t Weight2: [1.28038609]\t Bias: [2.6863772]\t Cost: 15.439295929131685\n",
            "Iteration: 1966\t Weight1: [9.02126372]\t Weight2: [1.28017893]\t Bias: [2.68619995]\t Cost: 15.439291351445233\n",
            "Iteration: 1967\t Weight1: [9.02139507]\t Weight2: [1.27997226]\t Bias: [2.68602324]\t Cost: 15.439286797969796\n",
            "Iteration: 1968\t Weight1: [9.02152609]\t Weight2: [1.27976611]\t Bias: [2.68584705]\t Cost: 15.439282268576212\n",
            "Iteration: 1969\t Weight1: [9.02165677]\t Weight2: [1.27956046]\t Bias: [2.68567139]\t Cost: 15.439277763136086\n",
            "Iteration: 1970\t Weight1: [9.02178712]\t Weight2: [1.27935531]\t Bias: [2.68549624]\t Cost: 15.439273281521668\n",
            "Iteration: 1971\t Weight1: [9.02191713]\t Weight2: [1.27915066]\t Bias: [2.68532163]\t Cost: 15.439268823605929\n",
            "Iteration: 1972\t Weight1: [9.02204681]\t Weight2: [1.27894651]\t Bias: [2.68514753]\t Cost: 15.439264389262487\n",
            "Iteration: 1973\t Weight1: [9.02217616]\t Weight2: [1.27874286]\t Bias: [2.68497394]\t Cost: 15.439259978365673\n",
            "Iteration: 1974\t Weight1: [9.02230518]\t Weight2: [1.27853971]\t Bias: [2.68480088]\t Cost: 15.439255590790506\n",
            "Iteration: 1975\t Weight1: [9.02243387]\t Weight2: [1.27833705]\t Bias: [2.68462833]\t Cost: 15.439251226412614\n",
            "Iteration: 1976\t Weight1: [9.02256223]\t Weight2: [1.27813489]\t Bias: [2.6844563]\t Cost: 15.43924688510839\n",
            "Iteration: 1977\t Weight1: [9.02269026]\t Weight2: [1.27793323]\t Bias: [2.68428477]\t Cost: 15.439242566754842\n",
            "Iteration: 1978\t Weight1: [9.02281797]\t Weight2: [1.27773205]\t Bias: [2.68411376]\t Cost: 15.439238271229627\n",
            "Iteration: 1979\t Weight1: [9.02294535]\t Weight2: [1.27753137]\t Bias: [2.68394326]\t Cost: 15.439233998411082\n",
            "Iteration: 1980\t Weight1: [9.0230724]\t Weight2: [1.27733119]\t Bias: [2.68377326]\t Cost: 15.4392297481782\n",
            "Iteration: 1981\t Weight1: [9.02319913]\t Weight2: [1.27713149]\t Bias: [2.68360377]\t Cost: 15.439225520410636\n",
            "Iteration: 1982\t Weight1: [9.02332554]\t Weight2: [1.27693227]\t Bias: [2.68343478]\t Cost: 15.439221314988687\n",
            "Iteration: 1983\t Weight1: [9.02345162]\t Weight2: [1.27673355]\t Bias: [2.6832663]\t Cost: 15.43921713179326\n",
            "Iteration: 1984\t Weight1: [9.02357738]\t Weight2: [1.27653531]\t Bias: [2.68309831]\t Cost: 15.439212970705974\n",
            "Iteration: 1985\t Weight1: [9.02370282]\t Weight2: [1.27633756]\t Bias: [2.68293083]\t Cost: 15.439208831609017\n",
            "Iteration: 1986\t Weight1: [9.02382794]\t Weight2: [1.27614029]\t Bias: [2.68276385]\t Cost: 15.439204714385255\n",
            "Iteration: 1987\t Weight1: [9.02395273]\t Weight2: [1.27594351]\t Bias: [2.68259736]\t Cost: 15.439200618918171\n",
            "Iteration: 1988\t Weight1: [9.02407721]\t Weight2: [1.2757472]\t Bias: [2.68243136]\t Cost: 15.439196545091878\n",
            "Iteration: 1989\t Weight1: [9.02420137]\t Weight2: [1.27555138]\t Bias: [2.68226586]\t Cost: 15.43919249279111\n",
            "Iteration: 1990\t Weight1: [9.02432522]\t Weight2: [1.27535604]\t Bias: [2.68210085]\t Cost: 15.439188461901235\n",
            "Iteration: 1991\t Weight1: [9.02444874]\t Weight2: [1.27516117]\t Bias: [2.68193633]\t Cost: 15.4391844523082\n",
            "Iteration: 1992\t Weight1: [9.02457195]\t Weight2: [1.27496678]\t Bias: [2.6817723]\t Cost: 15.439180463898614\n",
            "Iteration: 1993\t Weight1: [9.02469485]\t Weight2: [1.27477287]\t Bias: [2.68160876]\t Cost: 15.43917649655969\n",
            "Iteration: 1994\t Weight1: [9.02481743]\t Weight2: [1.27457943]\t Bias: [2.6814457]\t Cost: 15.439172550179208\n",
            "Iteration: 1995\t Weight1: [9.0249397]\t Weight2: [1.27438647]\t Bias: [2.68128313]\t Cost: 15.439168624645601\n",
            "Iteration: 1996\t Weight1: [9.02506166]\t Weight2: [1.27419398]\t Bias: [2.68112104]\t Cost: 15.439164719847861\n",
            "Iteration: 1997\t Weight1: [9.0251833]\t Weight2: [1.27400196]\t Bias: [2.68095943]\t Cost: 15.439160835675615\n",
            "Iteration: 1998\t Weight1: [9.02530463]\t Weight2: [1.27381041]\t Bias: [2.6807983]\t Cost: 15.439156972019061\n",
            "Iteration: 1999\t Weight1: [9.02542566]\t Weight2: [1.27361933]\t Bias: [2.68063765]\t Cost: 15.439153128768991\n",
            "Weight2: [1.27361933]Weight1: [9.02542566] Bias: [2.68063765]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfkv905tVI5t",
        "colab_type": "code",
        "outputId": "0b5bbf68-4254-4d60-aec6-803ee6a48a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.scatter(X_train, y_train, z_train, color='red')\n",
        "plt.plot(X_train, regressor.predict(X_train, z_train), color='blue')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f26dd3e9a20>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5CkFuIhInlKAi4jkKQW4iEie+n+TpwH7boWCMQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-Cb6LzTfUTq",
        "colab_type": "code",
        "outputId": "58142ced-94bd-4ab8-c86b-5e28e64c67f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        }
      },
      "source": [
        "# Visualising the Training set results\n",
        "plt.scatter(X_train, y_train, z_train, color='red')\n",
        "plt.plot(X_train, regressor.predict(X_train,z_train), color='blue')\n",
        "plt.title('Hours vs Scores (Training set)')\n",
        "plt.xlabel('Hours')\n",
        "plt.ylabel('Scores')\n",
        "plt.show()\n",
        "\n",
        "# Visualising the Test set results\n",
        "plt.plot(regressor.cost_trend, color='blue')\n",
        "plt.title('Cost Flow')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Cost')\n",
        "plt.show()\n",
        "\n",
        "# Visualising the Test set results\n",
        "plt.scatter(X_test, y_test, z_train, color='red')\n",
        "plt.plot(X_train, regressor.predict(X_train, z_train), color='blue')\n",
        "plt.title('Hours vs Scores (Test set)')\n",
        "plt.xlabel('Hours')\n",
        "plt.ylabel('Scores')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVmOc+M3MaowTv5lZjXHiNzOrMf8PKIkCBlJvoOUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ34zsyrjxG9mVmWc+M3MqowTv5lZlfn/a0Z1OTigxJgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIq43yKPfUTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}